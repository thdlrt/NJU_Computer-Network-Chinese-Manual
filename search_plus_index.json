{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction nju cs计网中文手册 designed by Thdlrt with chatgpt "},"asserts/网络概述.html":{"url":"asserts/网络概述.html","title":"U0 网络概述","keywords":"","body":"网络概述 internet构成 组成角度 计算设备（主机/端系统） 通讯设备：电缆、无线电频谱 传输速率用bit/s计量 路由器&交换机 API: 与因特网相连的端系统提供了一个应用程序编程接口 协议：一个协议定义了在两个或多个通信实体之间交换的报文格式和次序, 以及报文发送和接受一条报文或其他事情所采取的动作. 网络的网络：多层ISP（网络服务商） 低层isp是高层isp客户，高层isp间互联 如何连接到internet 组成 网络边缘edge：端系统、服务器 网络接入access networks：物理媒介，有线无线连接，将端系统连接到边缘路由器的网络（光缆、无线路由器，链接终端的“最后一公里”） 网络核心network core：交换机、路由器 家庭接入 电话线dsl 电缆 光纤ftth 卫星 公司接入 以太网 wifi 广域无线接入 广域网 wifi 4g，5g，lte 物理媒介： 光缆，双绞铜线（网线），同轴电缆 无线传输wifi，卫星 如何通过internet传输数据 共享连接代替点对点专有连接，节约资源 电路交换（网络核心）： 类似早起电话交换，点对点传输，线路专用 优点：资源预留，速度质量有保证 缺点：线路复杂，延迟，不能充分利用线路资源 分组（包）交换 非独立处理，将数据划分为小块 问题：拥塞问题，包可能需要在交换机排队暂时存储在输出队列，等待传输，超出容量可能发生丢包 优点：充分利用互联网资源 虚电路交换 分配路径，保留资源 统计复用： 所有用户不会同时使用网络，因此可以许诺给每个用户大于线路承载总合的带宽 互联网层次和模型 层次 物理层：通过连接传输bits 规定物理信号传输方式及接口规格 数据链路层：bits->帧 检查bits，将bits转化为有用的数据 在单线上传输信息，控制局域网 网络层：实现多线连接（ip） 让多个链路通信，自动选路 拥塞控制 传输层：在接通的机器间进行端到端应用的连接（tcp，udp） 应用层：支持网络应用（ftp，http） 融合session和presentation osi7层，tcp5层 实现过程 每一层对数据前加上包头，接收时再逐层解析 传输过程中对数据进行分割 优缺点 优点： 降低复杂度 提高灵活度 缺点： 过高负载（很短的信息也需要添加一系列的包头） 层次划分过严，高层可能需要一些低层次信息 互联网性能评估 延迟 概念：一个数据从发出到收到需要多少时间 时延=传输时延transmission+传播时延propagation+排队时延queuing+处理时延processing 传输：把包推进链路需要多长时间 包大小/链路宽度（transmission rate） 传播：在线路上传输需要的时间，由线路的物理媒介决定 线路长度/传输速度 例 按照最后一个bit传输完成计算 大包先拆分再传输 排队： 因素： 到达速率 到达分布（集中/分散） 传出速率 评价：均值/方差 平均排队数目L=平均到达速率A*平均等待时间W 处理：芯片处理能力决定 丢包 在传输过程中总共丢失了几个包 计算：乘法，每一段传输成功概率相乘 吞吐量 计算 传输速率R（吞吐量）（bits/sec）（由最细/慢的部分决定） 文件大小F 传输时间=F/R+传播延时 "},"asserts/链路层.html":{"url":"asserts/链路层.html","title":"U1 链路层","keywords":"","body":"链路层 一、基本服务 将数据打包成帧，添加头尾 连通 性质 协调多设备连接（多设备接入网络的控制） mac局部地址进行标识区分 半双工、全双工：是否双向同时传输 连接方式 点对点连接 广播（无线局域网lan、卫星无线通信） MAC（不是地址那个） 分布式算法、控制多设备接入的网络，组织多个设备同时传输数据，决定让哪一个设备开始数据传输 三种技术： 信道划分，分给不同节点 轮流传输 随机接入，提供发生冲突后的恢复解决方式 在链路层提供可靠传输（不都保证） 用光纤传输时通常不需要保证，因为出错概率很低，是小概率事件 无线连接出错的概率很高 目的是为了弥补物理层的缺陷 flow control（流控）：当接收端出现故障、繁忙时停止、暂停传输 停止等待协议：接收端接受完成后发出ACK信号，告知传输完成，可以继续发送 如果帧比较小，效率比较低（传回ack、信号需要一定的时间） 滑动窗口模式：发送方和接收方各有一个固定大小的缓冲区（buffer），用来存储发送或接收的数据。发送方会根据接收方的反馈（ACK）来调整自己的发送窗口（window），即可以连续发送的数据包的数量（还要对帧进行编号）。接收方会根据自己的缓冲区空闲情况来调整自己的接收窗口（window），即可以连续接收的数据包的数量，并通过ACK告知发送方。 总体思路是发送端不断发送窗口内的包，接收端收到后回返回附带包序号的ack，发送端收到ack后对滑动窗口进行平移 错误处理（丢包） go back n：回到发生错误（没有ack）的位置为起点，重新发送（有线网络常用） 只发送缺失的包（无线网络常用） 错误检查和纠正 处理信号衰减、噪声造成的错误，进行纠正 EDC（校验码）为较长则纠错能力强，但浪费相应的也更多 奇偶校验 单奇偶校验：用1位记录有奇数个1还是偶数个1，进行校验 二维奇偶校验： 对每列/行进行计算 可以纠正单比特错误 因特网检验和 将数据的字节作为16比特的整数对待并求和，这个和的反码形成了携带在报文段首部的因特网检验和 ==注意==首项溢出时进位到最后一位 只提供校验，不提供纠错 &&CRC检验算法 称r+1比特模式/生成多项式 能检测小于r+1比特的突发差错 crc中加法减法都不借位，相当于进行异或操作(在计算除法的过程中) 例： 要求（生成多项式）G的第一位必须为1 发送方将R的r个比特附加到D上进行发送，这d+r比特串刚好能被G整除 二、局域网（多路访问链路和协议） token ring 令牌环 数据环形单向传输 有一个token在环形中循环，当一个节点要发送数据时会捕捉token对其进行标记，并在末尾加上数据，放回环形，环绕一周，其它节点发现token被修改并指向自己时会获取其中的信息。循环一周后发送者将一个新的token放回环形 以太网802.3 以太网是全双工的，可以同时收发 链路模式 bus（早期模式），数据公开传播，会冲突 广播因特网 共用频道 发出的包可以被所有终端收到 使用CSMA 通过switch交换机点对点传输，不会冲突 交换因特网 点对点传输，连接端和交换机 不用CSMA 特点： 不需要先建立连接就可以先收发信息 不可靠，发送端不知道接收端是否收到信息，处理不了丢包 不对帧编号（不用滑动窗口） Preamble:7bytes用于同步时钟，1bytes用于指示帧的开始，（唤醒接收适配器） address:6bytes*2 type:2bytes data:max1500bytes，min46bytes crc:4bytes 最小长度为72字节，576比特 MAC地址：48bits 每个网卡有自己固定的mac地址 分割帧： 使用哨兵：01111110表示开始，01111111表示结束 需要防止其它部分出现哨兵，通过在发送端如果发现出现连续5个1就插0，接受时自动删除0 多设备接入控制 一条线路，有多个节点，当多个节点同时发送消息时就会造成冲突 目的：控制节点如何分享共用线路，如何传输 理想 一个节点传输速率为R M个节点平均为R/M 完全分布式，不同步时间；无控制节点 简单 分类 信道划分 TDMA(时间划分)： 缺点：没有使用的时间被浪费了 FDMA(频率划分)： &&CDMA(扩频多址数字式通信技术)： 多路信号只占用一条信道 轮流传输 轮询：存在中心节点，控制其他节点轮流发送传输信息（循环轮流询问是否要发送信息）（蓝牙） 令牌 问题 等待时间长 单点崩溃（master、token）造成系统崩溃 &&随机传输 ALOHA 当节点有消息要发送时就发出，如果发送失败就有p的概率重新发送，1-p的概率等待一会再重新发送 收到信息回复ACK slotted aloha 帧的大小一致 不同节点之间时间同步 发送数据只发生在特定的周期性时间 数据要么传输成功，要么完全冲突损坏 如果冲突了，在之后每个区间发送的概率都是p csma（载波侦听多路访问） 增加对线路的监听，如果线路空闲则发送帧，如果信道繁忙则等待一段时间之后再进行传输 由于传输延迟的存在，仍然会发生冲突 分类： nonpersistencent CSMA 如果繁忙则等待随机长度时间再进行监听 1-persistent CSMA 如果繁忙则持续监听，空闲后立即发送 问题：如果有几个节点同时监听等待发送，则大概率会发生冲突 p-Persistent CSMA（是折中方案） 如果空闲则有p概率立即发送，1-p概率等待一会再发送 假如有N个节点要发送消息，p的最优值是1/N 如果繁忙则保持监听直至空闲 冲突一旦被察觉，相关数据就会被丢弃 发送过程发生冲突会停止发送并发送jam信号（连续几个字节都是1，加强冲突，便于其他设备检测） 这个信号很强，一般可以通过检测信号强度来进行判断 为什么帧data部分有最小长度？ 避免察觉到发生冲突时已经完成该数据的传输 随机等待时间的设定：（现在使用的是1坚持）：二进制指数回退法 过程 对于前10次发生冲突后的等待时间每次是上一次的二倍 之后的6次时间保持不变 16次冲突（失败后）放弃发送信息 补充： 第n次碰撞后随机从（0 1 2...2^n^-1）中随机选一个值作为k（等待时间） k=1表示512比特时间 换算：秒=比特时间除以传输速率 问题：可能造成后进先出（等待时间反而更短） &&效率分析（会有大题） 传输时间/总时间 具体计算 p2p无竞争 1表示传输时延，a表示传播时延，==N表示节点数目== 指线路被征用时间（1+a）中实际在传输帧的时间的占比 ring： 由于求的是最大效率，因此认为token发出后会被下一个紧挨着的节点捕获 两种情况: a a>1,token在传播完成后释放 Pure ALOHA： 感觉2N-2更加合理 slotted ALOHA： 假设N个节点发送消息（都是活跃的），每个节点在每个时隙传输一帧的概率是p（无论是新帧还是发生冲突后重新发送的） 一个给定节点成功传输的概率就是其他节点都不传输的概率p(1-p)^N-1^表示一个节点的吞吐量，任意一个节点传输成功的概率就是Np(1-p)^N-1^ 对p求导，求得极大值：A实际上就是传输效率u CSMA（p型）： contention slots 以冲突结束（认为长度是2a，最坏情况下发现冲突需要2a的时间） contention interval 表示一系列的slots 节点可以成功传播 平均interval长度 先计算的到一个slot成功传输的概率A，然后得到传输成功间隔中（失败的）slot的数目的期望 总时间包括传输时延、传播时延以及两次传播之间的间隔时间（平均次数乘以单次的最大时间） 三、MAC地址 任何一个网卡都有一个固定的链路层地址（MAC地址），硬件决定 subnet mask：子网掩码：用于判断两个网络是否位于同一子网，用于对子网的划分 default gateway：默认网关：处于不同网络段（子网）的两台主机的通信需要经过网关（路由器） ARP（地址解析） 本地（局域网）机器之间的通信 沟通ip和mac（net和link层）（如果知道对方在同一局域网，则用ARP将对方法的ip转化为MAC） *DNS则是把域名（一串文字）转化为ip 过程 本地 发送者先在本地数据库查找，找不到的话则发送查找广播，包含自己ip，mac及目的地ip，接收者收到并确认后进行回复，发送者收到mac信息，存储信息建立映射 远程 DHCP（动态主机配置协议） 自动分配地址 分配ip、掩码，本地DNS 过程： 广播寻找DHCP服务器，服务器收到后广播自身地址，计算机向指定地址的服务器发送请求，服务器为计算机分配资源 释放：DHCP相当于向用户出租资源（ip），当用户不再使用或到达时间限制后服务器会收回资源（release） 异常处理 双方都会进行操作 如果计算机出现问题，DHCP服务器仍然会在到达时间后收回资源 到达时间后计算机找不到DHCP服务器，也会归还资源，重新进行申请 线路损坏，到时间后服务器和主机分分别归还、释放资源（即使不连通） ARP DHCP理念 初始链接使用广播寻找建立 caching，存储一段时间的历史记录 软状态，提高鲁棒性 两种信息发现方式： broadcast广播（在大型网络不适用，局部使用）arp，dhcp *dns数据库模式 四、网络设备 网桥 连接多个局域网（lans），接收来自一个端口的数据帧，存储下来并转发至其他端口（局域网），只转发不对帧进行修改，起到桥接的作用 透明性：其他设备不知道网桥的存在（这与路由器交换机是不同的） 不需要配置，即插即用 帧广播 广播因特网（bus） 会把信息发送到整个网络中，所有节点都会收到信息，当一个节点发现信息的终点为自己时会捕获信息进行处理（MAC地址ff:ff:ff:ff:ff:ff表示信息发送给所有人） 广播风暴（线路出现环） 解决：避免出现环（建生成树） STP算法 输入一个网络（图），输出一个生成树（子图），从而实现去掉环，避免发生广播风暴 先选择一个根节点（一般选择MAC地址最小的） 所有节点选择距离根节点最近的路径 当存在多条最短路径时，选择具有id较小的相邻结点的路径（避免重复选择产生环） 过程 假设每个节点只知道自己的MAC地址，不知道其他节点的联系，通过发送多轮消息逐渐获取信息，最后实现建成生成树 初始时每个节点X都是（X，0，X），即选择自己为根节点，从自己出发，距离为0 向相邻结点发送消息，如果收到消息（Y,d,Z）且Y的id（收到的消息中的）小于该节点的当下的Y的id那么就更新根节点为收到的，一个节点的最短距离就是收到的信息（相邻结点的最短）距离+1。 更新消息，开始新一轮的广播 根节点宕机：让根节点周期性发送消息，从而让其他节点确定根节点是否正常工作 泛洪（建立再生成树基础上） 网桥向所有其他端口发送消息（使网络中所有节点收到消息） 这也是网桥学习了解网络结构的过程 根据收到的信息，可以知道可以通过什么端口连接什么节点 每个网桥维护一个本地数据库，当通过端口X收到帧时（mac，port，time），再数据库中记录通过这个端口可以到达这个发送地址， 即学习发送者的信息 这个记录有时间限制，使用一段时间后会被删除。 收到一个帧时，查看是否在数据库中 转发： 如果数据库中记录目的地的端口，则进行转发 如果找不到则进行泛洪 如果端口和发送端口相同，则不转发，drop数据 例子 hubs physical repeaters 星型结构，所有节点通过两条线连接到hub（transmit和receive） 当一个线路transmit信息时，hub向所有其他线路（receive）进行简单重复消息 速度就是单条线路的最大速率 连接的所有设备处于同一个冲突域 layer 2 switches 一般情况下，普通交换机（非三层交换机）并没有自己的IP地址，它们通常没有网络层（第三层）功能。交换机的工作原理是基于MAC地址表，它学习和维护与各个接口相连设备的MAC地址，根据目标MAC地址将数据帧转发到正确的接口。 connecting Hosts or LANs (bridge functions + collision free) 存储传播帧，接收帧后向1到多个端口转发帧，使用CSMA减少碰撞 每个输入链路上使用以太网协议，但没有冲突； 每个端口/链路形成一个局域网段（没有冲突） 一次可以有多个站点传输 星型结构，节点直接连接到switch 和bridge区别 bridge用于连接局域网（lans)一般端口较少（2-4）而switch连接hosts和subnets有很多接口，并且是无冲突的 和hub区别 具有自学习能力（与桥类似） 传输速率更快（多条不同线路之间可以同时通信） 嵌套 如果存在环的话仍然会发生广播风暴，可以通过生成树避免成环来解决 layer 3 switches involving router（路由器） functions，三层交换机具有路由功能（链路层mac+网络层ip） 硬件上引入ip协议，连接2层次交换机 使用原因 广播过载 由二层交换机连接的一组站点和局域网构成了一个单一的物理网络。所有的节点共享一个MAC广播地址。广播帧会被发送到所有连接到二层交换机的局域网上的站点。在广播情况下，二层交换机变成了集线器（广播造成的，每次都向所有端口进行转发，这就和集线器一样了）。IP在日常工作中会产生很多广播，例如ARP、DHCP、ICMP等。这样会导致网络拥塞和性能下降。 缺少多路连接 两个节点之间只有一条线路（因为是生成树），限制速度和可靠度 解决： 把局域网分成若干个子网，用具有路由功能的交换机（三层交换机）来连接。这样可以限制MAC广播帧只在单个子网内传输，并且允许在子网之间使用多条路径。这样可以提高网络的性能和安全性。 五、无线网 组成 无线设备：手机、电脑 通常具有无线性以及移动性（但不一定） 基站ap：在有线网络和无线网络之间进行转化连接 无线延申（多跳） 把设备接入基站 可以通过多个无线基站逐个桥接实现接入远处的设备而不需要铺设电路（中继） 连接模式 INfrastructure mode(基础设施) 通过基站连接设备，基站之间相互沟通，实现设备转接，防止移动时断网 存在中心（基础信息）保障通讯 Ad-hoc mode 终端设备之间相互通讯，没有中心 特征 信号强度随传播距离逐渐缩减 真空环境下的损失 还会受到周围的环境的影响 评估 SNR：信噪比 信号能量/噪声能量 SNR越高，从信号中分离信号越容易 BER：bit出错率 当终端移动时，信号强度/干扰都会发生变化，需要对通讯进行动态调整，维持SNR和BER在可用的范围内 如当SNR减少时可以通过降低速率来减少BER 多路径传播 多路径传播：无线电信号反射离物体地面，到达广告目的地 时间略有不同 会产生自干扰问题 问题 公开传播，可以被监听 半双工，不同同时发送和接收（因为自干扰问题难以解决） 多设备同时发送接收会带来问题 WIFI 802.11 多个内部BSS连接在一起组成ESS DS 连接BSS构成ESS的交换设备 802.11b: 2.4GHz-2.485GHz划分为不同信道，由AP管理员选择 这个85MHz的频段定义了11个部分重叠的信道（1 6 11是唯一的三个非重叠信道的集合） 搜索和连接 Passive Scanning是指客户端在每个信道上监听AP定期发送的信标（扫描11个信道），而不主动发送任何请求。这种方法通常比较耗时，因为客户端必须等待信标的到来。（被动等待） 每个AP会周期性的发送信标帧，包含AP的SSID和MAC地址。 Active Scanning是指客户端在每个信道上发送探测请求帧，并等待AP回复探测响应帧应答探测请求帧，主机在能够响应的AP中选择进行关联，再发出关联求帧等待关联响应帧（一共需要进行两次请求/响应握手）。这种方法通常比较快速，因为客户端主动寻找AP。（主动请求） 多设备连接问题 这意味着AC相互不知道对方的存在，因而可能同时向B发出信息，从而导致发生冲突干扰（隐藏终端问题） 或由于信号冲突，难以检测到冲突信号 4-frame-exchange解决hidden terminal problem 四步 Source issues a Request to Send (RTS) frame to destination Destination responds with Clear to Send (CTS) After receiving CTS, source transmits data Destination responds with ACK RTS和CTS可以用于避免发生冲突 RTS alerts all stations within range of source that exchange is under way（告知发出者附近的机器即将要发送消息） CTS alerts all stations within range of destination（告诉接收者附近的机器即将发送消息） MAC分布式基础无线媒体访问控制 根据帧间距控制优先级（越短优先级越高） SIFS内容（控制信息） ACK Delivery of multiple frame LLC PDU（逻辑链路控制） Poll response（轮询回应，被轮询的节点响应） CTS PIFS（比普通的DIFS有更高的优先级） 发送polls轮询 AP用PIFS发送指令（具有更高的优先级） DIFS 用于普通的异步流量（不需要实时传输，严格同步的数据） 控制模式 PCF（点协调功能，了解，不常用） 用PIFS轮询设备是否有高优先级的数据要发送（AP发出） 收到轮询响应（有节点要发送数据）后阻止其他节点发出信号造成干扰 优先处理时间敏感信息（非异步） 过程 点协调器按照(AP)轮询（PIFS）的方式向配置了轮询的站点发送询问信号，通知其它站点开始一个超级帧周期。 当询问信号发出时，被询问的站点可以使用SIFS（短帧间隔）来回应。AP可以在信标帧中指定某些站点（时间敏感，高优先级）在特定的时间段内发送数据，这称为轮询列表（polling list）。这样可以避免碰撞和退避时间。 如果在预期的反转时间内没有收到回应，协调器就会发出另一个询问信号。（当轮询列表为空或超级帧结束时，AP发送一个CF-END帧来终止PCF模式，并恢复DCF模式。） 重复这个过程直到当前轮次结束。 超级帧： 先发布高优先级数据， 点协调器不断发布轮询，会封锁所有异步通信量。为了避免这种情况，在超帧时间的前一部分，由点协调器轮询(PCF)，在超帧时间的后一部分，允许异步通信量争用接入（DCF）。 busy medium是指无线局域网中的信道状态，表示信道正在被其他站点使用，不能发送数据。(等待发送完成后再开启下一轮的DCF) 在PCF中，AP通过监听信道来判断是否空闲，如果空闲则等待PIFS（点间隔）后发送信标帧或轮询帧。（AP也需要等待空闲了再发出指令） DCF（分布式协调功能） DCF子层使用CSMA/CA（避免碰撞）机制，即在发送数据之前，站感知媒介是否空闲，避免与其他站点的传输发生碰撞。 DCF包括一些延迟时间，例如帧间隔（IFS），站点在发送数据之前要等待IFS的时间。IFS的长度取决于不同的优先级方案。 由于无线信号的衰减和干扰，无线局域网中很难进行碰撞检测，因此DCF不使用碰撞检测机制。(使用ACK来确认是否成功发送信息) 发送站点在发送数据时很难接收到其他站点的信号，因为接收到的信号很弱，可能被噪声和自身传输的影响所掩盖。 即使能够接收到其他站点的信号，也不能检测到所有可能发生的碰撞，例如隐藏终端问题和信号衰落问题。 802.11策略（CSMA/CA）(DCF) casma/ca与有线网络使用的csma/cd的区别 CSMA/CA全称是带冲突避免的载波侦听多路访问协议，主要用于无线局域网（WLAN）。它的基本思想是在发送数据之前，先检测信道是否空闲，如果空闲，则发送数据；如果忙，则等待一段随机时间后再检测。（增加更多的随机等待，避免高代价的碰撞） CSMA/CD全称是带冲突检测的载波侦听多路访问协议，主要用于总线式以太网。它的基本思想是在发送数据时，同时检测信道上是否有冲突，如果有冲突，则停止发送，并等待一段随机时间后再重发。 两者的主要区别有以下几点： 检测方式不同：CSMA/CD通过电缆中电压的变化来检测冲突，而CSMA/CA采用能量检测、载波检测和能量载波混合检测三种方式来检测信道空闲。（不检测冲突） 信道利用率不同：CSMA/CA协议的信道利用率低于CSMA/CD协议的信道利用率，因为它需要额外的时间来避免冲突。 CSMA/CA：等没有人使用媒体，维持一段时间后，再等待一段随机的时间后依然没有人使用，才送出数据。由於每个设备采用的随机时间不同，所以可以减少冲突的机会。 并且还要使用RTS和CTS处理隐藏终端(由于这个开销太大，通常只对较长的帧使用) 在 CSMAI CD 协议中碰撞并非是一个严重的问题，因为两个站点检测到碰撞后都会放弃它们的发送， 从而避免Z3了由于碰撞而造成的该帧剩余部分的无用发送。 而 802. 11 并不检测碰撞和放弃发送，遭受碰撞的帧仍将被完全传输。（通过ACK判断是否正确传输） CSMA/CA 过程 如果某站点最初监听到信道空闲，它将在DIFS的短时间段后发送该帧 否则，该站点选取一个随机回退值，并且在侦听信道空闲时递减值。 当侦听到信道忙时，计数值保持不变。 当计数值减为 0 时并且空闲，该站点发送整个数据帧并等待确认 如果收到确认，发送站点知道它的帧已被 目的站正确接收了。 如果该站点要发送另一帧，它 将从第二步开始 CSMA/CA 协议。 如果未收到确认，发送站点将重新进入第二步中的回退阶段，并从一个更大的范围内选取随机值。 如果两个站点侦听到信道忙，它们都将立 即进入随机回退，希望选择一个不同的回退值。 如果这些值的确不同，一旦信道空闲，其中的一个站点将在另一个之前发送，并且（如果两个点均未对对方隐藏) \"失败站点\" 将会听到\"胜利站点\"的信号，冻结它的计数器，并在胜利站点完成传输之前一直抑制传输。 通过这种方式，避免了高代价的碰撞。 接收者： 如果成功收到信息，就用SIFS回复ACK 帧格式 address1： MAC address of wireless host or AP to receive this frame(下一跳) address2：MAC address of wireless host or AP transmitting this frame（发送者） address3： MAC address of router interface to which AP is attached（ap的上游路由器） 将host与ap上游的路由器端口jin'xin 例： address方便节点知道数据是从哪里来的，应该如何进行回复 如果一个交换机下有多个AP，那么交换机可以通过H1发出的帧中的add3知道它(H1)连接在哪一个ap下面（路由器会对目的地为自己的包进行学习） 电源管理 当一个节点想要进入睡眠模式时，它会向接入点发送一个消息，告诉它自己将要睡眠，直到下一个信标帧。接入点会知道不向该节点发送帧。节点会在下一个信标帧之前醒来。信标帧包含了等待发送到移动设备的帧的列表。如果有帧等待发送，则节点会保持唤醒状态。否则，节点会再次进入睡眠模式，直到下一个信标帧。（定期） 蜂窝移动网络 cell 包含基站BS（analogous to 802.11 AP） 用户通过BS连接到网络（通过物理层和链路层实现数据传输） 两种分配方案：FDMA/TDMA划分信道，CDMA msc 把cell连接到有线网络 管理传输请求 处理移动性（设备会从一个cell移动到另一个cell） 1g：FDMA，语音通讯专用 2g：初始为语音专用，后拓展因特网支持（2.5g）组合FDM/TDM，先划分时隙再对每个时隙进一步划分频率，承载更多的设备 BSC为用户分配信道，执行切换 MSC用户鉴别、账户管理、呼叫建立等 3g：CDMA 语音/网络分离 4g LTE 同一全ip核心网（淘汰原有的电话语音部分） "},"asserts/网络层.html":{"url":"asserts/网络层.html","title":"U2 网络层","keywords":"","body":"概述 功能 路由选择：决定数据包走怎样的路从出发点到目的地 是指确定分组从源到目的地所采取的端到端路径的网络范围处理过程，路由选择发生的时间尺度长得多 (通常为几秒) 寻路算法 怎样最近（快） 决定了forwarding表（控制如何转发一个数据包） 转发：数据从路由器的一个口进入，从哪个口出去 是指将分组从一个输入链路接口转移到 适当的输出链路接口的路由器本地动作，转发发生的时间尺度很短 时常拥堵需要排队 *（不都有）建立两点之间的连接 在开始传输之前，两个节点之间建立起虚拟连接 服务模型 因特网的网络层提供了单一的服务，称为尽力而为服务 期望 单个包传输 保证传输成功 保证传输时延 安全性。 网络层能够在源加密所有数据报并在目的地解密这些分组，从而对所有运输层报文段提供机密性 一组包传输 有序分组交付（按序到达） 保证最小带宽 保证数据包之间的到达间隔（连续传输到达） ip路由 性能评估（交换容量） 交换容量=N*R N=接（端）口数目 R=每个口的速率 路由器工作原理 入端口 物理层->链路层->网络层 任务： 接收进入的数据包 更新ip包头 寻找通往目的地址ip的出端口 输入排队，如果到达速率大于转发速率。先将数据缓存起来 这种 现象叫作输入排队交换机中的线路前部阻塞HOL 即在一 个输入队列中排队的分组必须等待通过 交换结构发送(即使输出端口是空闲的) ，因为它被位于线路前部的另一个分组所阻塞。 &&快速查表寻址：地址聚合（压缩地址，合并相同方向的地址） 根据范围划分端口，+最长前缀匹配 &&考试给定地址划分，设计树 switching fabric交换结构 把数据包从input传输到output（交换速率） 结构 memory模式（最简单） 交换速率取决于memory的速度，把input的数据保存到memory在导出传输到output bus总线模式 交换速率取决于总线的带宽 不同端口竞争bus的使用 Switching via a Mesh（先进） 使用算法决定通断，进行资源调度 每条垂直的总线在交叉点与每条水平的总线交 叉，交叉点通过交换结构控制器(其逻辑是交换结构自身的一部分)能够在任何时候开启和闭舍。 纵横式网络能够并行转发多个分组。 纵横式交换机是非阻塞的( nonbloeking) ，即只要没有其他分组当前被转发到该输出端口，转发到输出端口的分组将不会被到达输出端口的分组阻塞。然而，如果来自两个不同输入端口的两个分组其目的地为相同的输出端口，则一个分组必须在输入端等待 出端口 Packet classification数据包分类 Buffer management：决定什么时候开始丢包（到达数据量大于发出） Scheduler：决定在什么时候传输哪一个数据包 输出排队 在向输出链路发送一个分组的时间内，将有 N 个新分组到达该输出端口 (N 个输入端口的 每个都到达 1 个) 。 因为输出端口在一个单位时间(该分组的传输时间)内仅能传输一个分组，这 N个到达分组必须排队(等待)经输出链路传输 分组调度（环节输出排队） 最简单：fifo（低端路由器使用） Packet classification 多种分类依据决定优先级 Scheduler 设置几个不同的队列 几种转发先后的决定策略 优先级策略 高一级发送完成了低优先级才能发送 非打断式（非抢占式优先权排队），一个数据传输开始，另一个数据就不能打断（即使是高优先级） 轮询FQ：公平轮流发送（给与每个flow相同的优先级） WFQ加权轮询 排队 若N个输入、输出端口的速率都是R~lilne~，如果R~switch~比它快N倍，则只会发生轻微的排队 输入排队 当交换速度没有输入的速度快时会在输入出现分组排队 即使是纵横式交换，当有两项发往同一个输出端口时也会发生排队，并且排在正在等待的分组后面的数据包也全部会被阻塞（HOL线路前部阻塞） 输出排队 即使快N倍，但如果输出端口相同，会在输出端口处出现排队 Virtual Circuit 虚拟电路交换 Virtual circuit虚电路 预留资源，保证服务 提供连续传输的服务 有保障的服务，switcher需要预留保存信息 普通传输 提供的是单个数据报的传输服务 终端进行“智慧操作”（错误检擦、恢复等），线路只负责简单的传输信息 不建立连接，没有固定的线路，不保证按顺序到达 虚电路服务建立 Each packet carries VC identifier（包上有特殊标记） 中途的路由器等设备都要保存这个”专线“的转发状态，单独分配一些资源 两端交互，建立路线，途中每一个设备都要同一才能成功 VC服务内容 从起点到终点的路径 VCnumber标识（在一条线路不同区段可能不同，因为有不同的运营商） 在路径中交换机forwarding table中的存储 IP协议 地址 地址层次 物理网络地址 用于在单个物理网络内路由PDU（协议数据单元） 因特网地址 IP地址或因特网地址，用于在网络之间路由PDU 每个主机和路由器都有不同的IP地址（可能有多个） 应用地址 分配给目标主机的进程标识符 地址范围 全球地址 一个交换机可能有多个全球地址 Network attachment address 在特定网络范围内每个设备都有不同的地址（如局域网） 端口地址 不是网络层，不同主机、路由器可能不同，在单个设备/系统范围外可以相同（如ssh-22） 地址模式 单拨地址 发向单个系统/端口 广播地址 向一定范围内所有设备发送 多播地址 向指定的多个设备发送 任意拨地址 可以指定一个地址，但是可以有多个实体使用该地址。当数据包发送到该地址时，它将被路由到最近的实体。（负载均衡） IP 功能 路由 主机和路由器维护一个路由表 指明数据报应被发送到的下一个路由器 静态 - 可能包含替代路由 动态--对拥堵和错误的灵活反应 路由策略： 距离向量、路径向量、连接状态 数据包可以指定经过/不经过一些路由器 数据报文生命长度处理ttl 防止出了问题的报文一直在网络中浪费资源（无线循环） 给数据报文标记生命时长，一但到了时间，就丢弃数据包而不是向前传输 Hop count：设置可以转发的最大次数 数据包分解和合并 见后 错误控制 当路由器丢弃数据包时会尝试通知发送源（使用ICMP） 流控 路由器限制数据进入的速率 当buffer已经满了时丢弃掉新进入的数据 可能会通过ICMP告知发送者 两项基本功能 Send 是由上层调用，用于请求传输数据单元； Deliver 是通知上层数据单元已经到达。 包头信息 版本version： 4bits（ipv4中一定是） 记录数据保的ip协议版本 头部长度IHL（internet header length）： 4bits 记录头部的大小（由于可选内容的存在，头部的长度并不是固定的） 说明头部由多少个32位字组成（一行32bits，即4字节） 可选内容的最大长度为40字节 区分服务differentiated services： 8bits（ppt上包含拥塞警告） Precedence字段占3位，定义了8个级别,表示优先级； Reliability字段占1位，表示正常或高可靠性； Delay字段占1位，表示正常或低延迟； Throughput字段占1位，表示正常或高吞吐量。 全长total length： 16bits 定义ip包的总长度（包含头和数据） 标识符 identification： 16bits 用来唯一标识一个包的所有分片（一个包的所有分片具有相同的id）。因为 IP 包不一定都能按时到达，在重组时需要知道分片所属的 IP 包，标识符字段就是一个 IP 包的 ID 。它一般由全局自增计数器生成，每发一个包，计数器就自动加一。 标志flags： 3bits 包含几个用于控制和识别分片的标志位如（禁止分片、更多分片） 分片偏移 fragment offset： 13bits 以8字节为单位 记录分片在数据包中的位置 TTL： 8bits 协议protocol： 8bits 指示传输层协议类型（TCP还是UDP...） 头部校验和Header checksum 16bits 针对头部进行校验（数据部分由tcp/udp等负责处理） IP协议头校验和是IP协议头部的一个字段，用于检查IP数据包的完整性。它是由所有16位字（把头部切分为长度为16的片段）中的补码和计算得出的。如果校验和不正确，则路由器将丢弃数据包。在计算过程中，每个路由器都会重新验证并重新计算校验和，并将其设置为0。这样做是为了防止在计算过程中发生溢出。如果发生溢出，则会将最高位添加到最低位，这可能会导致校验和错误。因此，在重新计算校验和时，将其设置为0可以避免这种情况的发生。 每次都需要重新计算是因为头部会发生变化，比如每转发一次ttl就会减少一 源地址source adddress： 32bits ip包发送方的地址 目的地址destination addression： 32bits 可选片段options 最多40字节 若不是32整数bits倍，用padding进行补齐 数据内容 长度是8bits的整数倍 最大长度（头加上内容）是65535字节 数据包分片处理 一个数据包的长度不能超过MTU（途径设备能处理的最大长度） 分解：在host和router都可以进行 在host处：确定沿路径的MTU的最小值并进行分段。 在router处：当数据包长度超过下一个网络的MTU时，路由器会将其分成更小的片段。 合并：只在host进行 在host（目的地）：当数据包到达目的地时，需要将分片的数据包重新组装成原始数据包。 在router：路由器上重新组装分片是不可行的，因为分片可能会采用不同的路由（路径不同）。 失败控制 合并可能发生错误（比如有子数据包发生了丢失） 当一组数据包中第一个到达目的地时开始计时，如果到达时间限制后仍没有全部到达，则丢弃数据。 同时也在转发次数过多时丢弃包 在进行高层处理之前必须先完成还原！高层头不会被复制，只有ip头会被复制（因此复原后才能正常读取） 合并 需要信息： 单元标识符，用于标识源端系统发出的数据报（判断是不是原先属于同一个数据包） 地址、目的地址、上层协议 数据长度 偏移量（确定分片在原包中的位置）（8octets（64bits）为一个单位） 其他标志mreflag，确定是不是最后一个分片 总结： 当一个IP数据包被分成多个片段时，每个片段都有一个偏移量和长度。在重组时，需要为每个数据包准备足够的缓冲区空间，以便将数据包插入到正确的位置。使用长度和偏移量头字段，使用Moreflags来确定是否到达了最后一个片段，直到整个数据字段被重组。从偏移量为0开始，以moreflags为0结束。 ip地址及分配 IP地址是为了方便路由而引入的，每个物理接口都需要一个单独的地址。IP地址使用点分十进制表示法，其中网络号由美国互联网数字地址分配机构（ARIN）、欧洲互联网数字地址分配中心（RIPE）和亚太网络信息中心（APNIC）进行管理，而主机号则由指定组织内部分配。 分类 A 首位为0 默认子网掩码：255.0.0.0 2^7^-2即126个网段 1.x.x.x~126.x.x.x，不含0和127（用于测试本地网卡） 每个网段支持2^24^-2个主机（全0是网络号，全1是广播号）(这两个地址不一定必须是全0和全1，也可以是别的地址，但必须预留出来) B 首位10 默认子网掩码：255.255.0.0 网段从128.0.x.x到191.255.x.x（八位一组）2^14^个 每个网段2^16^-2个主机 C 首位110 默认子网掩码：255.255.255.0 网段192.0.0.x到223.255.255.x共2^21^个网段 每个网段最多2^8^-2 除了连接到一个路由器的不同设备可能处于同一子网，两个路由器之间连接的两端的两个端口也可能处于用一个子网，形成了几个隔离的网络岛 子网和子网掩码 解决ip地址不充足的问题 IP地址=网络地址+主机地址 网络地址=子网掩码&ip地址，网络地址相同说明处于同一个子网 主机号=~子网掩码&ip地址 划分子网：从原来的主机号里面借了几位拿去做子网号了 二级地址->三级地址 CIDR无分类域间路由选择 三级地址->二级地址 x.x.x.x/n(n表示网络ID的位数)（即自由划分网络号和主机号的位数分配） 一个组织通常具有相同的前缀，减少了路由器转发表的长度 isp层级 NAT 给内部网络和外部网络分配不同的IP集（不同内部网络可以使用相同的ip） 来解决地址不够使用的问题 在出网关时内部地址会被替换为外部地址 三个网段：10、172、192 优点 安全：隐藏内部ip地址（一个外部地址代表了许多不同的内部地址） 使得一个组织有多个不同ip地址（来分配给不同的设备） 便于切换isp（只需要重新配置网关），不需要修改内部设备的配置 分类 静态NAT： 一个内部ip绑定一个对应的外部地址 常用于网络服务器对外提供服务器（给定固定的外部接口，可以方便的更换设备ip） 动态NAT： 动态分配外部ip给内部设备（有一个ip池），谁用分配给谁 Single-Address 只有一个外部ip，所有内部ip对外通讯时都会被进行替换 结合四层次端口，用一个ip传输不同信息（实现对输入的信息发送给特定的设备） 路由器维护一个nat转发表，将外部端口与内部ip绑定，当外部ip向路由器发送信息时，会根据使用的端口向特定的内部设备转发消息 控制性 两个节点连接到服务器挂机（从而使得另外一个节点可以找到该节点，帮助建立p2p连接） ICMP 传递控制、错误消息、ping等 不同功能的包在第一行后面的格式不同 分类 ping 生成icmp包发送等待回复 可以记录传输信息：如传输时延等，传输路径（traceout经过哪些路由器） traceroute原理： 发送TTL依次递增的数据包（到不同路由器时TTL为0，路由器会返回信息，这样可以知道到每个路由器的时间，以及路由器的地址） 可以用于排除网络在哪里发生了中断，排除错误 路由跟踪 查找路径MTU： 发送具有一定大小的数据包，并禁止尽心分片，这样通过对包长度进行二分搜索来确定能通过最大的包大小 不能通过时路由器会返回信息 移动ip 解决设备从一个网络到另一个网络时断开连接的问题 防止上层应用发现网络发生了变化 由于系统移动会切换ip，通过转发伪装还在原来的位置 实现 包含一个移动节点和一个与其通讯的设备 由于安全性问题现在往返都使用转发，不用三角模型了 发现discovery 移动节点发现它是否在家庭网络中或外出。如果它在家庭网络中，则不需要采取任何措施。如果它在外面，则需要找到家庭网络的Home Agent。 路由器发送ICMP告知是否有这项服务 移动设备向路由请求服务 注册registration 移动节点向Home Agent注册，并告诉Home Agent它的当前位置。Home Agent将此信息存储在移动节点的注册表中。 步骤： 节点向外部网络请求服务 外部网络向家庭网络发送请求 家庭网络进行答复 外部网络把结果返回给节点 隧道tunneling 注册之后就建立起了隧道 家庭代理广播无偿ARP请求，将移动节点的IP地址绑定到家庭代理的MAC地址上 家庭代理接收到发送到移动节点的数据包，并通过IP隧道将数据包转发到外部代理 与移动节点连接的设备认为移动设备仍然从家庭络回复信息，也会继续把包发向移动设备 因此再不改变移动设备ip（通过隧道转发）下维护了连接 ipv6 128bits 包头 长度固定，为40字节 Version (4 bits)：值为6 Traffic Class (8 bits)：QoS 为了区分不同的数据流而设置的一种标识。 用来区分不同的服务类型，如语音、视频、数据等。 在IP协议中，Traffic Class被用来标识数据包的优先级，以便路由器可以根据优先级对数据包进行处理。 Traffic Class的值可以由源、转发器和接收方进行更改，因此上层协议不应该假定数据包中Traffic Class的值没有被更改 Flow Label (20 bits)：流标签 flow 网络流是指在网络中，从源节点到汇节点的一组流量，它们共享相同的特征，如路由、资源分配、丢弃要求、计费和安全等。 从主机的角度来看，流是由一个应用程序生成的，并具有相同的传输服务要求。可能包括单个或多个TCP连接。一个应用程序可以生成单个流或多个流。 从路由器的角度来看，流共享影响路由器如何处理这些数据包的属性，例如路由、资源分配、丢弃要求、计费和安全等 label 一个流被发出地址、目的地址、flow label唯一确定 flow label在开始传输前就确定下来 路由器只需要检查flow label结合存储的flow label就知道如何转发包 可以给某些数据得传输更高的优先级 Payload length (16 bits)有效载荷长度：包括所有扩展头以及用户数据(不含ip头) Next Header（8 bits）：标识下一个头部的类型，扩展或上一层 hop limit(8 bits):与ttl类似 Source / Destination Address (128 bits) ​ 扩展头 Hop-by-Hop Options（逐跳选项）：需要在每个路由器上进行处理的选项。这些选项可以包含一些需要在数据包传输过程中每一跳都进行处理的信息。 Routing（路由选项）：源路由选项，用于指定报文的传输路径，即源节点指定报文应该经过的中间节点列表。 Fragment（分片选项）：源分片选项，用于在发送端进行分片，将较大的IPv6报文切分为较小的分片，以便在网络中传输。 Authentication（认证选项）：提供对IPv6报文的认证机制，确保报文的完整性和身份验证。 Encapsulating Security Payload（封装安全载荷选项）：提供对IPv6报文的加密和完整性保护。 Destination Options（目标选项）：在目标节点处理的选项。这些选项可以包含一些目标节点需要处理的信息。 其他改变 路由器不再负责分片（改为由host负责） 如果一个IPv6数据包太大，无法通过下一跳，则会发送一个“数据包太大”错误消息。这是一个ICMPv6消息过滤ICMPv6会导致问题。 广播 ipv6不再有单独的broadcast地址，而是使用包含所有节点的组进行多拨来实现。 广播缺点： 实际上只有一少部分需要接收信息，但是唤醒了所有节点 会产生广播风暴 Neighbor Discovery 不使用ARP，使用Neighbor Discovery Uses ICMPv6、Multicast 取消首部校验和 ipv6地址 优势 128位 多播地址的可扩展性 任意广播--传递给一组节点中的一个节点 地址自动配置 在IPv6头和传输层头之间分离出可选的头 大部分不被中间路由器检查 更容易扩展选项 取消校验，进一步减少每个路由器的处理时间 更有效、更强大的移动性机制 更加安全： 内置的、强大的IP层 加密和认证 融合（ipv4->ipv6） 不是所有的路由器都能同时升级 两种建议的方法 双栈 - 一些具有双栈（IPv6、IPv4）的路由器 可以在不同格式之间进行转换 隧道--在IPv4数据报中以有效载荷形式传输IPv6 在IPv4路由器之间 路由基础 使用路由表决定到达的包的出口 目标: 效率：经过最短（少）的路（交换机） 鲁棒性：当线路、交换机负载过高时正常工作 稳定性：在一定时间内指的路相对固定而不是快速变化 把网络拓扑抽象成有向图 同一条路不同方向的代价可能不同（如负载不同） 考虑因素 性能评估 多种cost计算方法 决策时间与位置 时间 普通：在packet到达路由器后查表转发 vc虚电路：在发送时（建立vc）决定线路 地点： 中央服务器计算决定 在（发送）源决定 （最多用）分布式决定：由每个路由器自己决定 信息来源 路由器自身的信息 相邻路由器的信息 网络中所有路由器的信息 信息到达时间 动态路由选择算法 周期性更新（始终发生更新） 网络结构发生重大变化时更新（如故障） 更容易受诸如路由选择循环、路由振荡之类问题的影响 固定，不自动更新，由管理员手动进行更新（静态路由选择算法） 路由算法 集中式 如链路状态 (Link State , LS) 算法 用完整的、全局性的网络知识计算出从源到目的地之间的最低开销路径 当网络发生重大改变时重新计算并下发 分布式算法 路由器以迭代、分布式的方式计算出最低开销路径 ，没有节点拥有关于所有网络链路开销的完整信息，仅有直接相连的链路的信息 如距离向 ( Distance-Vector, DV) 算法 flooding 收到数据包后发送到除了发送端口以外的全部端口，最终会有一系列的（相同）数据包到达目的地 用于相对简单的网络 可以用于控制平面的信息交互 鲁棒性很高，只要发送节点和目的节点是连通的，就能发送成功 至少一个包经过最短路径到达目的地 可以用于建立虚电路 问题： 创建了一个包的多个副本 容易产生环路问题（使用ttl解决） random 不需要网络信息 从除了发送端口以外的其他端口随机发送 适用于连通性很强的网络（邻居节点很多） 选择是不固定的、具有随机性，这是random的根本特征 adaptive(自适应路由) 需要网络信息 致力于拥塞控制 网络发生变化时路由选择也会发生变化 综合考虑到目的地距离和排队情况，使用距离加上排队情况得到权值 两个最小路径算法 dijkstra's单源最短路径 过程： &&例 复杂度O(n^2^) 问题：可能不稳定，发生震荡 在网络中，路由算法的目的是为了找到从源节点到目的节点的最佳路径。在某些情况下，当路由算法选择了某个路径后，该路径的负载会随着时间的推移而增加，导致该路径的成本增加。当其他可用路径的成本变得比当前路径更低时，路由算法将会选择其他路径。然而，这可能会导致原先负载较高的路径成本降低，使得该路径再次成为最佳路径。这种情况下，路由算法又会重新选择该路径，如此循环往复，就导致了路由算法的震荡。 解决： 让一些流量留在负载较重的链路上，以平衡流量 应用链接利用率来表示链接的状态。 基于先前值和新的利用率进行平衡。 使用跳数归一化指标来计算链接成本。 就是在路由计算中考虑链路的负载情况，并根据链路的利用率进行平衡，同时使用跳数归一化指标来计算链接成本。这些方法可以降低震荡问题的发生，从而提高路由计算的性能和稳定性。 让路由器不同时运行LS算法进行更新 bellman-ford1 每个节点各自维护一个表 枚举路上的最大节点数目 步骤 &&例 收到其他节点上一阶段的表，更新自己这一阶段的表 cost变化对算法的影响 当网络中的链路成本发生变化时，路由协议需要对此做出响应并重新计算最短路径。当一个节点检测到本地链路成本的变化后，它会更新自己的距离向量，重新计算到其他节点的距离，并将更新的信息通知给它的邻居节点。 当链路成本发生变化时，节点之间的距离信息需要经过多轮传递才能收敛，这可能会导致距离信息的不稳定，进而导致网络性能的下降。 例; t0时刻，节点y检测到本地链路成本的变化，它更新自己的距离向量，然后通知它的邻居节点。 在t1时刻，节点z收到节点y的更新信息，更新自己的距离向量，并向它的邻居节点发送更新信息。 在t2时刻，节点y收到节点z的更新信息，更新自己的距离向量，但是因为节点y的最小成本没有发生变化，所以它不需要向节点z发送任何信息。 这样，网络中的所有节点都能够及时地响应链路成本的变化，并重新计算最短路径，从而保证网络的高效性和稳定性。 由于“good news travels fast”， bad news travels slow，信息具有一定滞后性，如节点都将数据涌向空闲的线路，导致空闲的线路变成繁忙的，可能会产生count to infinity问题 遇到路由 选择环路 routing loop) ，即为到达x，y通过z路由，z又通过y路由。路由选择坏路就像 一个黑洞，即目的地为x的分组在t1时刻到达y或z后，将在这两个节点之间不停地来回反复。直到 终算出它经由 的路径开销大于 50 为止，此时将(最终)确定它到x的最低开销路径是经过它到x的直接连接，y将经由z路由选择到x。关于链路开销增加的 坏消息的确传播得很慢!如果链路开销 c(y，x) 变为 10000 且开销 c(z，x) 9999 时将发生什么样的现象呢?由于这种情况，我们所见的问题有时被称为无穷计数( countto-infini ty )问 因此，路由选择协议通常采用一些措施来避免这种情况的发生，例如拓扑分离、路由毒化等。 毒性逆转（是一种路由协议中常用的策略，用于解决距离向量路由协议中出现的\"count to infinity\"问题。这种策略的核心思想是，在发生链路成本变化时，如果一个节点要通过它的邻居节点(如 z-w-y-x中y会告诉w无穷大，但不会告诉非直接相连的z)来到达某个目的地，那么该节点会将到达该目的地的距离设置为无穷大（来针对这个邻居节点防止被选择），这样可以防止邻居节点将数据包发回给它。具体来说，当某个节点Z需要通过邻居节点Y到达目的地X时，它会向节点Y发送一条信息，告诉它到达目的地X的距离是无限大。这样一来，如果节点Y想要到达目的地X，它就不会再通过节点Z了，因为节点Y知道它通过节点Z到达目的地X的距离是无限大，不会再选择这条路线。毒性逆转策略能够有效地减少路由环路的出现，从而避免距离向量路由协议中出现的\"count to infinity\"问题。 例： 算法对比 Link State算法是计算网络中的最短路径的一种分布式算法。每个节点会将其它节点的信息广播出去，通过收集其它节点的信息来计算最短路径。这种算法的优点是计算结果较快，并且能够自适应网络的变化，但是需要较多的网络带宽和计算资源。 Distance Vector算法是计算网络中的最短路径的一种分布式算法。每个节点会向其它节点广播自己的距离向量，包括它自己到其他节点的距离以及其他节点到目的节点的距离。通过不断地更新距离向量来计算最短路径。该算法的优点是计算结果较快，但是在存在网络环路的情况下可能会出现问题（无限跳），需要采取一些特殊的处理方式。 信息传递： Dijkstra： 节点会将信息flood到所有连接的节点，每个节点都维护整个网络拓朴，根据算法建立自己的routing table 不能处理负权图 Bellman-Ford： 每个节点维护一个距离向量（关于知道的点） 直接相连的点之间传递距离向量来更新路径和花费 分布式的方法建立路由表 | | DK（全局、集中信息） | BF（分布、局部信息） | | ------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------------------- | | 消息复杂度（节点之间发送的消息数量） | n nodes, e links, O(ne) messages（每个点都需要知道所有边的开销） | Depends on convergence time | | 速度 | O(n2) and quick; May have 震荡 | Slow and depends on changes; May contain routing loops | | 鲁棒性（节点故障） | 节点故障可能会导致错误的直接链路成本广播，但错误范围受到限制。 | 错误节点可能会交换错误的路径成本，错误可能会通过网络传播。 | 代价计算 第一阶段是1969年，ARPANET刚刚创建不久。在这个阶段，输出队列长度被用来定义一个链接的成本，并且使用Bellman-Ford算法进行路由。第二阶段是在1979年，此时ARPANET已经发展成为一个更大规模的网络。在这个阶段，测量延迟被用来定义链接的成本。路由使用Dijkstra算法。 延迟=重新传输的时间-数据包到达的时间+传输时间+传播时间 排队模型计算： 链路的利用率：（给定时间内链路上传输的数据量与链路的总传输能力之比） ρ = 2(Ts − T)/(Ts − 2T) T是当前测量的延迟 Ts是平均数据包长度/链路的传输速率 平滑化（leveling） Un = α×ρn+(1–α)×Un–1 Un：– leveled link utilization at time n α – constant, now set 0.5 路由协议 问题 规模问题：有200 million destinations，目的地太多，不能在一个路由表中存储全部的目的地（不可能在一个路由器中存储整个因特网的拓扑结构！），收敛速度太慢！ 管理自治问题：因特网是将许多子网连接在一起，子网可能想管理自己内部的路由，对外部隐藏一些内部的信息 层级路由管理 把路由器按照区域（自治域AS）进行划分 AS：一个路由、网络的集合，它们在互联网上被视为一个单一的单位，由单个组织/isp进行管理 在同一个AS中的路由运行相同的路由策略策略 每个自治系统在互联网中都有一个唯一的自治系统号码，16/32位 在任何两个节点之间至少有一个路由 网关路由： 负责路由到AS外目的地的路由器 它们运行与其他网关路由器的自治系统间路由协议，并与AS内的路由器运行自治系统内路由协议 是一个自治系统与外界通信的关键设备 一级之间互联，与center互联 二级之间互联，与一级互联 大型互联网公司与多个运营商相连，如图中中央部分的AS 内部/外部路由协议 “Perform inter-AS routing amongst themselves”意味着不同的自治系统之间的路由器之间需要执行路由选择协议，以便它们可以找到最佳的路径将数据包从一个自治系统传递到另一个自治系统。 而“Perform intra-AS routing with other routers in their AS”则意味着自治系统内的路由器需要执行路由选择协议，以便它们可以找到在自治系统内传递数据包的最佳路径。这个过程称为自治系统内部路由选择。 IGP (Interior Gateway Protocol): for Intra-AS routing IGP用于在AS（自治系统）内部进行路由选择，它在路由器之间传递路由信息，可以专注于性能，而不需要考虑其他AS的路由算法和表格（可能不同）。 RIP是一种距离向量协议，用于测量距离并选择最短路径。 OSPF是一种链路状态协议，它使用链路状态数据库中存储的拓扑信息来计算最短路径。 IGRP是思科公司专有的自治系统内部路由协议。 EGP (Exterior Gateway Protocol): for Inter-AS routing EGP用于在AS之间进行路由选择，因为路由器需要了解其AS之外的网络情况，它支持关于可达性的摘要信息。在这种情况下，策略可能会优先于性能。（要兼容） BGP是一种边界网关协议，用于在不同自治系统之间传输路由信息。 EGP要求的特性： 不同的AS可能会使用不同的指标和有不同的限制； 最关心的是通过了哪些AS（isp） 并不是所有子网都需要被所有路由器知道； 距离向量协议无法提供有关经过的AS的信息； 链路状态协议将链路状态信息泛洪到所有路由器中不可控 所以：链路状态协议（Link-state protocol）和距离向量协议（Distance-vector protocol）。它们被用于AS内的路由，但是对于连接不同AS之间的路由，它们并不适用。 EGP协议： 让每个网关路由器向邻居广播到达目的地的完整路径。每个信息块列出了在路径上经过的所有自治系统。这样，网关路由器可以执行策略路由，避免经过特定的自治系统，尽可能减少经过的自治系统数量。此外，该协议还可以考虑其他因素，如链路速度、网络容量、易拥塞程度、总体运营质量和安全性等。 路由协议 正在使用： RIP 使用dv 即通过跳数（最大15跳）来衡量网络中不同节点之间的距离 后来使用队列长度代替hop来衡量距离 每隔30秒，路由器会向相邻的节点发送一条RIP更新消息，其中包含了距离向量信息。 如果在180秒内未能接收到更新消息，则说明与相邻节点的连接已经断开。 每个更新广告中最多可以列出25个目标网络。这些广告会通过UDP数据包进行发送。 策略上与bf算法类似 例: OSPF 替代了RIP 使用Link-State routing algorithm替代dv 在该算法中，每个路由器都会维护与相邻路由器之间的链路状态列表，并定期向整个自治系统广播状态信息（即广告），以便其他路由器更新其路由表。 这个广播过程称为泛洪（所有其他路由器），每10秒进行一次。LS算法使用一个成本度量值来评估每条链路的开销，这个度量值通常是链路带宽、延迟等因素的综合。 广告消息直接通过IP协议传输，而不是UDP协议。 每个节点都存储了一个有向图，用于描述该节点的相邻节点和它们之间的连接方式。 节点分为路由器节点和网络节点（过渡节点和Stub节点）。边分为路由器之间的边和路由器与网络之间的边。为了计算出到每个目的地的最短路径，使用了Dijkstra算法，确定spf（以自身为根节点到所有子网的最短路径树 ）。 每条链路的具体开销是由管理员设定的 目的地：Networks（N）, hosts and BGP(H) routers(R) 操作过程： &&网络中的每个路由器都计算出到所有目的地的最短路径树（SPF tree），并使用这些路径来转发数据包(使用dj单源最短路径算法) SPF树可以通过使用路由协议中的链路状态信息来计算。在OSPF中，每个路由器通过发送链路状态广告（LSA）来描述与其相邻的所有链接。这些LSA被所有OSPF路由器接收并用于计算SPF树。在RIP中，每个路由器发送其已知的路由表，其他路由器将它们的路由表合并到自己的路由表中，然后使用这些信息来计算SPF树。 一旦SPF树被计算出来，每个路由器都可以使用该树来选择到目标的最佳路径，这是通过选择SPF树中的最短路径来完成的。当一个路由器决定了它的最佳路径，它会将该路径作为下一跳来发送数据包。 优势： 安全性：OSPF使用身份验证来防止恶意入侵。 允许多条相同代价的路径：OSPF支持在相同代价的多条路径之间进行负载平衡。 支持不同类型的服务类型（TOS）：对于每个链路，可以为不同的服务类型设置多个代价指标。例如，可以将卫星链路的代价设置为“低”，以获得最佳的尝试，而将其设置为“高”，以获得实时传输。 集成的单播和多播支持：OSPF集成了单播和多播的支持。 大型域中的分层OSPF：在大型域中，可以使用分层OSPF来减少网络复杂性。层次化的配置多个区域。 区域划分Hierarchical OSPF-提高可扩展性： 每个区域由一个32位的区域ID进行标识，该区域内的路由器只知道该区域内的完整拓扑信息，从而限制了链路状态信息向其他区域的洪泛。 区域边界路由器可以对其他区域的信息进行汇总，从而实现跨区域的路由信息传播。 每个区域都必须与骨干区域（仅有一个）（0.0.0.0）相连（用于连通其他下层区域），以便在区域之间传播路由信息。通过分级的方式，有效地减少了 OSPF 网络中链路状态信息的洪泛，从而提高了网络的可扩展性。 路由器分类： Internal router 是指只有连接到同一区域内的网络的路由器，它们只知道区域内的拓扑信息。 Area border router 是指连接不同 OSPF 区域的路由器，它们会汇总所连接区域内的路由信息，将其广播到其他区域的 Area border router 中。 是位于两个或多个区域边界上的路由器，它连接不同的区域并负责交换LSA信息。 Backbone router 是指连接 OSPF 各个区域的骨干路由器，它们会将所连接区域内的路由信息汇总，然后再将其广播到各个 Area border router 中。 是负责运行在骨干区域的路由器。BBR处理在骨干区域内的所有路由信息，负责与其他骨干区域路由器之间的路由交换。 AS boundary router 是指 BGP 中的路由器，主要是负责将 OSPF 内部的路由信息发送到其他 AS（虽然ospf进行了分区，但这还是在同一个AS中！） 中。 广告分类： Router Link Advertisement（路由器链路广告）：由所有OSPF路由器生成，包含了在该区域内所有路由器的链路状态信息，仅在该区域内部进行广播。 Network Link Advertisement（网络链路广告）：由指定路由器（DR）生成，列出了连接到该网络的所有路由器的ID，仅在该区域内部进行广播。 Summary Link Advertisement（汇总链路广告）：由区域边界路由器（ABR）生成，概括了来自其他区域的路由信息，用于跨区域的路由，仅在本区域内和相邻的区域进行广播。 AS External Link Advertisement（AS外部链路广告）：由AS边界路由器（ASBR）生成，描述了到达OSPF网络之外目的地的路由，被洪泛到所有的区域。 BGP AS希望自由的自主选择路由（传输过程）、自主性、隐私性(保密自身的信息，如拓扑结构) &&AS之间的关系 customer\\provider(给钱)，peer（互助型，不互相给钱） 差距三倍以内认为几乎相等，才能构建peer peer的目的：省钱 前提：peer双方都能从中受益 物理上通，商业上不一定通，这是商业策略的结果 一个由多个自治系统（AS）组成的网络，每个AS都有一个唯一的标识符，并使用BGP协议进行自治域间路由。在网络拓扑图中，IP前缀被分配给目标，而AS被表示为节点，而链接则表示物理链接和业务关系。由于AS的内部是隐藏的，因此网络拓扑图中只显示自治域间的路由信息。 基本idea： An AS advertises (“exports”) its best routes to one or more IP prefixe 这个广播是有选择的，选择广播哪些，不广播哪些 Each AS selects the “best” route it hears advertised for a prefix 其他节点对路径的选择也是自主选择 BGP与DV 它不需要将整个网络的拓扑信息集中在一起，而是在每个目的地处计算出最佳路径。这种方法可以使网络更快地收敛，并且不需要大量的计算和存储资源。 区别： 不一定选择最短路径： 会根据策略选择最好的路径，而不是最短的路径 BGP是一种路径矢量（Path-Vector）路由协议，而DV是一种距离向量（Distance-Vector）路由协议 路径矢量路由协议的关键思想是广告整个路径，这样每个路由器都可以了解整个网络的拓扑结构，并可以通过该信息做出更好的路由决策。距离向量路由协议的关键思想是发送到达目的地的距离度量值，这样每个路由器可以通过这些度量值选择最短路径来转发数据包。 除了距离外还想知道更多的信息 优点： 可以避免回路 基于整个路径的灵活有利的策略 有选择的路径广告 出于各种原因，as可能选择不向某个目的地广告某条路由，因此即使图形物理上已连接，可达性也不能得到保证。 BGP可以将一组具有相同前缀的路由汇总为一个路由 减少了需要交换的路由数量，提高了路由交换的效率和可扩展性。 BGP协议细节 BGP协议是由AS中的边界路径来使用的 规定了：与其他BGP“speaker”交换的消息，消息类型（例如路由广告，更新），消息语法，以及如何处理这些消息。 BGP分类： eBGP： eBGP是指处于不同自治系统（AS）之间的边界路由器之间的BGP会话，其目的是学习到外部目的地的路由信息，以便最优地转发数据包到不同的AS中。 iBGP： iBGP是指处于同一个自治系统中的边界路由器和其他路由器之间的BGP会话，其目的是在AS内部分发外部学习到的路由信息，以便实现内部路由的可达性。 在一个自治域内部，如果有多个边界路由器与不同的外部AS相连，这些路由器之间必须使用iBGP协议来分发学习到的外部路由信息，以确保自治域内部的所有路由器都具有完整的路由信息。iBGP协议确保自治域内部所有路由器之间的路由信息同步，并且避免出现路由环路等问题。 IGP： IGP是指“Interior Gateway Protocol”，即自治域内部的路由协议，如OSPF和RIP等，其目的是为自治域内部的所有路由器提供内部可达性，使数据包能够在自治域内部进行正确的路由选择和传输。 总结： 首先，自治域内的边界路由器会使用eBGP协议来学习到外部AS中的路由信息，以便知道如何将数据包发送到外部目的地。然后，边界路由器之间使用iBGP协议来分发和同步学习到的外部路由信息，以确保自治域内的所有路由器都具有完整的路由信息。 最后，自治域内的所有路由器都使用IGP协议（如OSPF或RIP）来确定到达目的地的最短路径，即通过自治域内部的网络设备来确定到达目的地的下一跳路由器，并将数据包发送到该下一跳路由器。这个过程会一步步地进行，直到数据包到达自治域的边界路由器，然后通过eBGP协议将数据包发送到目的地的外部AS中。 BGP的实现 路由属性: 路由是通过属性来描述的。这些属性用于路由的选择和导出决策，即帮助路由器选择应该发送到其邻居的路由，以及如何向外传播路由。 BGP中的路由属性可以分为本地属性和全局属性。本地属性是仅在本地AS中使用的属性，不包括在路由公告中。全局属性则会随着eBGP路由公告一起传播。 具体属性： ASPATH： 是全局属性，在BGP路由公告中被携带，并以反向顺序列出所有经过的AS。 可以防止环路：如果一台路由器在路径列表中看到包含自己的AS，将拒绝该通告 使得目标BGP路由器可以了解到路由是如何到达它们的，从而进行合理的路由选择和策略制定。 LOCAL PREF： LOCAL_PREF属性是本地属性，仅在iBGP消息中传递，不会被传播到其他AS中。是要发送信息的as内部的属性，用于指定想要的路由路径（即经过哪些AS）。 在BGP路由选择中，LOCAL_PREF属性通常是第一优先级。当有多条AS路径到达同一目的地时，BGP路由器将优先选择LOCAL_PREF值最高的路径。 MED： 用于在存在多个出口的情况下选择到达目的地的最优路径。 是转发的AS所宣布的，即以何路径从一个AS到另一个AS（当存在多条线路时） 指定了前缀到达该出口的距离，这有助于选择到达目的地的最短路径。 MED属性的值由AS宣布前缀的路由器设置，它是一个非强制性属性。当一个AS有多个出口时，MED属性可以告诉其他AS它希望通过哪个出口传递数据，也可以用于将流量分布到多个链接上。 IGP cost： 每个路由器根据内部域协议中的路径成本选择最近的出口点。IGP cost属性携带在BGP更新中，用于影响BGP的路径选择。当存在多个出口点以到达目标时，路由器选择距离目标最近的出口点，即IGP成本最小的出口点。 它是通过在自治系统内使用内部网关协议（IGP）来计算的，因此在整个自治系统内是可见的。每个路由器都使用IGP成本选择最近的出口点来路由数据包。因此，IGP成本对于自治系统内的所有路由器都是相同的。 信息传递： Open消息用于在两个BGP对等体之间建立BGP会话，并且在该会话上使用TCP协议进行数据传输。 Notification消息用于报告不寻常的状况，如错误或异常情况，以便另一端的BGP对等体可以采取相应的措施。 Update消息用于向邻居通知新的路由信息或者已经失效的路由信息，以便邻居可以更新其路由表。 BGP协议中的路由更新消息包括一个IP前缀和一组路由属性。路由属性描述了路由的各种属性和特征，例如路由的度量值、来源、下一跳等。\\ 分类： Announcement指的是新路由或对现有路由的更改，这些更新将被发送到BGP邻居中。 Withdrawal消息指的是移除已经不存在的路由，也会被发送给邻居，以便邻居可以更新其路由表并删除已经不可达的路由。 Keep-alive消息用于向邻居发送一个空的BGP消息，以便让邻居知道连接仍然有效。这有助于避免连接因长时间不活动而被认为是失效的情况。 *路径决策过程 AS Path：BGP路由器会检查AS Path属性并选择具有最短AS Path的路径，因为这通常意味着这是最直接的路径。 LOCAL_PREF：如果AS Path相同，则BGP路由器将比较LOCAL_PREF属性，并选择具有最高LOCAL_PREF值的路径。 MED：如果两个路径来自同一个AS，并且AS Path和LOCAL_PREF相同，则BGP路由器将比较MED属性，并选择具有最低MED值的路径。 IGP cost：如果上述三个属性都相同，则BGP路由器将使用IGP cost属性来决定路由路径。它将选择到最近egress点的路径。 ip多播 分类： 多播可以发一份（一个操作）到达不同目的地，效率高： 应用： 电视广播 电话会议 数据库应用，如一个数据库同时为多个模型的训练提供信息 分布式计算 定义： multicast group：接收组的集合 source：发送者 receiver：接收者 服务模型 当一个主机加入一个组播组时，它会通知本地路由器，告诉路由器它要接收该组的数据包。路由器会记录哪些主机已经加入了哪些组播组，并在收到组播数据包时，将数据包转发给那些已经加入了该组的主机。 多播地址 ipv4使用D类ip表示，一个地址表示一组（多个）目的ip地址 ipv6: 8 bit prefix, 4 bit flags, 4 bit scope, 112 bit group identifier 地址转换（IP multicast address and multicast MAC address) 组播mac地址的高24bit为0x01005e，mac 地址 的低23bit为组播ip地址的低23bit。 通过将组播IP地址的低23位与固定的MAC地址前缀进行组合，就可以得到对应的组播MAC地址。 IGMP组播 建立 本地主机可以通知多播路由器告知要加入某个组 多播路由器相互交互，构建多播树 过程： 主机发送信息加入、退订一个多播组；离开不一定立刻完成（如轮询时发现要退出） 路由器周期性的询问主机都是否还要在某个组里（不回答就是退出） 两个特殊地址： 224.0.0.1: all multicast groups on subnet 224.0.0.2: all routers on subnet 每个子网中只需要选出一个路由器来作为querier（询问者） Querier periodically sends a Membership Query message to 224.0.0.1 with TTL = 1 回复时，每个节点给与每个组一个随机的发送时延（0-10s），计时结束后发送，如果一个节点发现别的节点发送了，则不再重复发送，这样可以减少开销 询问分类： “General query”是对所有组播组的查询 “Group-specific query”是对特定组播组的查询 “Group-and-source specific query”是对特定组播组和源的查询 版本 IGMP v1： 每次都广播询问所有组的订阅情况 主机只发送要加入的组，通过不回复来表示离开某个组 IGMP v2： 可以询问单个组的使用情况 允许主动发送消息主动离开组 问题：（1&2） 发送源的位置是未知的，每一个主机都可发送信息到任何一个组 多播树的建立存在问题 多播的垃圾邮件问题 寻找全球唯一的组播地址很困难 IGMP v3 允许接收主机设定一个源列表（只接受来自列表中的源的信息），其他的会在路由器丢弃 允许主机阻止来自来源的发送不需要的流量数据包。 表头 询问 Type (8 bits): 数据包类型，0x11 表示查询数据包。 Max Response Time (8 bits): 接收方在发送响应前的最长（随机）等待时间，以 1/10 秒为单位。 Checksum (16 bits): 数据包的校验和，采用和 IPv4 相同的算法。 Group Address (32 bits): 查询的多播组地址，若为通用查询，则为 0。 S Flag (1 bit): 是否抑制接收方常规的定时器更新操作，1 表示抑制。 QRV (querier's robustness variable) (3 bits): 发送查询的路由器鲁棒性变量，用于确定重传次数以确保报告不会被漏掉。 QQIC (querier's query interval code) (8 bits): 查询间隔代码，指定发送多个查询的时间间隔。路由器可以采用最近收到的 QI 值。 Number of Sources (16 bits): 源地址的数量。 Source addresses: 源地址，每个地址使用 32 位无符号整数表示。如果有多个源，则会有多个地址字段。 回复 Type (8 bits): 报告消息类型，0x22表示这是一个IGMP报告消息。 Checksum (16 bits): 检验和，用于检验IGMP报告消息在传输过程中是否出现错误。 Number of Group Records: 组记录的数量，即这个报告消息涉及到的组的数量。 Group Records: 每个组记录对应一个组 Record Type (8 bits): 记录类型，有三种：0x01表示该组仅仅是一个模式匹配，0x02表示该组是属于特定主机的，0x03表示该组是共享的。 Aux Data Len (8 bits): 辅助数据长度，表示附加到此记录中的数据的长度（单位：字节）。 Number of Sources (16 bits): 源的数量，即加入此组的主机数量。 Multicast Address (32 bits): 多播地址，标识一个特定的组。 Source Addresses: 源地址列表，表示加入此组的所有主机的IP地址列表。如果Number of Sources为0，则该字段为空。 ipv6中的多播 igmp被整合到了icmpv6 包含icmpv4和idmp的全部功能 包括组成员查询和组成员报告消息，这些功能与IGMPv3一样被使用。 多播路由 多播树 多播树：构成最小费用树连接所有节点（发送者、接收者） 路由器要知道多播组的存在；知道哪些端口连接着目标组（中的节点）； 分类： 共享树：（共享一个生成树） 每个（发送至）源构建不同的树： 构建 确定多播数据包应该发送到哪个接口 每类树都有两种构建方法 Shortest Path Trees 使用dijkstra算法，找到从源到全部接收者的最短路径树 used with OSPF &&Reverse Path Forwarding Used with RIP 建立在路由器知道到每一个发送者（节点）的最短路径的前提上 基本思想是：当一个路由器收到一个多播数据包时，它将检查其路由表中是否存在最佳路径来到达数据包的源地址。如果该路径存在，则认为数据包是从最短路径到达该路由器的，并将数据包转发到其出站接口（泛洪到所有其他接口）。否则，该路由器将丢弃该数据包。 通过构建反向树来确定多播数据包的最佳路径。这个反向树的构建是基于每个路由器维护的路由表信息，路由表中记录了反向路径最短的前一跳路由器和相应的出接口信息。如果网络中存在链路不对称的情况，反向树的构建可能会出现问题。在这种情况下，如果选择了错误的前一跳路由器，可能会导致反向树的路径不是最优的，从而影响数据包的传输效率和可靠性。 可能会包含不含加入多播组的节点（即数据 不需要发送到该多播组）路由器可以向上游发送“prune”消息，告诉它的上游路由器它已经没有任何下游组成员需要接收这些数据报，可以停止向它转发了。这样可以避免不必要的数据传输和浪费网络资源。 Steiner Tree 最小化成本的树形连接所有具有连接组成员的路由器的算法。虽然问题是NP完全的，但有很好的启发式方法来解决。然而，在实践中，该算法不被广泛采用，主要因为计算复杂度很高，并且需要对整个网络进行信息收集。此外，该算法是整体式的，需要每当路由器需要加入/离开时重新运行。 Center-based Trees 将网络中的一个路由器标识为中心节点，并由此构建树形结构。 其他路由器可以通过向中心节点发送单播加入消息来加入该树形结构，加入消息将由中间路由器进行处理，并向中心节点转发。当加入消息到达中心节点时，加入路径成为新的树枝，该路径成为加入节点和中心节点之间的分支。 R6为中心节点，其他路由器向R6发送信息，发送的路径构成生成树 多播路由协议 DVMRP 一种基于RIP的多播路由协议，使用dv Reverse Path Forwarding方法构建源基树source-based tree。 该协议是软状态的，DVMRP路由器会定期（1分钟）\"忘记\"剪枝的分支，多播数据会再次通过未剪枝的分支传输。下游路由器可以重新剪枝，否则将继续接收数据。 修剪是指从路由器的多播转发树中删除特定分支的操作。当某个分支上没有接收者或者接收者已经明确要求不接收该组的数据时，路由器会将该分支标记为修剪状态。这样，多播数据将不会被发送到这些被修剪的分支上，从而减少了网络流量和资源消耗。 然而，为了确保及时传递多播数据，DVMRP路由器会周期性地（每分钟）\"忘记\"分支被修剪的信息。这意味着即使某个分支之前被标记为修剪状态，DVMRP路由器也会在一定时间后重新考虑是否发送多播数据到该分支，以确保数据能够及时到达接收者。 然而，DVMRP协议的缺点是在规模化网络中不适用，因为所有路由器都需要全局了解所有多播组和其源的信息。 MOSPF MOSPF是指“多播扩展开放式最短路径优先协议”（Multicast Extensions to OSPF），基于ospf MOSPF是一种基于链路状态的路由协议，可以为每个多播数据报计算一棵相同的最短路径树，从而保证每个目的组成员都能够接收到多播数据报，且数据报从源到目的组成员的传输路径是唯一的。不过，MOSPF并没有得到广泛的应用。 PIM 依赖于任何特定的底层单播路由算法，可以与任何单播路由协议一起使用。 PIM 协议有两种模式，一种是稀疏模式，适用于组成员分散的情况，采用中心点的方法建立组播树。另一种是密集模式，适用于组成员比较密集的情况，采用源点树（source-based tree）和反向路径转发（reverse path forwarding）的方式建立组播树，与 DVMRP 协议类似。 在稀疏模式下，PIM 协议使用中心点方法建立组播树，这个中心点可以是任意一个路由器，其他路由器通过向中心点发送加入消息来加入组播。组成员比较分散，带宽有限。 在密集模式下，PIM 协议使用源点树和反向路径转发建立组播树，与 DVMRP 协议类似。组成员比较密集，带宽相对较充足。 应用层多播 多播它并没有被广泛采用。仅仅谨慎使用，例如仅在局域网或校园网内使用，很少在广域网上使用。它的失败原因有很多，包括路由协议的可扩展性、难以管理、难以实现TCP等效性、难以让应用程序在没有广泛部署的情况下使用IP组播、难以让路由器供应商支持功能，并且难以让ISP配置路由器以启用功能。这些问题导致IP组播在实际应用中存在困难和挑战。因此，我们需要探索其他方法来实现高效的多点传递，而无需IP层的支持。 应用层组播通过在应用层复制和缓存数据包而不是在路由器上复制数据包来避免IP组播的部署问题。应用层组播无须对路由器作任何修改,因此在 Internet 上非常容易部署 应用层多播只是最终要将信息发送到多个目的节点，而不关心途径路径 也不一定是从一个源发送到所有目的节点，可能经过多个端进行传递。 组播是通过分段单播连接实现的。很明显，终端主机而不是路由器负责复制和转发组播数据包，这样ALM的生成树在最终主机之间形成了一个仅由终端主机和单播连接组成的叠加拓扑。 对比： | | 应用层多播 | ip多播 | | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | | 原理 | 应用层多播是在网络层IP单播的基础上实现的。应用层多播是基于点对多点通信的思想，即将源节点发送的数据复制到多个目标节点上，从而实现多点传输。不依赖于网络层的多播支持。 | IP多播是在IP协议层实现的，依赖于底层网络（设备）的多播支持 | | 使用场景 | 点对点应用，例如P2P文件共享和在线游戏。 | IP多播通常用于广播媒体流和网络电话等多媒体应用 | | | | | 优缺点： 优点： 不需要底层网络支持IP多播功能，因此可以在任何网络环境中使用。 可以更容易地控制多播组成员，以便更好地保护网络安全。 可以更灵活地处理不同的应用需求，如实时视频和音频流等。 缺点： 由于没有底层支持，因此需要更多的计算和网络带宽资源。（效率低、延迟高） 需要专门的服务器来协调多播组成员，这可能会导致单点故障和瓶颈问题。 应用层多播不如IP多播标准化和普及，因此不如IP多播适用于大规模网络部署。 "},"asserts/传输层.html":{"url":"asserts/传输层.html","title":"U3 传输层","keywords":"","body":"传输层 概述 运行在端系统上，分为发送端和接收端（通常既是发送端又是接收端） 为应用层提供端到端的传输 发送端：将从应用程序接受的报文划分为较小的块，加上运输层头部生成运输层报文 分为TCP UDP UDP是最简化的服务，只包括mux和demux TCP提供有序的、有保证的服务 与网络层的区别： 网络层将信息从一个主机运输到另一个，而运输层则是一个主机将到达的数据进行分发到应用；打包发送 socket套接字 套接字是一个软件抽象，用于表示一个应用程序进程与操作系统中的传输层之间交换网络消息的接口。 一个Socket由主机的IP地址和端口号组成，可以唯一地标识网络上的一个进程。在传输层使用的地址表示为，通常称为套接字（Socket)。 套接字可以分为两种类型：UDP套接字和TCP套接字。 UDP套接字的类型为SOCK_DGRAM，，使用UDP协议提供数据传输服务，它是一种面向无连接的传输方式，不保证数据传输的可靠性和有序性。 TCP套接字的类型为SOCK_STREAM，，使用TCP协议提供数据传输服务，它是一种面向连接的传输方式，能够保证数据传输的可靠性和有序性，但会引入一定的传输延迟。 端口（四级地址） 16bits长度 用来区分一个主机上的不同应用 0-1023为保留端口，用于一些基础服务 软件与端口之间的关系由操作系统进行存储 udp不管远程连接到谁，而tcp需要知道远程的信息 服务模型 进程间通信复用/去复用：区分开不同应用的信息（一个主机会受到属于不同应用的信息） mux（多路复用）合并发送端发出的不同应用的信息，并在网络层传输 demux（多路分解）将合并的数据再分开 使用端口 提供了应用层共同使用的端到端服务（ip层服务不稳定可能发生各种问题，没有保障，传输层进行处理） 保证数据的可靠性和有序性，确保数据能够正确地传递到目的地，而且数据的顺序也得到维护。 还需要控制数据传输的速率，避免发送数据过快导致网络拥塞，或者发送数据过慢导致效率低下。 mux与demux 使用ip+port组合地址 每个IP数据报都包含源IP地址和目标IP地址。 每个IP数据报只能携带一个传输层协议的报文段。传输层协议的报文段包含源端口号和目标端口号。 udp 创建连接： 当创建一个UDP套接字时，该套接字会绑定到一个主机本地的端口号上。例如，在这段代码中，创建了一个端口号为12534的UDP套接字：DatagramSocket mySocket1 = new DatagramSocket(12534); 在使用UDP套接字发送数据时，必须指定目标IP地址和目标端口号。 接收： 当主机收到一个UDP数据报时，会检查数据报中的目标端口号，并将该数据报转发到与该端口号相对应的套接字中。 对于来自不同ip/端口的数据，如果有相同的目标ip/端口则会被放入目标的同一个socket中。 仅依据目标端口进行合并 tcp CP套接字由四个值组成，称为4元组（4-tuple）：源IP地址，源端口号，目标IP地址和目标端口号。 demux：接收器使用这四个值来将数据段定向到相应的套接字 服务器主机可以支持许多同时存在的TCP套接字，每个套接字都由自己的4元组来识别。（源头ip/端口不同不合并） Web服务器为每个连接的客户端使用不同的套接字，因此对于每个请求，非持久化的HTTP将会有不同的套接字 可靠传输 手段 校验和：Checksums (to detect bit errors) 超时：Timers (to detect loss) ack：Acknowledgements (positive or negative) 序号：Sequence numbers (to deal with duplicates) packet corruption 校验，回复ack 但是ack也可能会出错！ 无法判断是1还是2 因此给数据加上序号，表示是第几个数据包 窗口长度必须小于或等于序号空间大小的一半 packet loss 发送者从发送时开始计时，超时没有答复后重新进行发送 timeout时间长度要恰好，太短可能发生错误判断；太长会导致效率太低 停止&等待协议 效率： 效率极低，不能充分利用资源 发送者繁忙时间占总时长的比例 Pipelined（流水线） 一次发送多个包而不等待ack 效率计算 假设一次发送三个包 滑动窗口 滑动窗口长度为n，发送端在窗口中发送，接受端接收，两个窗口是相对独立的（可能不同步，如返回的ack正在传输中） 最多有n个未确认包在传输之中 窗口末尾是最后面的没有ack的包 带宽 n太大超过网络带宽会产生丢包严重等问题 确认 Cumulative ACKs：ack附带信息表示想要收到的下一个（滑动窗口中第一个元素）数据包 Selective ACKs 对收到的每个包进行回复，提供更为精准的信息，但需要更为复杂的处理流程 重发送（解决错误）： Go-Back-N 当接收端只按照顺序接受时（会丢弃将来才应该到的后面的包） 接收端使用Cumulative ACKs 发送端只需要为一组数据包中的第一个设置定时器，如果这个包没有成功发送，那就重新发送所有的数据包（第一个数据包是否受到决定了滑动窗口能否向前移动） Selective Repeat 复杂，对每个数据包都设置定时器 接受方受到一个不在滑动窗口（在前面）中的数据时也要重新发送ack，否则可能导致发送无法向前滑动 - 当错误率很高时gbn甚至不能完成传输 sr常用于无线网络 没有确定的数据都要放在buffer里（内存/缓存） UDP 概述 尽力而为的服务 可能丢失 不一定按顺序到达 无连接的 发送者接收者之间不会握手 包头相对较小 用途 直播服务（不在乎丢包，注重实时性、流畅度） DNS SNMP 包头 构造伪首部用于计算校验和 源port可以省略（当不需要回复时） checksum计算 发送端计算后放入checksum，接收端重新计算并比较是否相同 checksum=0表示不需要进行校验确认 对报文段中所有16比特字的和进行加和 将溢出位加在末尾 最后对结果取反码得到checksum TCP 概述 可靠性 一定把数据正确传到 丢失就重新传输 按顺序到达 字节流传输 机制 checksum 序列号（偏移量） 使用缓存存储乱序的数据包 双方维护滑动窗口进行维护 使用累计确认法（发送n表示n之前的都收到了） 包头 32比特的序号字段和32比特的确认号字段。这些字段被TCP发送方和接收方用来实现可靠数据传输服务 16比特的接收窗口字段，该字段用于流量控制。该字段用于指示接收方愿意接受的字节数量。 4比特的首部长度字段，该字段指示了以32比特的字为单位的TCP首部长度。由于TCP选项字段的原因，TCP首都的长度是可变的。(通常， 选项字段为空，所以TCP首部的典型长度是20字节。) 可选与变长的选项字段(options ßeld) ，该字段用于发送方与接收方协商最大报文段长度(MSS)时，或在高速网络环境下用作窗口调节因子时使用。首部字段中还定义了一个时间戳选项。 6比特的标志字段，ACK比特用于指示确认字段中的值是有效的，即 该报文段包括一个对已被成功接收报文段的确认。RST、SYN和FIN比特用于连 接建立和拆除。在明确拥塞通告中使用了CWR和 ECE比特。（当PSH比特被置位时，就指示接收方应立即将数据交给上层。最后，URG比特用来指示报文段里存在着被发送端的上层实体置为\"紧急\"的数据。紧急数据的最后一个字节由16比特的紧急数据指针字段 指出。当紧急数据存在并给出指向紧急数据尾指针的时候，TCP必须通知接收端的上层实体。）（这两项实际中并不使用） 丢包与重传 sequence number（偏移量） 数据量达到一节或者超时时tcp执行发送（应用程序的数据是逐渐转交给tcp的） 长度 ack与序列号具体实现过程 当发送方发送一个数据包时，数据包的第一个字节会被标记为一个序列号X。如果数据包中有B个字节，则数据包中的字节序列为[X，X+1，X+2，… X+B-1]。当接收方接收到这个数据包时，它会发送一个ACK确认接收到了该数据包。如果在序列号X之前的所有数据都已经被接收方接收到，则ACK将确认接收到了序列号为X+B的下一个字节。如果接收方已经接收到了最高顺序的字节为Y，使得（Y +1） 反复发送500告知发送方没有收到 因为TCP只确认该流中至第一个丢失字节为止的字节，所以TCP被称为提供累积确认 接收方收到重复ack时的处理 重复ack是出现数据包丢失的标志 当发送方发送一个数据包后，如果在一段时间内没有收到接收方的确认信息，则会进行重传。但是，TCP协议使用了一种更快的重传机制，即在接收到连续的k个重复的确认信息后，就会立即触发重传，而不是等待超时时间。在TCP中，通常将k设置为3。 如果等待一段时间后没有收到任何ack 那么从滑动窗口的第一个开始进行重传 RTT：数据往返一次需要的时间（发送数据到接收确认所需要的时间），应该使timeout与RTT相近（SampleRTT：样本RTT，是指当前分组往返的时间；EstimatedRTT：估计的RTT，是指对SampleRTT进行平均计算得到的RTT值） 问题：如何区分ack的来源 在发送方进行重传之后，有两种选择： 在发送缺失的数据包之后，将滑动窗口向前移动与收到的重复确认信息数相同的距离。这种方法可以加速传输速度，但也可能出现错误。 在发送缺失的数据包之后，等待接收方发送确认信息，然后再将滑动窗口向前移动。这种方法会因为一个数据包的丢失而减慢传输速度。 RTO指数回避算法（超时重传时间，指在此时间内如果没有收到确认信息，就会触发超时重传机制） 不要使用从重传中获取的SampleRTT，因为这可能会导致估计的RTT偏高。重传的数据包可能会受到拥塞等其他网络问题的影响，从而导致RTT偏高。因此，我们只使用原始的、成功传输的数据包的SampleRTT。 EstimatedRTT = (1 - α) × EstimatedRTT + α × SampleRTT 其中，α = 0.125是平滑系数，表示对当前SampleRTT与上一次的EstimatedRTT进行平均的权重。这里我们假设初始的EstimatedRTT为0。 RTO的初始值为2倍的EstimatedRTT。算法采用指数退避机制，当RTO超时时（没有收到答复），将RTO加倍，直到达到一个最大（60s）；收到了就对RTO进行重置 问题RTT会发生变化，不稳定 Jacobson/Karels algorithm SRTT（EstimatedRTT）：平滑的往返时延，通常是通过对多次测量的SampleRTT进行加权平均得出的估计值。SRTT是用于计算RTO和DevRTT的重要参数。 SERR (Smoothed Error)：平滑误差，是估计的RTT和实际测量值之间的差异。SERR用于计算SDEV，以便更好地估计RTT的变异性。（SamplaeRTT-EstimatedRTT）即Deviation SDEV (Smoothed Deviation)：平滑的偏差，是样本RTT与SRTT之间的差异的指数平均值。SDEV用于计算RTO，以便更好地调整重传超时时间，以适应网络中的变异性。即DevRTT 计算RTO：RTO是估计RTT加上4倍平均偏差的值，旨在提供足够的时间来等待确认信息的到达。 该算法的主要优点是它能够更准确地估计网络延迟和RTT的波动，从而提供更准确和可靠的RTO超时时间。同时，该算法还能够自适应地调整RTO超时时间，以适应网络的变化和波动。 例子 只要第二个报文段的ACK在新的超时发生以前到达，则第二个报文段将不会被重传。 连接建立与控制 标志位 2-way握手 a发送syn，b回复syn 丢失的syn包使用重传处理 问题： 可能会收到来自旧的会话的过时的数据包 问题解决： 对sn随机初始化（isn： initial sequence number）用于标识发送方发起连接的初始序列号 但过时的syn包还是会造成问题 three-way： syn附带序号，确认序号正确（是对应的）再回复ack确认建立连接 过程 如果syn包发送失败，那么不会收到ack回复，并且发送者不知道接收者距离有多远，因此设置一个固定的超时时长（一般3s） SN是自己的编号，AN是对方的 SN：序列号，用于标识TCP协议中每个数据包的唯一序列号。 AN：确认号，用于标识收到的数据包的序列号。当接收方收到TCP数据包后，会向发送方发送一个ACK包，其中包含确认号，表明接收方已经成功接收了前面发送方发送的数据包。 双方会分别选择一个序号作为自己包序列序号的起点 连接断开 单边关闭 只关闭了a处的连接 如果b没有收到ack会重复发送fin a在回复ack后不会立即关闭，因为b可能收不到ack，需要重新进行发送 双边关闭 强制关闭 发送rst后对方不会进行回复，但如果对方继续发送data(表示没收到rst)则会重新发送rst 流量控制 滑动窗口回顾 发送方和接收方都会维护一个窗口，窗口的左边缘表示未确认的数据的开始位置，发送方维护的是还未收到确认的数据，接收方维护的是期望接收的数据的开始位置以及接收到的第一个缺失数据的位置。当发送方收到确认信息时，就知道接收方的窗口已经向前移动了。窗口的右边缘则是左边缘加上一个常数，这个常数只受传输层缓存大小的限制。 数据接收到并取走才滑动 流控：控制发送端发送的数据不会超过接收端的缓存能力 credit scheme 在发送ack同时在tcp包头中附加RWND，告诉发送方自己还有多少空闲的缓存，即还有多少空间可以接收数据。（总缓存大小减去已经使用的部分）（已使用的长度为最后一个接收到的减去最前面收到但还没有处理完成的长度） 总结： 发送方和接收方都会维护一个窗口，窗口的大小和位置会随着数据的发送和接收而变化。当发送方收到ACK确认信息时，窗口向前移动，表示之前发送的数据已经被接收方成功接收了。而当接收方消耗掉接收缓冲区中的数据时，窗口也会向前移动，表示接收方已经成功接收了之前发送的数据。 为了防止接收方缓存区溢出，接收方会告诉发送方当前接收缓存区的右边界位置，即还有多少空间可以接收数据。发送方会遵循这个位置，确保自己发送的数据不会超出接收方缓存区的限制，从而避免数据丢失的问题。 优点： ack与流量控制信号分开，避免二意性 头部 AN表示已经接收到的数据的最大序列号（接收方已经成功接收的所有数据段的最后一个字节的序列号为AN-1，下一个期望接收的字节的序列号是AN） W表示接收方当前的窗口大小。（W表示接收方当前还有多少缓存空间可以用于接收数据，如果发送方想要继续发送数据，需要得到接收方的允许，发送窗口大小不能超过W。） 如果接收方B想要将窗口大小增加到k（k>j），而此时没有额外的数据到达，那么B可以发送一个ACK/CREDIT消息，其中AN=i，W=k，表示允许发送方在下一次发送数据时发送k个字节。 如果接收方B收到了一个包含m个字节数据的数据段（m 需要注意的是，如果ACK/CREDIT消息丢失了，那么对协议的影响很小，因为未来的ACK消息会重新同步协议。 如果发送方超时并重新发送数据段，那么它会触发一个新的ACK/CREDIT消息，从而重新调整窗口大小。 死锁问题： 接收方B首先向发送方A发送一个带有AN=i、W=0的数据段，表示关闭接收窗口。接着，B向A发送另一个数据段，其中AN=i，W=j，表示重新打开窗口，但这个数据段可能会丢失。此时，A认为窗口已经关闭，而B认为窗口已经打开，从而导致了死锁。 为了解决这种死锁情况，可以采用窗口定时器的方法。具体来说，当窗口定时器到期时，如果没有收到任何数据，则发送方A可以发送一些数据，例如重传之前的数据段。这样，即使接收方B发送的第二个数据段丢失了，发送方A仍然可以通过定时器来重新激活数据传输，从而避免了死锁。 拥塞控制 拥塞产生的原因与代价 当繁忙时会产生大量丢包与重传，即做大量无用功，进一步加重拥塞 让传输路径上的路由器发送速率大于接收速率，防止在传输过程中超出路由器缓存造成丢包 思路：根据拥塞状况调整滑动窗口的大小 主机可以通过不同的方式来推断当前网络的拥塞程度，并根据拥塞程度进行相应的调整。 另一方面，网络也可以向主机报告拥塞程度，并要求主机进行相应的调整。 还有一些策略是将以上两种策略结合起来，例如，主机可以根据自己的传输情况来推断网络的拥塞程度，并将这些信息反馈给网络，从而实现更加精细的拥塞控制。 在TCP连接中，每个连接都有一个窗口，它控制着可以同时发送的未确认数据包数量，从而影响发送速率。（ 发送速率 ~Window/RTT） 如果窗口大小越大，就可以发送更多的数据包，从而提高发送速率；反之，如果窗口大小越小，就可以限制发送速率。通过动态调整窗口大小，可以实现流量控制和拥塞控制等功能，从而保证网络的可靠性和效率。 除了流量控制窗口（RWND），又增添拥塞窗口（CWND）表示可以在网络中发送而不会导致拥塞的字节数量（由发送方根据拥塞控制算法计算出来的）。 Sender-side window = min {CWND, RWND} 实际上：RWND >> CWND 确定可用带宽 判断方式： 数据包往返时延（但是由于抖动很大，不可靠） 由路由器告诉终端发生了拥塞(太复杂了，不实际) 实际：使用数据包的丢失作为拥塞的标志（在广域网中使用，但移动网络中大量丢包造成了干扰） 丢包分类 收到连续ack：说明丢了个别包，问题不严重 超时没有收到ack：问题严重，出现严重拥塞 带宽动态调整 基本策略： 收到新的ack：加快发送速率 发现丢包：降低发送速率 在慢启动阶段，TCP会快速增加其拥塞窗口（CWND），以发现网络的可用带宽。（在第一次丢包之前会以指数速率快速增长） 初始时CWND=1，发送速率为MSS（数据包最大大小）/RTT（通过每收到一个ACK就把CWND+1），相当于每RTT翻一倍 ssthresh最初会被初始化为一个很大的值 一旦达到了阈值（ssthresh）或发生拥塞丢包/重复ACK，TCP就会进入拥塞避免阶段。在这个阶段，TCP会以一种被称为加性增加和乘性减少（AIMD）的方式调整其CWND大小。简而言之，TCP在这个阶段会将CWND每RTT增加一个MSS（1/CWND，缓慢增加，即一个RTT加1），检测到3个连续重复ack时ssthresh = CWND/2 CWND= ssthresh+3（收到3个重复ACK）开始快速恢复（就是不到1，到CWND/2）（是较新版本TCP Reno所特有的，早期版本Tachoe会不区分丢包和冗余ACK，都会置1，进入慢启动）阶段，检测到丢包时ssthresh = CWND/2, CWND = 1重新慢启动 tip：当出现ack冗余或者数据包丢失后，拥塞窗口长度会在下一轮回发生变化 如果在一轮回达到了sshresh，那么本轮回的长度就是sshresh，因为到达后会终止本回合开启下一回合！ &&典：p41 AIMD原理（选择原因） 优势：效率&公平 可以找到带宽上限 动态调整带宽 公平分配带宽 其他可选： 绿线上：公平；红线上：效率；交叉点为最佳点（希望最终收敛到这一点） AIAD（常数加减） 不满足公平性 MIMD(比例加减) 不满足公平性 AIMD(常数加，比例减) MIAD(比例加常数减) 垃圾 带宽分配 改进-快速恢复（TCP Tahoe） 改进（TCP Tahoe） cwnd=10，接收方等待101，发送方为 [101, 102, 103,…, 110] 假设101丢失 直到重传的101被收到后窗口才能继续向前移动，因此会造成窗口阻塞问题 收到3个ack说明发送还在正常进行，不妨+3 在快速恢复阶段 直到收到新ack（包含缺失重传的那一个）再退出快速回复，并令CWND = ssthresh，进入拥塞避免 保证发生了单数据包拥塞后，还会继续向前发送 && 理论分析 宏观模型 吞吐量 忽略慢启动指数增加阶段，因为这一阶段是很短的 假设在连接持续期间 RW几乎不变.那么 rcp 的传输 速率在 W/(2xRTT) W/RTT 之间变化（拥塞抑制阶段，每次加一个MSS） 故 平均发0.75w包/RTT，平均0.5wRTT发生一次丢包 当RTT不一致时TCP不是公平的 问题 高速传输问题 && 使用throughput公式计算，注意单位 解决 当越过上界时加快传输增加速度（乘性增加） 建立多条连接 Rate-based 避免震荡，直接计算出rate，发送数据 目的：速率与传统方式相同，但比较平稳，固定速率发送 移动网络丢包问题 TCP在某些情况下可能会将数据包的丢失误认为是网络拥塞的结果，而实际上这些丢失可能是由于数据包损坏或其他非拥塞原因导致的。这种情况下，TCP会错误地将数据包的丢失解读为拥塞信号，从而触发拥塞控制算法中的拥塞避免机制，导致流量的速率被削减。 流量的吞吐量与丢包概率之间存在一个倒数的平方根关系。如果丢包概率增加，流量的吞吐量会下降。这个关系适用于所有类型的丢包，无论是由于拥塞引起的还是其他非拥塞原因引起的。 短数据问题 如果数据流比较短，可能无法充分加速，没有离开慢启动就结束了 如果包比较少可能无法启动快速重传，可能被误判为丢包 会增加短数据的延时，因为tcp总是想将缓存占满，因此数据包到达路由器后可能会经历漫长的延时等待 长数据支配短数据 欺骗问题 由于TCP是端算法，如果在操作系统修改CWDN的长度，会造成公平性的问题 一个传输开多个TCP连接抢占资源 路由器拥塞控制 思想 路由器告诉终端发生了拥塞： 解决误判、高排队延迟问题 路由器通知终端发送速率： 解决高速传输问题、短流问题 路由器保证传输公平性 抑制分组 拥塞路由器告诉发送源发生了拥塞丢包，使用ICMP进行通知 问题： 对路由器性能要求太大 反馈速度太慢 反压 逐层进行抑制分组，一层通知相邻的一层 警告位 在数据包的包头做一位标记，如果接收端发现head中有信号，则在返回的ACK中添加标志位提醒发送端，由此接收端不丢包也可以知道拥塞状态 精确拥塞通知 优点 不将数据包损坏误认为拥塞：ECN的优点之一是它可以通过在数据包中设置特殊的标志位来显式地通知接收方关于网络拥塞的情况。这样，TCP不会将数据包的损坏误认为是拥塞信号，而是通过相应的机制进行恢复和调整传输速率。 提前指示拥塞：ECN可以作为早期拥塞指示器，提供关于网络拥塞的信息。这可以帮助发送方避免等待传输超时来检测拥塞，从而减少传输的延迟。 易于增量部署：ECN的部署相对容易，特别是在今天的网络中，已经通过RFC 3168定义并使用IP头中的服务类型/差分服务代码点（ToS/DSCP）位来标识ECN。在数据中心环境中，ECN也很常见。 随机早期丢弃 防止出现同步波动问题 RED 在队列完全堆满之前就提前开始进行随即丢包，避免同时丢包 队列越长，丢包的概率越大 公平丢弃 为每个流提供独立queue，轮流传输，保证公平 &&MAX-MIN 不能直接平分，因为有的流很小，平分会造成浪费 如果需求小于直接平分的值，则直接满足，剩下的包再继续瓜分 无法直接实现：因为一个包必须一次性发送完成，无法轮流发送（不能拆分为逐字节发送） Fair Queuing 使用算法进行模拟： 首先计算理想评分条件下每个数据包完成发送的时间，按照理论完成的先后依次进行发送 WFQ带权重的公平 在实际中不一定是对单条TCP算作一个流（太多了），可以对一个更大范围的数据算作一个“流”（比如一个系楼） 与FIFO相比 优点： 避免欺骗，带宽分享不取决于往返时间（更加公平） 网络中的不同流（或连接）可以独立选择自己的速率调整方案或拥塞控制算法。 问题： 实现复杂度高 不能避免拥塞 虽然公平，但在这种情况下造成低效率 多媒体传输 音频传输 采样范围（频率范围） 采样频率（与模拟信号拟合程度） 视频传输 压缩： 空间压缩：同一图像不同位置（相邻） 时域压缩：不同帧相同信息压缩 分类 流媒体： 服务器有完整视频，不需要下载整个文件，在线（在下载的同时）播放 服务器读取->发送->用户接收 正在播放的内容与正在接受的内容有一定不同（预先缓冲） 挑战 能否流畅播放（缓冲不用光）是用户最重视的 用户可能回看、快进等 网络时延、传输带宽不稳定 最初播放开始前先进行缓冲（储备） 在播放过程中buffer的量会反复波动 根据buffer进出速率关系 使用UDP传输 丢包没有很大影响，将丢包、异常处理交给应用层 send rate = encoding rate = constant rate UDP may not go through firewalls 使用tcp+http 使用tcp拥塞控制机制，还可以更为方便的实现用户控制（播放、暂停）等功能 DASH传输（HTTP基础上） 用于传输存储的数据 把大文件（视频）切分成好多小文件发送 将不同清晰度的文件分别切分发送，供用户选择 客户端根据网络带宽选择不同清晰度，实现自适应 客户端决定什么时候请求下一个文件，请求什么清晰度，从哪里请求，都交由用户决定 视频电话Voip： 注重延迟 > 400 msec bad 数据包会丢失（1%-10%是可以接受的）、数据包有延迟 数据包丢失：如路由器缓存已满丢包 延迟丢包：数据包到达的太晚，即使到达了也要被丢弃（如>400ms） 使用超级节点帮助host建立连接 登陆后保持登录，内层与超级节点保持连接 因为数据包的传输实验可能发生抖动，因此也需要有播放延时（小于400ms） 流直播： 体育比赛啊 实时传输协议 RTP 在UDP之上，一种实时传输协议（传输实时音频视频等） RTP分组是封装在UDP内的 包含负载类型、序列号、时间等信息 Timestamping（时间戳）注意与序列号区分 接收方使用时间戳来重构原始的时序信息。 协调不同流之间的同步，例如音频和视频的同步播放 时间戳的主要作用是在接收方进行数据恢复和播放时，保持正确的时序。通过时间戳，接收方可以根据数据包的采样时间来恢复和播放音视频数据，以确保音视频同步和正确的时序。 序列号 丢包检测：接收方可以通过比较接收到的数据包的序列号来检测是否有数据包丢失。如果接收方在连续的序列号中发现有缺失的序列号，就可以推断出存在丢包的情况。 恢复包序：在网络传输中，数据包可能会经历乱序的情况，即接收方可能以不同的顺序接收到数据包。通过序列号，接收方可以重新按照正确的顺序组装接收到的数据包，以保证数据的正确顺序。 负载类型中会标识数据包携带的数据类型、如音频视频等，以及用于指定有效负载格式以及编码/压缩方案。应用程序可以根据有效负载类型标识符来解释有效负载数据。 RTP并不提供确保及时数据传递的机制。RTP封装仅在端系统可见，中间路由器看不到RTP封装。路由器对RTP数据包不做特殊处理，不提供额外的支持 RTCP 与RTP配合使用 用于源和端交换信息（双向，可以反馈信息） 用于传输关于RTP流的控制信息，如接收质量反馈、丢包统计、带宽估算和参与者信息等 服务 QoS（服务质量）监测： 接收者向发送者反馈服务质量 发送者由此对传输进行调整 接收方可以确定拥塞是局部的、区域的还是全局的 源标识（接收者可以确定数据的来源） 媒体间同步（音画同步） 控制信息缩放：调整传输以适应网络状况，如调整传输方式、帧率等 限制控制流量：防止控制信息占用资源过多对正常传输造成影响 RTSP 与RTP配合使用 可以使用UDP也可以使用TCP，以ascii的格式发送命令 它允许客户端通过发送请求来控制流媒体服务器，如播放、暂停、快进、倒带和选择不同的音视频轨道等操作，可以用于控制实时流媒体的播放和交互。 SIP 在IP网络上实现软电话功能，可以在通话中更换编码方式、邀请加入 找到通话对象：都在代理处登记，通过代理寻找对方 SIP主要用于会话的建立、修改和终止（而不是传输！），它处理会话的控制和信令。 格式 user@host 通话建立 通过SIP地址确定被叫方（callee）的当前IP地址。 通知被叫方，告知其有人想要建立通话。 主叫方（caller）和被叫方商定媒体类型和编码，确定通话所使用的媒体格式和编码方式。 SIP地址必须转换为被叫方当前主机的IP地址(即将一个无法直接访问的内网地址转为为一个可以在公网访问到的地址) 注册服务器（Registrar）：接受来自客户端（主叫方或被叫方）的注册请求，存储用户名对应的ip地址，可以用于查询 重定向服务器（Redirect）：将指向被叫方的下一个跳转地址返回给主叫方，指示主叫方应该尝试另一个地址或服务器来完成通话建立。（不直接参与请求的传输） 代理服务器（Proxy）：决定下一个跳转地址并将请求转发（作为中间人）。 主叫方（Caller）：Bob@umass.edu，发起一个INVITE请求消息，发送给umass SIP代理。 代理（Proxy）：umass代理将请求转发给upenn注册服务器。 注册服务器（Registrar）：upenn服务器返回一个重定向响应，指示应该尝试Alice@eurecom.fr。 代理（Proxy）：umass代理向eurecom注册服务器发送INVITE请求。 注册服务器（Registrar）：eurecom注册服务器将INVITE请求转发给IP地址为197.87.54.21的Alice SIP代理。 SIP响应：SIP代理和服务器之间进行一系列的请求和响应交互，包括接受INVITE请求、确认、会话建立等。 媒体传输：媒体直接在SIP代理之间传输，也就是Bob和Alice之间进行语音或视频通信的过程 通话管理 在通话过程中添加新的媒体流：允许在通话进行中添加额外的媒体流，例如添加一个新的音频或视频流。 在通话过程中更改编码方式：允许在通话进行中更改媒体数据的编码方式，以适应网络条件或其他需求。 邀请其他人、转接和保持通话：允许用户邀请其他人加入通话、将通话转接给其他人或将通话放置在保持状态。这些功能用于通话的管理和协调。 因特网质量控制QoS 整合服务架构ISA 把一组数据包定义为一个流 一组数据包具有相同的QoS参数（传输需求） 功能 路由算法：除了延迟外考虑更多的因素，如优先等级等 排队先后：优先级调度 丢包策略：选择性丢包 资源预留：为特定QoS的流预留资源（类似虚电路） RSVP Admission control：确定是否有足够的资源来满足请求的服务质量（QoS）下的数据流 Traffic control database：流量控制数据库用于存储与流量控制相关的参数 Management agent：管理代理通过修改流量控制数据库的内容来指导接纳控制模块设置策略。 RSPV预留过程 接收方（Receivers）：接收方生成带有预留请求的RSVP消息，并将消息沿着上行传递给发送方。 请求的范围：预留请求传播的发送方主机集合。 每个中间路由器：RSVP模块将请求传递给接纳和策略控制模块，并执行检查。 维护每个流的软状态：为每个流维护软状态，定期进行更新。 缺点 设备要求高，复杂，成本高 不具有很好的弹性 不能很好的同时服务很多的流 差分服务DS 只提供几种服务分类，把数据分为不同类，对每一类的数据进行统一处理 从而减少状态，降低复杂度 对数据包打标记 Use IPv4 header Type of Service or IPv6 Traffic Class field 作用域可控 可以单个ISP实施（通常），也可以共同实施 内部路由 在域内一致解释DS代码：确保在特定网络域内对DS（差异化服务）代码点的一致解释。 基于代码点的简单处理机制：使用简单的机制根据代码点（类别）处理数据包。 分类器：根据DS代码点、源地址、目标地址、高层协议等对数据包进行区分。 队列管理：对数据包进行排队管理。 Per Hop Behavior（PHB）：根据代码点为数据包提供优先处理，不同的代码点会得到不同的待遇。 数据包丢弃规则：当缓冲区饱和时，规定了应丢弃哪些数据包。 边缘路由 对每个流进行流量管理：边缘路由器可以对每个数据流进行个别的流量管理。它可以标记和监管数据包，将其划分为符合要求的流量（in-profile）和不符合要求的流量（out-profile），标识分组。 内部路由器：边缘路由器将标记过的数据包传递给内部路由器。内部路由器根据边缘路由器的标记对数据包进行分类、缓冲和调度。它根据数据包的标记给予优先处理，更重视符合要求的数据包（in-profile）。 分类器（Classifier）：将传入的数据包流分成不同的类别。 流量计（Meter）：测量流量以符合预设的规格要求。 标记器（Marker）：根据需要，通过重新标记代码点来进行流量管理。 塑形器（Shaper）：使用令牌桶来塑造数据包流的流量。 丢弃器（Dropper）：如果流量速率超过类别规格中指定的限制，丢弃数据包。 边缘路由器：对流分类打标记、对包数目等进行控制 根据in-profile and out-profile分类（是否在合同保证内） 常用控制 平均速率（Average Rate）：指的是数据以恒定速率离开漏桶的速率。它表示单位时间内允许发送的平均数据量。例如，如果平均速率为100 Mbps，则漏桶每秒可以以平均100 Mbps的速率发送数据。（可以通过设置装填速度实现） 峰值速率（Peak Rate）：表示漏桶允许的最大发送速率。峰值速率通常高于平均速率，并且可以在短时间内发送更多的数据。例如，如果峰值速率为200 Mbps，则漏桶可以在某些短时间段内以高达200 Mbps的速率发送数据。(可以通过设置通的容量和装填速度实现) 突发长度（Burst Size）：指的是漏桶能够容纳的最大突发数据长度。突发长度与峰值速率相关，它定义了在突发情况下漏桶可以容纳的最大数据量。例如，如果突发长度为1 MB，则在突发发送数据时，漏桶最多可以容纳1 MB的数据。 在数据进入网络前进行控制、分类 漏桶策略 以恒定速率将数据放入网路，用缓冲区进行稳定 如果积累的数据超过了限制就进行丢包 token桶 在边缘有一个”桶“里面装在用于提供特殊服务的token，装入速率r表示允许的最大(平均)速率，大小b表示可以爆发传输的最大数据量，没有token的意味着普通服务（低优先级）， t时间内最多$$rt+b$$ 发送队列$$3_7$$ 设有n条流，参数$$b_i$$ $$r_i$$ 总带宽为R 流i至少有贡献链路带宽$$\\frac{R*w_i}{\\sum w_j}$$ 漏桶+加权公平队列 数据包需要经过漏桶才能进入WFQ队列 当$$bi$$个分组被一次性加入到WFQ等待区域时具有最大时延$$d{max}=\\frac{b_i}{R*\\frac{w_i}{\\sum w_j}}$$ "},"asserts/网络安全.html":{"url":"asserts/网络安全.html","title":"U4 网络安全","keywords":"","body":"网络安全 概述 分类 阻断、窃听、修改、伪装 被动攻击： 窃听 明文传输可以直接获取 加密传输还可以分析传输模式等信息 不干扰过程，但是窃取信息 很难能被发现 主动攻击： 伪装 修改 阻断服务 很难被阻止但是容易发现 安全要求： keyongxing可用性：针对阻断（通讯不能被阻断） 机密性：针对窃听（不能被听懂（可以听）） 完整性：针对篡改（不能在无法察觉的前提下修改） 授权性：针对伪装（保证双方的身份正确） 模型 不能对物理安全做任何假设 加密的算法也不是保密的 对信息内容加密 增加校验，识别改动 标志，源不能被伪装 加密 对称密钥 即使有密钥也很难解码，还需要解码算法 难以被破解 问题：如何实现安全的密钥传递 只拥有密文： 穷举法：尝试使用所有可能的密钥对密文进行解密。 密码分析：利用加密算法的性质以及对明文和密文的一般特征的了解，试图推断出原始信息或加密密钥。 已知明文攻击： 拥有明文和相应的密文。能够分析二者之间的关系，有可能推断出加密密钥或解密其他密文。 已选择明文攻击： 可以选择特定的明文消息并获取相应的密文。能够分析加密过程，可能发现漏洞或推导出加密密钥。 传统加密 易于破解 凯撒密码 key只有一位，最多只需要尝试26次 单表密码 将字母乱序对应 通过语言学分析（如出现次数）进行破解 Vigenere密码 Rail Fence Cipher 按列书写，转换为行 key是行数 暴力破解 Row-Column Cipher 在rail的基础上增加列顺序变幻 现代加密（块加密） 计算机可以实现快速暴力破解 对称加密使用快加密的方式 算法 数据加密标准（Data Encryption Standard，DES）：DES是一种对称密钥块密码，使用56位密钥对64位的明文块进行加密。然而，由于DES的密钥长度较短，已经被认为不够安全，因此在一些应用中已经不再广泛使用。 三重数据加密标准（Triple Data Encryption Standard，TDES）：TDES是对DES的改进和增强版本。它通过对数据应用DES算法三次来提高安全性。TDES可以使用不同的密钥长度（如168位）和操作模式，以提供更高的保护级别。 高级加密标准（Advanced Encryption Standard，AES）：AES是一种广泛采用的对称密钥块密码，被视为DES的替代方案。AES使用可变长度的密钥（如128位、192位或256位），以及不同的加密模式和操作方法，具有较高的安全性和效率。 DES加密 选择一个56位的密钥，通过应用奇偶校验位生成64位的密钥(将56位的密钥按每个字节的7个位进行分组，形成8个字节，每组统计1的个数，计算得到8位校验码) 将输入的64位明文分成左右两个32位的数据块（L0和R0）。对每个数据块应用初始置换表（IP表）进行重排（打乱原先列列的顺序，按照一个固定顺序进行重新排列） 迭代运算（具体运算过程不需要掌握） 迭代运算共有16轮，每轮都使用不同的子密钥。 对于每一轮，进行以下操作： 将前一轮的左数据块（Li-1）赋值给当前轮的右数据块（Ri-1）。 对右数据块进行扩展置换（Expansion Permutation），将32位扩展为48位。 将扩展后的右数据块与当前轮的子密钥进行异或运算。 将异或结果分成8个6位的块，每个块通过S-Box进行替换得到4位的结果。 将替换后的结果合并成一个32位的数据块。 对合并后的数据块进行P-Box置换。 将P-Box置换的结果与前一轮的左数据块进行异或运算，并将结果作为当前轮的左数据块（Li）。 最终置换（Final Permutation）： 将最后一轮迭代后的左右数据块进行交换。 将交换后的左右数据块合并成64位的数据块。 对合并后的数据块应用最终置换表（FP表）进行重排，得到最终的64位密文 每轮过程 只能使用暴力破解$O(2{56}) = O(10^{17}) $keys 随着计算机发展，容易被破解了 淘汰 Triple DES Uses 3 keys and 3 executions of DES algorithm 相当于进行3次DES EEE模式，三次加密 EDE模式，加密、解密、加密 问题：块太小（64比特）速度太慢 *AES 可变key长128~256 比Triple DES的效率更高 以块（二维数组）的格式进行运算，效率更高 State Array 一个矩形数组，由4行和B（等于4）列组成，每个数组条目存储一个八位字节（8位） Array的初始值是按列输入的明文块。 Array的初始值是按列输入的明文块。 加密完成后的State Array会被按列读取，得到密文块。 密钥扩展方案 密钥在AES中被组织为一个密钥集序列 初始密钥集由K列，每列包含4个八位字节（32位）组成。密钥扩展过程会生成(r+1)×B个4个八位字节（32位）的列，用于每一轮的轮密钥加操作。 S-盒代替（S-box substitution）：S-盒是一个用于进行字节替代的查找表。在S-盒代替操作中，每个八位字节被替换为另一个八位字节，具体的替换规则由S-盒表格决定。S-盒代替操作是AES中的一个重要步骤，用于增加密码算法的非线性性和混淆性。 行移位（Row shifting）：行移位操作涉及对State Array中的行进行循环移位。具体来说，每一行向左循环移位的位数取决于行的索引。这个操作通过改变数据在State Array中的位置，增加了算法的扩散性和抗差分攻击的能力。 列混淆（Mix-Column）：列混淆操作涉及将一个4个八位字节的列替换为另一个4个八位字节的列。这个操作使用了一个特定的查找表，根据列中的每个字节的值来查找对应的替换值。列混淆操作提供了算法的扩散性和抗线性攻击的能力。 当前Ki的位异或（Bit-wise XOR with current Ki）：这个操作涉及将当前轮密钥（Ki）与State Array中的数据进行位异或运算。位异或操作是一种逐位比较操作，将两个二进制数对应位上的值进行异或运算，结果是一个新的二进制数。这个操作用于将轮密钥与数据进行混合，增加加密算法的安全性。 &&公私密钥（非对称加密） 使用一对两个密钥，发送端和接收端不共享关于自己密钥的信息 每个端都有私钥和公钥，私钥只有自己知道，公钥大家都知道 公钥用于加密，私钥用于解密 Decrypt(Encrypt(M, PUBA), PRVA) = M：将明文M使用A的公钥PUBA加密，然后使用A的私钥PRVA解密，最终得到原始明文M。 用于加密数据传输 Decrypt(Encrypt(M, PRVA), PUBA) = M：将明文M使用A的私钥PRVA加密，然后使用A的公钥PUBA解密，最终得到原始明文M。 可以用于进行发送者的身份验证 即使有公钥和算法，也应该很难得到私钥 &&RSA算法 数学原理 思想：把任何信息看作01串进一步看作一个数字 m= 10010001=>145. 例如把字母的序号作为值：a=1,b=2... 单词看作二进制拼接后的值 dog=>00100 01111 00111=>4583 过程 选择两个很大的素数p、q（500-1024bits） 取$ N = p × q$ $Φ = (p–1)×(q–1)$（欧拉函数，计算小于N并与N互素 的整数个数） 选择一个e $GCD(e, Φ) = 1$ 找到e的模反元素（$(d×e) mod Φ = 1$） Public Key: (e, N), and Private Key: (d, N) 发送： 使用e作为指数，N作为模数 $C = M^e(mod N)$ 发送$C$ 接收： $M=C^d(modN)$(由欧拉定理还原出了M！) 例 强度: 素数 p 和 q 应该具有大致相同的长度。在RSA算法中，安全性依赖于大素数的难解性。确保 p 和 q 长度相近可以提高算法的安全性。（p 和 q 的长度约为 N 的一半。） 素数 p 和 q 应该是不相关的。这意味着它们之间不应该存在简单的数学关系，以防止攻击者利用这些关系破解加密。 公钥指数 e 可以选择较小的值。公钥指数通常是一个较小的常数值，用于加密过程，因为它不会对加密过程增加太大的负担。 私钥指数 d 必须选择一个较大的值。私钥指数用于解密过程，需要足够大的值以确保解密的安全性。 RSA的强度取决于以下事实： 使用大的 N，其中包含大的素数因子，因子分解是一个困难的问题。 N 的长度可以增加以增强加密算法的安全性。 反向使用（身份验证） 问题： 在RSA加密算法中，指数运算是计算密集型的操作。加密和解密过程中需要进行大数的指数运算，这需要较长的计算时间和资源。 DES对比RSA在计算效率上至少快100倍。DES是一种对称密钥算法，相对于RSA的指数运算，DES的加密和解密操作更快。 应用; 使用公钥加密算法建立安全连接，然后建立第二个密钥，即对称会话密钥，用于数据加密。 Bob和Alice使用RSA加密算法来交换对称密钥KS。这意味着Bob和Alice使用各自的公钥加密KS，并通过互相交换加密后的密文来实现对称密钥的安全传输。 一旦Bob和Alice都获得了KS（对称密钥），他们将使用对称密钥密码算法进行加密和解密操作。对称密钥算法在性能上比公钥加密更高效。 身份验证 发展 ap1.0: ap2.0: ap3.0 \\ ap3.1: 仍然不是安全的 ap4.0 防止遭受\"录制\"攻击，每次使用不一样的R alice使用密钥对称加密R并回复 ap5.0 使用非对称加密 安全漏洞（中间人窃听漏洞） 图片左右没对上，大致意思是攻击者伪装alice与bob通信，并让bob误以为自己与alice通信（记录的公钥为攻击者的） 同时与Alice通信建立了连接 在之后的通讯中，攻击者可以解码bob发送给alice的信息进行查看，再转交给alice，而不会被发现 使用自己的公私钥与bob进行通信，使用alice的公私钥与alice进行通讯 这种情况下的中间人攻击具有危险性，因为攻击者可以窃取敏感信息、篡改通信内容或执行其他恶意操作，而受害者完全不知情。为了防止中间人攻击，通信双方应该采取额外的安全措施，例如使用加密技术、数字证书和身份验证来确保通信的安全性和真实性。 信息完整及认证 确认信息的来源正确，并且没有被篡改 消息认证码 发送者计算并发送认证信息作为常规信息的一部分，接收者将收到的认证信息与预期的信息比较 基本概念 MAC（Message Authentication Code）一个附加在消息末尾的固定长度代码：消息认证码（MAC）是一个固定长度的代码，它会附加在要传输的消息末尾。它用于验证消息的完整性和真实性。 典型的MAC大小范围从64到256位 可以在不加密的情况下发送明文消息：由于MAC用于验证消息的完整性和来源，可以在没有加密的情况下发送明文消息。通过验证MAC，接收方可以确保消息未被篡改，并且来自所声称的发送者。 MAC是消息和密钥的函数：MAC是根据消息和一个密钥生成的。通过使用特定的哈希函数或加密算法，将消息和密钥作为输入，生成MAC作为输出。只有知道密钥的合法方能够验证和生成正确的MAC。 把密钥添加进来是为了防止攻击者将信息内容与MAC全部修改 MAC不应该可逆，不需要解密 MAC的强度取决于函数和密钥的保密性：MAC的安全强度取决于所使用的函数（例如哈希函数）的安全性和密钥的保密性。使用强大的哈希函数和足够长的密钥可以增强MAC的安全性，使其难以被破解或伪造。 性质 可以处理任何长度的消息而自身的长度固定 可以被快速计算出来 具有单项性 已知MAC为X的情况下，很难找到一个数据Y满足MAC(Y)=X。这个属性确保了认证码的不可逆性，防止未授权的人通过认证码推导出原始消息内容。 弱碰撞抗性 给定一个消息X1，很难找到另一个消息X2，使得MAC(X1) = MAC(X2)。这意味着很难找到两个不同的消息产生相同的认证码。这个属性确保了在给定一个消息的情况下，很难找到另一个与之碰撞（具有相同认证码）的消息。 强碰撞抗性 很难找到任意两个不同的消息X1和X2，使得MAC(X1) = MAC(X2)。这意味着在整个消息空间中，很难找到任意两个不同的消息具有相同的认证码。这个属性确保了在整个消息空间中，很难找到任意两个碰撞（具有相同认证码）的消息。 通过加密进行身份验证 CBC-MAC 计算过程 将待认证的消息M分割成长度为n位的L个块（$M=M_1,...,M_L$） 选择一个秘密密钥K，用于加密算法E。 选择一个随机的初始向量（IV），作为初始的前一个密文块$C_0$ $Ci = E_K(M_i+C{i–1})i = 1, 2, . . ., L$ 对于每个消息块Mi，使用加密算法E和密钥K对其与前一个密文块Ci-1进行加密运算，得到当前密文块Ci。 $CBC-MAC=C_L$ 将最后一个计算得到的密文块CL作为CBC-MAC的输出，作为消息M的认证码。 $MAC_K(M) = (C_0, C_L) = (IV, CBC-MACK(M))$ 将初始向量$C_0$和最后一个密文块$C_L$组合在一起，形成完整的CBC-MAC认证码$MAC_K(M)$ 通过哈希进行身份验证 输· 入要小于$2^{64}$bits，划分为512bits的块 对数据进行进行扩展，使得长度满足448(mod 512) 填充一个1和多个0 最后64位为原始数据的长度 由初始向量与块中的每个单元进行计算处理得到最终的校验数 &&MD5 长度：128bit 使用一个四个字的缓冲区（一个分组）（16字节，128bits），初始值为01234567, 89abcdef, fedcba98, 76543210(16进制)作为计算的起点 此后均使用上一次计算的结果作为初始值 处理一个块（512bits）需要拆分为16个字（32bits) 将消息分成长度为16个字的块进行处理，每个块由 M0, M1, … M15 组成，$M_i$表示块中的每个字 处理消息块的过程分为4个阶段（即主循环有四轮,内层循环有16轮），每个阶段Using F, modular +, and left rotation进行处理 MD5对一个block数据要进行16次（512/32）完全相同的一套完整操作，一套完整的操作包括4轮向量运算。也就是说，每32bits明文数据为一个单位，要进行4轮的向量运算；而每一个block要对16个（32bits）单位明文数据进行运算，共计64次。 每个阶段包括16个相似的操作，用于处理块中的每个字。 M是要进行处理的数据的一个16个字的块 SHA-1 160bit 使用5个字，初始值67452301, efcdab89, 98badcfe, 10325476, c3d2e1f0 将消息分成长度为16个字的块进行处理，每个块由 M0, M1, … M15 组成，$M_i$表示块中的每个字 有四个阶段，每个阶段使用不同的F进行处理，并且包含20个操作 数字签名 一种不依赖对称密钥的使用公私钥的认证过程 Bob使用私钥对生成的校验码进行加密 Alice使用公钥对加密的校验码进行解码，并与重新计算的到的校验码进行比较 密钥分发 问题 在安全通信中，Alice和Bob需要共享一个秘密密钥，但问题是如何安全地将密钥传输给对方 在公钥加密中，Alice需要确定接收到的公钥确实属于Bob，而不是被篡改或伪造。 解决方法 Diffie-Hellman密钥交换协议 通过公开的通信渠道协商出一个共享的秘密密钥，而不需要在传输过程中直接共享密钥。该协议基于数学问题的难解性，确保第三方无法推断出实际的密钥值。 可信任的认证机构（CA） 使用机构颁发的数字证书，包含了相关信息，并由CA签名以证明其真实性。Alice可以通过CA验证身份。 公钥证书 是由CA签发的包含公钥及其相关信息的文档。证书中的公钥可以被Alice使用，而CA的签名则提供了对公钥真实性的保证。通过获取Bob的公钥证书并验证其合法性，Alice可以确保她拥有正确的Bob公钥。 Diffie-Hellman 过程 选择一个知名的大质数P，以及P的一个原根g（增加破解的复杂度） A从$Z_P^*$选择一个数$x$，把$X=g^x(modP)$发送给B B从$Z_P^*$选择一个数$y$，把$Y = g^y(modP)$发送给A A得到密钥$Y^xmodP$ 即($g^{xy}modP$) B得到密钥$X^ymodP$ 会受到中间人攻击，但无法直接通过窃听获得密钥 ​ 可信任的认证机构 会话密钥是一种在逻辑连接期间使用的密钥。它会在会话结束时销毁，并且不是永久性的密钥。 Permanent key主要作用是用于密钥分发。 CA负责确定发送方和接收方的身份有效性，并为该连接提供一个会话密钥。会话密钥用于在通信过程中的加密和解密操作。 The Needham-Schroder Protoco 由于公钥加密算法通常不适合对大块消息进行加密，因此在通信中，使用一次性会话密钥来实现加密。 安全服务模块（Security Service Module，SSM）在整个通信链路中扮演重要角色。SSM负责执行端到端的加密操作，并获取用于主机的密钥。 初始状态下AS、C、S都有各自的长期公私密钥 C向AS发送请求，希望与S进行对话 AS为CS的会话生成密钥$K_{cs}$并用AS和S之间共享的公钥进行加密，外面再用C和AS之间共享的公钥进行加密 C收到信息后用私钥进行解码得到K，然后把内层加密的K发送给S，S使用私钥进行解码 S使用AS提供的CS之间的会话密钥加密随机数发送给C，C解码后得到N，计算出N-1再加密后返还给S，确认通讯建立（建立对称加密） 公钥证书 另一种密钥传输方式 Bob准备一条消息，将要发送给Alice。 Bob使用对称加密算法，使用一个一次性会话密钥对消息进行加密。 Bob使用Alice的公钥对一次性会话密钥进行加密。 Bob将加密后的一次性会话密钥附加到消息上，并将消息发送给Alice。 Alice收到消息后，使用自己的私钥解密获取一次性会话密钥。 Alice使用一次性会话密钥对消息进行解密，以获取原始的明文消息。 问题：公钥可能并不是A的，B可能被欺骗 因此引入公钥证书 公钥证书包含： 公钥 用户ID CA颁发的带有时间戳的证书 由此其他人无法用自己的公钥来替代A的公钥，因为CA的签名是无法伪造的（使用私钥加密，公钥解密-身份认证） 首先申请者准备好信息内容，使用hash生成校验码，发送给AC，AC使用公钥进行认证 序列号：每个证书都有一个唯一的序列号，用于标识该证书的唯一性。 证书所有者信息：包括证书所有者的相关信息，如姓名、电子邮件地址等。还包括算法和密钥值相关的信息，用于指定证书的加密和签名算法。 证书颁发者信息：包括证书颁发者（CA）的相关信息，如名称、电子邮件地址等。还包括证书的有效日期范围，即证书的生效日期和过期日期。 数字签名：证书颁发者会对证书的内容进行数字签名，以确保证书的完整性和真实性。签名结果也称为指纹（thumbprint）或摘要（fingerprint），它是对证书内容进行哈希计算得到的固定长度的值。 邮件PGP Alice生成一个随机的对称密钥$K_s$ 同时发送使用对称密钥加密的信息$K_s(m)$和使用Bob的公钥加密的$K_B(K_s)$ Bob使用私钥解码得到对称密钥再得到信息m Alice希望提供发送者身份验证和消息完整性 Alice发送m和m的校验码$H(m)$（使用私钥进行加密，防止被篡改）方便Bob与m进行比对 若Alice希望提供保密性、发送者身份验证和消息完整性 对上面的m和$H(m)$再使用对称密钥进行加密，同时传输使用Bob的公钥加密的对称密钥 传输层网络安全 端到端加密 传输层加密可以确保数据在传输过程中的保密性，但在网络中的其他节点上可能仍然可以观察到传输的元数据（如源IP地址、目标IP地址、端口号等）。 SSL标准 保护应用数据安全传输，保护一个互动数据流（连接） 需要验证服务端的身份 加一层SSL，使用SSL的api发送数据，而不是tcp 理念 握手认证，双方通过公私密钥互相认证，得到一个统一的对称密钥MS（主密钥） 使用共享密钥传输一系列密钥（共享密钥作为生成种子） 使用生成的不同密钥数据分块传输 不同密钥 Kc：用于从客户端发送到服务器的数据的加密密钥。 Mc：用于从客户端发送到服务器的数据的MAC密钥。 Ks：用于从服务器发送到客户端的数据的加密密钥。 Ms：用于从服务器发送到客户端的数据的MAC密钥。 这些密钥是通过密钥派生函数（KDF）生成的。KDF接受主密钥和（可能还有）一些附加的随机数据，并创建这些密钥。 分块（最小单位，成为记录） 一个分组（数据包）会包含多条记录 将数据流分解为一系列块。每个块都携带自己的MAC，使得接收方可以在每个记录到达时立即进行处理。这样可以更快地在每个记录上检测篡改或损坏，而不需要等待整个数据流的接收完成。 问题：攻击者可以捕获并重放记录，或者重新排序记录。 在MAC中加入序列号： MAC = MAC(Mx, sequence || data) 问题：攻击者可以重放所有记录。 解决方案：使用一次性数字（nonce）标记数据。 安全关闭连接 问题：截断攻击。 攻击者可以伪造TCP连接关闭段。 解决方案： 使用记录类型，并为连接关闭操作定义一个特殊的记录类型。即使用加密和MAC保护信息 类型0表示数据记录。 类型1表示连接关闭记录。 真实SSL SSL是一个基于TCP的安全协议，旨在为通信提供保密性、完整性和身份验证。它通过在TCP协议之上添加两层协议实现安全性。 服务组成 记录（块）协议（Record Protocol）：提供基本的安全服务给各种高层协议使用。它负责将数据分割成记录，并对每个记录进行加密、完整性校验和解密等操作。 在SSL中，还有三种管理SSL交换的高层协议，这些协议嵌入在特定的软件包中，如IE（Internet Explorer）或Netscape中。这些高层协议用于管理SSL握手过程、证书交换、密钥协商和身份验证等操作。 首先服务器和客户端之间需要通过握手协议建立会话session 在这个关联中，每个实体（客户端和服务器）都具有一组密码安全参数 对等方（服务器）的证书：用于公钥的验证和身份认证。 48字节的主密钥：用于共享密钥的生成。 压缩算法、加密算法或MAC（哈希）算法的选择：用于通信数据的压缩、加密和完整性保护。 这种关联可以在一个应用程序的客户端和服务器之间建立多个（TCP）连接。这样做的目的是避免为每个连接都重新协商新的安全参数。通过共享已建立的关联，可以节省计算资源和时间。 数据结构 应用层协议功能 更改密码规范协议 一个单个字节的消息，其值设置为1 服务器和客户端进行沟通，决定要选择的加密策略与算法（双方都支持的交集） 警报协议 警报消息会被压缩和加密以保证安全性。 警报级别：可以是1（警告）或2（严重）。 如果级别为严重（2），SSL会立即终止连接。（但是一个session会有多个连接，其他连接不会被立即关闭，但是会话不再接受新的连接的建立） 如果级别为警告（1），SSL会继续进行，但会向对等实体发出警告。 警报描述：根据情况不同，可能有不同的描述。 严重警报描述（Fatal）包括：UnexpectedMessage（意外的消息）、BadRecordMAC（错误的记录MAC）、HandshakeFailure（握手失败）等。 警告警报描述（Warning）包括：CloseNotify（关闭通知）、Certificate Unsupported/Revoked（证书不支持/已废止）、Illegal Parameter（非法参数）等。 握手协议 身份验证发送方/接收方：握手协议用于验证通信的发送方和接收方的身份。这确保了通信双方的身份是可信的，并防止中间人攻击。 协商加密算法、MAC算法和密钥：握手协议用于协商通信双方所使用的加密算法、消息认证码（MAC）算法和密钥。通过协商这些参数，握手协议确保了通信的保密性和完整性。 握手协议通常包括四个回合 建立安全能力：通过握手协议，客户端和服务器之间建立了SSL连接，并确定了双方的安全能力。这包括使用的加密算法、MAC算法和密钥长度等参数。 服务器鉴别与密钥交换：服务器在握手过程中对自身进行身份验证。它向客户端提供适用于共享密钥分发的公钥，以确保通信的安全性。 客户端验证服务器并开始密钥交换：客户端对服务器进行验证，并开始进行密钥交换。这确保了客户端与合法的服务器进行通信，并建立了共享密钥。 交换确认：在握手过程中，各个阶段都会进行确认，确保握手的每个步骤都得到了正确执行。 根据协商更改密码规范：一旦握手协议的各个阶段完成，通信双方根据协商的结果改变密码规范。这意味着双方根据握手协议中达成的协议更改加密算法、MAC算法和密钥等参数。 *握手协议的具体过程 握手报文也要MAC，防止被篡改（如删除更安全的方法） phase1 主要用于双方的初步沟通，确定协议方案、算法等选择 ClientHello消息由客户端发送给服务器，其中包含以下字段： vC：客户端支持的SSL/TLS版本。 r1：随机数（nonce），用于加密密钥生成。 sid：当前会话ID（如果是新会话，则为0）。 Ciphers：客户端支持的加密算法列表。 Comps：客户端支持的压缩算法列表。 ServerHello消息由服务器发送给客户端，其中包含以下字段： V：客户端和服务器都支持的最高SSL/TLS版本。 r2：随机数（nonce），用于加密密钥生成。 sid：当前会话ID（如果是新会话，则为0）。 Cipher：要使用的加密算法。 Comp：要使用的压缩算法。 在第一轮握手之后，，服务器进行选择，客户端得知以下信息： SSL版本。 密钥交换、消息认证和加密算法的加密算法。 压缩算法。 用于密钥生成的两个随机数。 客户端和服务端使用相同的导出函数以及随机数导出相同的主密钥MS 使用共享主密钥MS切片得到用于加密不同部分的密钥以及随机向量等信息，用于之后的加密传输 需要两个随机数，假设Trudy窃听了Alice和Bob之间的所有消息。第二天，Trudy与Bob建立了一个TCP连接，并发送了完全相同的记录序列。Bob（Amazon）会认为Alice对同一件事进行了两次不同的订单。为了解决这个问题，Bob在每个连接中发送不同的随机数（nonce）。这样会导致两天的加密密钥不同，确保了安全性。 phase2 certificate服务器证书：在建立新会话时，服务器需要提供其证书给客户端。 server_key_exchange密钥交换： certificate request 客户端证书（可选）：服务器可能要求客户端提供其证书 Server_hello done：一旦服务器完成必要的握手步骤，包括证书交换和密钥协商，它会发送Server_hello done消息，表示服务器握手阶段已完成。 phase3(可选，客户端证明自己的身份) certificate证书验证（如果需要）：客户端可能需要验证服务器提供的证书的有效性。 client_key_exchage：客户端将生成的密钥用服务器公钥加密并返回 检查Server_hello参数 发送密钥信息 phase4（进行最终的验证和确认） 客户端发送change_cipher_spec消息：客户端将等待中的CipherSpec复制到当前的CipherSpec中，表示要使用新的加密和认证算法。这个消息使用Change Cipher Spec协议发送。 客户端发送finished消息：在新的算法、密钥和密钥信息下，客户端发送finished消息。该消息用于验证密钥交换和认证是否成功。它包含对之前握手阶段的摘要，以确保握手过程的完整性和正确性。 客户端和服务器会分别生成一个\"Finished\"消息，用于验证握手过程的完整性。\"Finished\"消息中包含一个散列值（Hash），该散列值是使用握手过程中协商的密钥和参数对握手消息进行摘要计算得到的。客户端和服务器会根据各自的计算结果生成并发送\"Finished\"消息。 接收到对方发送的\"Finished\"消息后，接收方会进行验证。它会使用相同的密钥和参数对收到的握手消息进行摘要计算，然后将计算结果与对方发送的\"Finished\"消息中的散列值进行比较。如果计算结果匹配，说明握手过程的完整性得到了确认，连接建立成功。 即确认之前握手过程中的报文没有被篡改 这两次发送MAC都包含了发送之前所有的握手报文 服务器发送change_cipher_spec消息：服务器响应客户端的change_cipher_spec消息。它将等待中的CipherSpec转移到当前的CipherSpec中，表示服务器也要使用新的加密和认证算法。然后，服务器发送自己的finished消息。 服务器发送finished消息：服务器在新的算法、密钥和密钥信息下发送自己的finished消息。这个消息用于验证密钥交换和认证是否成功，并确认握手过程的完整性和正确性。（比上面第一次发多了两条新记录） 每个上层消息在传输之前被分割成较小的片段。如果启用了压缩，压缩后的消息加上消息认证码（MAC）会使用对称加密进行加密。 PDU 会在协议数据单元（PDU）前添加SSL记录头部，并将整个PDU通过TCP段进行传输。 协议类型（1个字节）：指示记录类型。其中20表示change_cipher_spec（变更密码规范）、21表示警报、22表示握手、23表示应用层数据。 主要版本号（1个字节）：指示SSL的主要版本。SSL v3的主要版本号是3。 次要版本号（1个字节）：指示SSL的次要版本。SSL v3的次要版本号是0。 压缩长度（2个字节）：指示压缩后的消息长度。每个字节可以达到最大值214+2048。 MAC（0、16或20个字节）：用于消息完整性检查的消息认证码。其长度根据使用的MAC算法而变化。 网络层网络安全 ip加密，站到站 网络层加密提供了更高级别的安全性，保护整个通信链路中的数据和通信元数据。 IPSec 服务： 数据完整性 发起者认证 防止重放攻击（Replay Attack Prevention）这确保了接收方不会接收到重复的或过期的数据包。 保密性（Confidentiality） 应用示例： 分支机构通过互联网连接：IPsec可以用于建立安全的分支机构与总部之间的通信连接，以保护数据的机密性和完整性。 安全的远程访问（用户到站点） 服务器之间的流量加密 增强的电子商务安全性 VPNs（虚拟私有网络） 动机： 机构通常希望建立私人网络以增强安全性。 传统的私人网络建设成本较高，需要使用独立的路由器、链路和DNS基础设施。 VPN可以通过在公共互联网上发送机构的办公室间流量，从而降低成本。 VPN会在数据进入公共互联网之前进行加密，确保数据的安全性。 VPN在逻辑上与其他流量隔离，实现了逻辑上的分离。 目的： VPN的主要目的是在公共互联网上建立安全的通信通道，用于机构内部的数据传输。 通过对数据进行加密，VPN确保数据在通过公共互联网传输时的保密性。 VPN使机构的办公室间流量在逻辑上与其他公共互联网流量隔离，提供了一定程度的隐私和安全保护。 传输模式和隧道模式 传输模式 传输模式提供端到端的加密，主要用于远程访问场景。 使用传输模式，终端设备必须实现IPsec协议。 在传输模式下，IPsec仅对IP数据包的有效负载进行加密，而IP头部保持原样。 传输模式通常用于直接连接的通信，例如远程用户与企业内部网络之间的通信 隧道模式 隧道模式通常用于防火墙之间的通信，并用于构建虚拟私人网络（VPN）。 使用隧道模式，IPsec会加密整个IP数据包，包括IP头部和有效负载。IP数据包的头部中的IP地址是IPSec网关的地址，而不是实际的源和目的地址。 隧道模式用于在不安全的网络上加密所有流量，确保通信的机密性和安全性。 在隧道模式下，通信的两端需要配置IPsec隧道，以便在两个隧道终点之间进行加密和解密。 IPsec协议策略 认证协议AH 认证协议用于提供数据包的认证，但不对消息进行加密。 AH协议通过在IP数据包中添加认证头部来实现数据的完整性验证和源身份验证。 AH协议负责在整个IP数据包上进行额外的数据完整性校验，并验证数据的源身份。 封装安全载荷协议ESP 封装安全载荷协议提供了消息的加密和认证。 ESP协议通过将IP数据包的有效载荷进行加密和认证来保护数据的机密性和完整性。 分为头部和尾部，夹住数据 头部提供了协议参数和选项的定义和传递，尾部则提供了完整性保护和数据验证的能力。 ESP协议负责对有效载荷进行加密，并添加校验码以验证数据的完整性。 Internet密钥交换协议AKE IKE协议用于在两个对等体之间协商安全功能和密钥。 用于建立和管理IPsec安全关联 SA安全关联 在发送数据之前，发送方和接收方之间会建立一个称为\"安全关联\"的SA，用于定义双方之间的单向关系。用于描述安全通信的参数和策略。 为了进行全双工通信，通常需要建立两个SA。 发送方和接收方维护关于SA的状态信息，类似于TCP端点维护的状态信息。 IP是无连接的，而IPsec是面向连接的，因此需要建立和维护SA来确保安全通信。 安全参数索引（Security Parameters Index，SPI）用于确定接收到的数据包应该使用哪个SA进行处理。 每个主机都有一个包含SA的表，SPI是用于查找特定SA的索引(用于标识和区分不同安全关联SA)。 SPI在两个对等体之间具有本地意义，没有全局意义。 配置内容 SA标识符：（SPI） 源SA接口 目的SA接口 安全协议（AH&ESP） 使用的加密类型（DES、AES） 加密密钥 认证密钥 帧结构 ESP Header：用于封装加密和认证的数据。它包含ESP的各种参数和选项，如加密算法、认证算法、SPI等。 SPI：SPI是一个32位的标识符，用于唯一标识与IPsec相关的安全关联。 Seq#（Sequence Number）：Seq#是一个用于序列化IPsec数据报的字段，用于确保IPsec数据报的顺序性和完整性。 ESP通过使用序列号字段在ESP头部中防止重放攻击。 每当在SA上发送数据报时，发送方会递增序列号计数器，并将其放置在序列号字段中。 ESP Trailer：ESP尾部，包含填充字段和填充长度等。 Authenticated Padding：填充字段，用于填充ESP尾部的长度，以满足加密算法的要求。 Pad Length：填充长度字段，指示填充字段的长度。 Next Header：下一个头部字段，指示在ESP封装后的数据中紧随ESP头部之后的下一个头部类型。 ESP auth校验码 使用共享的密钥创建的消息认证码（MAC），用于验证数据的完整性和防止数据被篡改。 生成过程 R1将原始数据报追加到IPsec数据报的末尾 R1使用SA指定的算法和密钥对数据进行加密 R1在加密数据前附加ESP头部 R1使用SA指定的算法和密钥创建认证MAC R1将认证MAC附加到\"enchilada\"的末尾。 R1创建全新的IP头部：R1创建一个全新的IP头部，其中包括经典的IPv4头部字段。这个新的IP头部位于有效载荷的前面，形成了最终的IPsec数据报。 IKE 互联网key交换协议，帮助建立ipsec连接 内容 协商安全算法 身份验证 交换对称会话加密密钥 功能 密钥交换：IKE协议提供一种安全的方式来交换对称密钥或非对称密钥，以便在通信节点之间建立安全通信。它使用Diffie-Hellman密钥交换算法，允许节点在不直接交换密钥的情况下生成共享密钥。 身份认证方式 PSK预共享密钥 通信双方事先共享一个秘密密钥（如使用Diffie-Hellman生成）。它们使用IKE协议来相互验证身份并生成IPsec安全关联，不会暴露自己的公私钥造成信息的泄露。 PKI公钥基础设施 通信双方分别拥有公钥和私钥，并持有相应的证书。它们使用IKE协议来相互验证身份，并获取IPsec安全关联（协商算法与加密方式等信息）。 补充 无线网络安全 802.11标准 使用身份认证+加密 采用\"有线等效隐私\"（Wired Equivalent Privacy，WEP）但这一方法被证明存在漏洞，安全性不足。（现在实际使用的是802.11i） 它使用共享密钥，由一个40位的主密钥（WEP密钥，加密和解密数据的共享密钥）和一个24位的初始化向量（IV）组成（每个帧内使用一个）。（IV用于增添一些随机性，生成密钥流） WEP没有密钥分发机制，密钥需要手动设置。（wifi密码） 入点（Access Point）假设只有移动设备具有密钥。 802.11i 身份验证服务器与接入点分离(类似需要登录的wifi网络) 通过使用独立的身份验证服务器，可以实现更强大的加密方式，并且提供更安全的密钥管理。身份验证服务器可以负责生成和分发密钥，确保只有授权的设备能够访问网络。 通过将身份验证和密钥管理功能与接入点分离，可以提供更灵活、可扩展和安全的无线局域网解决方案，使得不同的加密算法和安全机制可以根据需要进行配置和使用。 移动主机和身份验证服务器进行相互认证，确保彼此的身份合法性和信任关系。 在认证成功后，移动主机和身份验证服务器共同生成主密钥（KS）。这个主密钥将用于后续的密钥派生和加密过程。 身份验证服务器将生成的主密钥（KS）发送给接入点（AP）。接入点在后续的通信中将使用这个主密钥进行密钥派生和临时密钥（TK）的生成。 移动主机和接入点使用主密钥（KS）派生出临时密钥（TK），这个临时密钥用于消息的加密和完整性保护。这个临时密钥在通信过程中动态生成，提供了更高的安全性。 WEP 认证 移动设备向接入点发送认证请求。 接入点回复一个128位的随机数（用于防止重播攻击（录制））。 移动设备使用共享的主密钥（KS）对随机数进行加密。 接入点解密随机数并对移动设备进行认证。 加密 使用主密钥和初始化向量，生成一串密钥流。（种子） 加密器确保相同的64位密钥生成相同的密钥流。 密钥流与明文和校验和进行异或操作，生成密文。 安全漏洞 如果IV是随机分配的，预期在5000个数据帧中会出现一次重复使用的情况。如果IV是顺序分配的，那么在每次启动时都会重新使用IV。 并且IV明文传输，因此IV的重复是会被察觉的 如果攻击者（Trudy）引导Alice加密一个已知的明文P1，一旦IV重新出现，攻击者就能够知道对应的加密后的密文P2。 对相同的密钥C进行两次加密会使得加密失效 或者如果等待两个回合*（相同随机IV输入相同的数字）这杨就能完全解出公钥的序列 防火墙 理念 将组织的内部网络与更大的互联网隔离开来。 允许某些数据包通过，阻止其他数据包。 确保内部网络和系统免受外部的黑客和恶意软件的攻击。 功能 防止拒绝服务攻击：通过阻止攻击者建立伪造的TCP连接或尝试ping攻击来防止SYN洪泛等类型的拒绝服务攻击。（占用服务器资源，使得服务器无法正常服务用户） 仅允许授权的访问进入内部网络：通过设置经过身份验证的用户/主机集合，只允许授权用户/主机访问内部网络。 防止对内部数据的非法访问/修改：防止未经授权的用户访问或修改内部数据。 分类 无状态数据包过滤器：基于数据包的源地址、目标地址、端口等信息进行过滤，没有记忆或状态跟踪能力。 有状态数据包过滤器：除了基于数据包的信息进行过滤外，还具有状态跟踪功能，可以检测和控制数据包的状态和连接。 应用程序网关：也称为代理服务器，它在应用层对网络流量进行过滤和代理，提供更高级的安全性和控制。 无状态数据包过滤 防火墙通过检查到达的数据包来确定是否允许进入，同时也检查出去的数据包 依据 源IP地址和目标IP地址 TCP/UDP源端口和目标端口号 ICMP消息类型 TCP的SYN和ACK位 例子 阻止传输层协议字段为17的入站/出站数据报 所有的入站和出站UDP流量都被阻止 阻止源端口或目标端口为23的入站/出站数据报 所有telnet连接（bbs）都被阻止 阻止ACK位为0的入站TCP段 防止外部客户端向内部主机建立TCP连接（即DOS攻击） ACL表：控制通过策略 有状态数据包过滤 有状态的数据包过滤器：跟踪每个TCP连接的状态 跟踪连接的建立（SYN）和关闭（FIN）：确定入站和出站数据包是否“合理” 在防火墙上超时处理不活跃的连接：不再允许该连接的数据包通过 在访问控制列表（ACL）中增加了一个指示，在允许数据包通过之前需要检查连接状态表。 应用程序网关 更高级的应用网关可以在应用数据以及IP/TCP/UDP字段上过滤数据包。例如，允许选择的内部用户进行telnet外部访问，但用户认证应该在应用程序级别进行。 应用网关要求TCP连接必须通过网关进行中继。路由器过滤器会阻止所有不是源自网关的TCP连接。这种方式可以提供更精细的控制和认证，因为所有的TCP连接都必须经过应用网关进行处理和转发。 "},"asserts/应用层.html":{"url":"asserts/应用层.html","title":"U5 应用层","keywords":"","body":"概述 进程：指在计算机系统中正在运行的程序的实例。每个进程都有自己的内存空间和执行环境，可以与其他进程进行通信。 进程间通信：是指在同一个主机上运行的两个进程之间进行通信的方式。操作系统提供了一种机制来支持进程间的数据传输和交互。 应用层协议（App-layer protocol）：用于在不同主机上运行的进程之间进行通信的协议。不同的应用程序（如Web、电子邮件、流媒体）使用不同的应用层协议来实现数据交换和通信。 用户代理：是介于应用程序和网络之间的接口。它实现了用户界面和应用层协议，使用户能够与应用程序进行交互，同时通过网络与其他主机上的进程进行通信 用户层协议的内容 消息交换的类型：应用层协议规定了在不同进程之间交换的消息类型。 消息类型的语法：应用层协议规定了消息类型的语法。它定义了消息中的字段以及如何划分字段。 消息中的字段和字段的语义：应用层协议规定了消息中字段的含义。它确定了字段中包含的信息的含义和解释。 进程何时以及如何发送和响应消息的规则：应用层协议定义了进程发送和接收消息的规则。它规定了进程何时发送消息、如何构造消息、如何发送消息以及如何对收到的消息做出响应。 分类 client-server client向server发送请求，开启会话，通常具有动态ip server始终开机，等待client的信息并进行服务，通常具有固定ip peer-to-peer (P2P) 不是一直可用，分布式，不一定一直开机 节点之间是动态链接的 新的节点加入既会索求资源，也会加入服务资源 BitTorrent, Skype DNS 位于应用层 功能：实现从域名到ip的映射 使用UDP进行传输 内容 分发数据库： 应用层协议：host和服务器沟通获得信息进行映射 负载均衡：同一个域名可能被映射到不同ip 分布式系统 目标： 唯一性：域名不能有冲突 可扩展性：系统或网络具有应对不断增长的负载和需求的能力，可以频繁进行更新。 分布式、自治性管理 可以更改自己的信息 不需要跟踪（记录）全世界的所有信息 高可用性 迅速 不追求强一致性（可以偶尔出错） 域名层次结构 将命名空间进行划分，即将系统中的命名空间分成多个部分。每个分区的管理将被分配给不同的实体，这样每个实体就可以自主更新自己的机器名称，而不需要追踪其他人的更新。 关键思想：层次结构 层次化的命名空间 层次化管理 从根节点向下划分域名 完整域名是从根节点从下向上 通常最深128层 使用树形结构可以避免域名冲突 每个节点各自管理自己为根的子树 每个服务器存储总DNS数据库的一个（小）子集：这意味着DNS数据库被分割成多个部分，并分布在不同的服务器上。每个服务器只存储与其具有管理权限的域相关的资源记录。 如*.nju.edu.cn 运作原理 根域名服务器：这些服务器是DNS系统的顶级服务器，它们保存了顶级域名的信息，例如.com、.org、.net、.edu等，以及所有顶级国家域名，如.cn、.uk、.fr等。当本地名称服务器无法解析某个名称时，它会向根域名服务器发送请求。 顶级域名服务器（TLD）：这些服务器负责管理顶级域名，如.com、.org、.net、.edu等。它们也管理所有顶级国家域名，如.cn、.uk、.fr等。 授权DNS服务器：这些服务器属于组织或机构，提供对应用程序的域名到IP地址的授权映射。它们维护着特定域名的权威信息，当有其他DNS服务器查询特定域名时，授权DNS服务器提供正确的映射。 授权DNS服务器存储某个域中所有DNS名称的“资源记录”：授权DNS服务器负责存储其具有管理权限的域中所有DNS名称的资源记录。这包括该域中每个主机名对应的IP地址等信息。 授权DNS服务器是组织自己的DNS服务器，用于提供对该组织命名主机的权威域名到IP地址的映射。这些服务器可以由组织自行维护，也可以由服务提供商来维护。 本地名称服务器：每个住宅ISP、公司、大学都维护着自己的本地名称服务器。当主机发起DNS查询时，查询被发送到本地名称服务器，它负责处理查询并尝试解析域名。如果本地名称服务器无法解析域名，它会向更高级的DNS服务器发送查询请求。（负责向上查询） 本地名称服务器不严格属于DNS层次结构：本地名称服务器不直接属于DNS的层次结构，它是每个ISP（住宅ISP、公司、大学）都拥有的一个服务器。它也被称为“默认名称服务器”。 当主机进行DNS查询时，查询会发送到其本地名称服务器。 本地名称服务器具有最近的名称到地址转换对的本地缓存（但可能过期）：本地名称服务器会缓存最近的名称到地址转换对，以提高查询的性能。但是，这些缓存可能会过期，因此可能不是最新的。 本地名称服务器充当代理，将查询转发到层次结构中：本地名称服务器充当代理，将主机的查询转发到DNS层次结构中的其他服务器，以获取所需的解析结果 每个服务器需要知道负责其他层次结构部分的其他服务器：为了能够正确解析域名并提供准确的资源记录，每个服务器都需要了解负责其他层次结构部分的其他服务器的存在。这样，当某个服务器无法解析特定域名时，它可以向负责该域名的服务器发送查询请求。 每个服务器都知道根服务器：为了建立整个DNS层次结构，每个服务器都需要了解根服务器的存在和位置。根服务器保存了所有顶级域名的信息，并可以提供对其他DNS服务器的查询引导。 查询过程 DNS记录 name为字符串 value为ip值 type表示类型 ttl表示生命周期 保存在cache中 可靠性 复制的DNS服务器（主/备份）：主服务器是主要的服务器，而备份服务器是在主服务器不可用时提供备份服务的服务器。 只要至少有一个复制服务器正常工作，服务就可用 查询可以在复制服务器之间进行负载均衡：查询可以在多个复制服务器之间进行负载均衡，以分担服务器的负载和提高性能。 如果需要可靠性，必须在UDP上实施可靠性机制，例如通过重试和超时处理来确保查询的可靠传输。 如果在查询过程中发生超时，可以尝试使用备用服务器进行查询。 在重试相同服务器时，可以使用指数退避策略，逐渐增加重试的间隔时间，以避免对服务器造成过大的负载。 对于同一个查询，所有的复制服务器都使用相同的标识符，以便可以识别和跟踪查询的状态和结果。 对于发起查询的客户端来说，并不关心哪个复制服务器响应查询，只要能够获得有效的解析结果即可。 快速查询 进行所有这些查询需要时间：执行所有的DNS查询需要一定的时间。这些查询包括从根服务器到顶级服务器再到授权DNS服务器的一系列查询，这可能导致下载之前的延迟。 缓存可以大大减少开销：DNS缓存可以大大减少DNS查询的开销。因为顶级服务器很少更改，并且访问频率较高的常用网站的信息通常被本地DNS服务器缓存。 DNS缓存的工作原理：DNS服务器会缓存对查询的响应结果。响应结果中包括一个“存活时间”（TTL）字段，它指示了该条目在缓存中的有效期。当TTL到期后，服务器会删除缓存中的条目。 email 常见协议 SMTP（简单邮件传输协议）：用于传递简单文本消息的协议。它是电子邮件系统中用于发送邮件的主要协议。 MIME（多用途互联网邮件扩展）：用于传递各种类型的数据，例如声音、图像、视频剪辑等，扩展了SMTP协议的功能。 POP（邮局协议）：用于从服务器中检索邮件的协议，包括授权和下载邮件。当用户通过邮件客户端下载邮件时，通常使用POP协议。 IMAP（互联网邮件访问协议）：用于在服务器上操作存储的邮件的协议。IMAP允许用户在不下载邮件到本地计算机的情况下，在邮件服务器上直接管理和操作邮件。 用户代理（客户端）（User Agent）：用户代理是指用于组织、编辑和阅读邮件消息的软件应用程序。例如，Eudora、Outlook、Foxmail、Netscape Messenger等都是常见的用户代理。用户可以使用用户代理来编写、编辑、发送和接收邮件消息。发送的邮件消息和接收的邮件消息都存储在邮件服务器上。 邮件服务器（Mail Servers）：邮件服务器是指用于处理电子邮件的服务器。它包括两个主要组件：邮箱（Mailbox）和消息队列（Message Queue）。 邮箱（Mailbox）包含了用户接收的邮件消息。当其他用户向该用户发送邮件时，邮件服务器会将这些邮件消息存储在相应的邮箱中，以便用户可以检索和阅读。 消息队列（Message Queue）包含了等待发送的邮件消息。当用户发送邮件时，邮件服务器会将这些邮件消息存储在消息队列中，以便逐一发送到目标地址。邮件服务器之间使用SMTP协议进行邮件消息的传输。 邮件的构成 传输过程 email从本地用户端发送到SMTP服务器 本地用户作为SMTP客户端，本地服务器作为SMTP服务器 本地服务器发送到远程SMTP服务器 本地服务器作为SMTP客户端 远程服务器使用access protocol to access the mailbox on remote server POP3 or IMAP4 Alice使用用户代理（UA）撰写一封邮件消息，并发送给bob@someschool.edu。 Alice的用户代理通过SMTP协议将邮件发送到她的邮件服务器，并将邮件放置在消息队列中。 SMTP客户端在客户端与Bob的邮件服务器之间建立TCP连接。 SMTP客户端通过TCP连接发送Alice的邮件。 Bob的邮件服务器将邮件放置在Bob的邮箱中。 Bob使用他的用户代理（UA），例如通过POP3协议，来读取邮件。 SMTP传输协议 使用ASCII码文字作为交互命令 RFC 821： 使用TCP协议的25号端口进行通信。 直接传输：将电子邮件消息从客户端直接传输到服务器。 需要在邮件信封（即消息头）上写入相关信息，以确定邮件的传递路径。 可以在消息头中添加日志信息，以显示邮件的传递路径。 RFC 821并不涵盖邮件消息或数据的格式。邮件消息的格式定义在RFC 822或MIME中。 邮件消息必须采用7位ASCII编码。 过程 握手 传输数据 关闭连接 可靠性 使用TCP进行传输，依赖于TCL的可靠性 不保证可以找回丢失的邮件 没有端到端的确认（回执，确认收到已读） 可能只是传输到了服务器，而没有到用户手中（可能未读） 通常是比较可靠的 邮件获取协议 从服务器获取收到的邮件 POP（邮局协议）：POP是一种用于电子邮件系统的协议，定义在RFC 1939中。它用于用户代理（邮件客户端）与邮件服务器之间的授权验证和邮件下载过程。使用POP协议，用户可以授权访问邮件服务器上的邮件，并将邮件下载到本地计算机进行阅读和处理。 IMAP（互联网邮件访问协议）：IMAP是一种用于电子邮件系统的协议，定义在RFC 1730中。IMAP相比于POP具有更多的功能。除了授权验证和邮件下载外，IMAP还提供了操作邮件服务器上存储的邮件的能力。用户可以在邮件服务器上直接管理和操作邮件，例如创建文件夹、移动邮件、标记已读或未读等。IMAP协议适用于需要在多个设备上同步邮件状态的场景。 HTTP（超文本传输协议）：HTTP是一种用于在互联网上传输超文本文档的协议，广泛用于网页浏览器和服务器之间的通信。某些电子邮件服务提供商（如Gmail、Hotmail、Yahoo!等）使用HTTP协议作为访问其电子邮件服务的接口。通过HTTP，用户可以使用网页浏览器访问电子邮件服务提供商的网页界面，进行邮件的发送、接收和管理操作。 pop3 过程 用户身份认证 获取数据/操作 可以选择下载并从服务器删除/继续保留 IMAP可以在线观看/编辑，邮件都保存再服务器上，服务器可以记录邮件阅读状态（在线修改） 编码 MIME多媒体拓展 所有数据内容使用文本（base64）进行编码，为了兼容其他的早期协议 以7位ASCII编码：MIME将邮件内容和附件中的所有数据都编码为7位ASCII字符集，以确保兼容性和可靠的传输。这意味着MIME邮件可以在任何支持ASCII字符集的系统上正确显示。 忽略非MIME邮件系统的头部和分隔符：非MIME邮件系统无法解析MIME邮件的头部和分隔符，因此会将其忽略。这样做可以确保MIME邮件在非MIME系统中的传递和显示。 MIME是可扩展的：MIME提供了一种可扩展的机制，允许定义和支持各种不同类型的数据和附件。通过使用适当的MIME类型和子类型，发送方和接收方可以约定一致的编码方案，以确保正确解析和显示邮件中的数据。 增加头部 多文件 FTP RFC 959, use TCP, port 21/20 同样使用ascii作为控制命令 客户端/服务器模型，相互传递文件 由客户端发起文件下载/上传请求 过程 建立两条信道：数据（tcp20）/控制（tcp21） 进行客户端身份认证 客户端收到文件列表，查看 客户端选择文件进行处理，服务端收到指令后开始执行（传输） Web \"World Wide Web (WWW)\" 万维网，它是由许多互连的文档（称为“页面”）组成的分布式数据库。这些页面通过超文本传输协议（HTTP）进行链接。 \"分布式数据库\" 指的是万维网上存储的大量页面，这些页面可以由全球范围内的多个服务器托管和提供。 \"页面\" 是包含文本、图像、音频、视频和其他媒体的文档，可以在浏览器中显示和访问。通过超链接，页面可以相互连接，形成一个网状结构。用户可以通过点击链接在页面之间进行导航。 HTTP（Hypertext Transport Protocol）是用于在万维网上进行通信的协议。它定义了客户端和服务器之间的请求和响应规范。当用户在浏览器中访问一个页面时，浏览器会向服务器发送一个HTTP请求，服务器会响应并返回所请求的页面。 架构：client-servers 内容： URL：为内容命名 HTML：页面内容 协议http URL 每个页面都有一个唯一的地址，称为统一资源定位符（URL），可以通过浏览器访问 格式://:/? 协议（Protocol）：用于传输或解释对象的方法，例如 HTTP、FTP、Gopher 等。协议指定了客户端和服务器之间通信的规则和约定。 主机（Host）：指对象所在的主机的 DNS 名称或 IP 地址。主机表示托管或提供对象的服务器的位置。 端口（Port）：可选项，指定服务器上用于与客户端通信的端口号。如果未指定端口，则会使用默认的协议特定端口（例如 HTTP 的默认端口为 80）。 路径（Path）：指对象所在文件的路径名，用于定位服务器上包含该对象的文件。路径可以包含文件夹和子文件夹的名称。 查询字符串（Query String）：可选项，用于将参数以名称/值对的形式发送到服务器上的应用程序。查询字符串通常用于向服务器提供额外的参数或数据。 HTTP 认为服务器总是开放，并且知名（公网ip） 客户端向服务器请求，初始化对话 request/reply 使用TCP：80 无状态性 每个请求-响应独立处理： 每个客户端请求和服务器的响应都被独立地处理，服务器不需要保留先前请求的状态。 这意味着服务器在处理每个请求时不需要考虑之前的请求或响应，它可以按需处理每个请求而无需维护连接状态。 服务器不需要保留状态： 服务器不需要保留客户端请求的状态信息，因为每个请求都被视为独立的事件。 这提高了服务器的可伸缩性，因为它不需要为每个连接保留大量的状态信息。 优点： 独立处理请求-响应使得故障处理更加容易。 服务器能够处理更高速率的请求，因为每个请求都是独立处理的。 请求的顺序对服务器来说不重要，因为每个请求都是独立的。 缺点： 某些应用程序需要保持持久状态，例如购物车、用户配置文件、使用情况跟踪等。 对于这些需要持久状态的应用程序，需要一种方式来唯一标识用户或存储临时信息。 使用ascii文本指令 HTTP1.1 分类 GET获取资源（页面） HEAD获取响应头 POST提交内容（表单） PUT上传文件 DELETE删除 cookie 状态存储在客户端 功能： 身份认证 信息存储（如购物车） 个性化推荐 问题：cookie可能会泄露信息，发送给网页服务器 如页面上的广告会根据信息推荐（如内嵌携程广告） 跨网站传输cookie 网页传输 目标 用户：速度快，高可用性 内容提供者：满意的用户，高效性（减少开销） 网络提供商：让网络性能满足需求、稳定 改进： 改进协议：http、tcp... 缓存，在多处存储内容，减少远距离传输 CDN等专用服务 http性能提升 网页上有很多object，图片等各种信息，早期http一次一个，效率很低（tcp传输大量小文件！） 早期暴力解决：同时发送多个请求 最终改进：一个TCP传输更多信息，不再需要建立那么多的连接，并且传输时间长，TCP更稳定到达更大速率 多个请求组合在一起发送，减少数据包数量 &&小文件延时（传输时间忽略） 逐个获取（One-at-a-time）： 当每个小对象都是逐个获取时，时间主要由网络延迟所主导。 在这种情况下，获取 n 个小对象所需的时间大约是 2nRTT 并发获取（Concurrent）： 如果能够并发获取多个小对象，可以减少获取时间。 当使用 m 个并发连接时，获取 n 个小对象所需的时间大约是 2[n/m]RTT。 持久连接（Persistent）： 当使用持久连接时，可以减少连接建立的开销。 在持久连接下，获取 n 个小对象所需的时间大约是 (n+1) RTT。第一个对象的获取需要一个额外的 RTT 用于建立连接，后续的对象可以在同一个连接上进行获取。（在同一个TCP上发送，但是一次发送一个） 流水线传输（Pipelined）： 在使用流水线传输时，可以一个TCP同时发送多个请求并减少等待时间。 使用流水线传输，获取 n 个小对象所需的时间大约是 2 个 RTT。 流水线传输与持久连接（Pipelined/Persistent）： 当结合流水线传输和持久连接时，首次获取可能需要 2 个 RTT 的时间，之后的获取只需要一个 RTT 的时间。 &&大文件延时（忽略RTT） 逐个获取（One-at-a-time）： 当每个大对象都是逐个获取时，时间主要由带宽所主导。 在这种情况下，获取 n 个大对象所需的时间大约是 nF/B，其中 B 是每个连接的带宽。 并发获取（Concurrent）： 如果能够并发获取多个大对象，可以减少获取时间。 当使用 m 个并发连接时，获取 n 个大对象所需的时间大约是 [n/m]F/B。 假设带宽是与大量用户共享的，并且每个 TCP 连接都获得相同的带宽。（个人总带宽会变化） 流水线传输和/或持久连接： 在流水线传输和/或持久连接下，获取 n 个大对象所需的时间大约是 nF/B。 缓存 引入原因 生成不必要的服务器和网络负载： 当多个客户端同时请求相同的信息时，服务器需要为每个请求生成相同的响应。这会导致不必要的服务器负载和网络负载，因为相同的信息被多次传输。 客户端经历不必要的延迟： 当多个客户端同时请求相同的信息时，每个客户端都需要等待自己的响应。这可能导致不必要的延迟，因为客户端在获取相同的信息时需要等待其他客户端的响应。 引用局部性指的是在一段时间内，访问的数据往往具有较高的相关性，即相邻的数据项更有可能被多次访问。 缓存利用了这种引用局部性，将频繁访问的数据存储在快速访问的缓存中，从而加快数据的访问速度。 缓存的效果非常好，但是存在一定的限制。 缓存的效果取决于内容的重叠程度。虽然有大量内容重叠，但请求的内容也有很多是唯一的。缓存的有效性随着缓存的大小呈对数增长。 请求时提供上一次的请求时间，询问是否发生了变化 如果资源的最后修改时间早于或等于指定的时间，则服务器返回 \"Not Modified\" 的响应。 如果资源的最后修改时间晚于指定的时间，表示资源已经发生了修改，服务器将返回 \"OK\" 的响应，并提供最新版本的资源。 Expires： 指示了资源在缓存中的有效期限，即缓存的过期时间。 当客户端再次发起请求时，如果当前时间已超过 Expires 字段指定的时间，则缓存的副本将被视为过期，客户端需要向服务器请求最新的资源。 No-cache： No-cache 字段用于禁止缓存服务器对资源进行缓存。 当服务器返回带有 No-cache 字段的响应时，客户端和中间缓存服务器都会忽略缓存，每次都直接从服务器获取最新的资源。 这样可以确保客户端获取的是最新的资源，而不是缓存副本。 分类 客户端缓存 转发代理（Forward proxies）： Forward proxies位于客户端和目标服务器之间，客户端发送请求时，请求首先发送到转发代理，然后由代理服务器转发请求到目标服务器。 转发代理还可以缓存响应以提高性能，减少对目标服务器的请求。 反向代理（Reverse proxies）： 使用反向代理进行缓存可以将文档缓存在靠近服务器的位置。 Reverse proxies的作用是代表目标服务器处理请求，并将响应返回给客户端。 这样做可以减少服务器的负载，因为对于经常请求的文档，反向代理可以直接提供缓存的副本，而无需每次都从服务器获取。 Forward proxies位于客户端和目标服务器之间，代表客户端发送请求。 Reverse proxies位于目标服务器和客户端之间，代表目标服务器处理请求。 Forward proxies用于代表客户端发送请求、隐藏IP地址、提供访问控制和内容过滤等功能。 Reverse proxies用于代表目标服务器处理请求、负载均衡、缓存内容等功能。 内容分发网络（Content Distribution Network，CDN） CDN 起因 大量向单一服务器请求，不堪重负 防御DDOS 解决方案： 使用内容分发服务器，与内容生产（源）服务器区分 复制源服务器的内容 内容提供商（如视频网站）是CDN服务的客户 CDN服务器会复制服务器的内容，并保持更新 实现 DNS转接到CDN的地址（重定向） 一个域名会映射到多个ip （路由）转接到最近的、负载最小的服务器 CDN通过创建一个“地图”，标示出与末端ISP和CDN服务器之间的距离。当查询到达权威DNS服务器时，服务器确定查询起源的ISP，并使用“地图”来确定最佳的CDN服务器。CDN服务器创建一个应用层覆盖网络。 URL重定向 "},"asserts/重点.html":{"url":"asserts/重点.html","title":"期末重点","keywords":"","body":"概述 知识点 协议：一个协议定义了在两个或多个通信实体之间交换的报文格式和次序, 以及报文发送 区域分类 网络边缘：终端用户设备、服务器 网络接入：物理媒介、无线路由器AP、光缆等 将端系统接入边缘路由器的网络 网络核心 由一系列高容量、高速度的网络设备和路由器组成，实现数据在不同网络之间的转发和路由功能， 交换、机路由器 &&计算机网络层次结构 OSI：物理层、链路层、网络层、传输层、会话层、表示层和应用层。 TCP/IP：物理层、链路层、网络层、传输层、应用层 多层协议的必要性： 分工合作：多层协议使得网络功能得以分层并分配到不同的层次，每个层次专注于特定的任务和功能。显式的结构允许对复杂系统中各个部分进行确定和理解，并了解它们之间的关系。这有助于理解不同组件如何相互配合和交互。 抽象和简化：每个协议层次可以隐藏底层细节，提供更高层次的抽象接口，使得上层应用或服务可以更简单地使用网络功能。 互操作性：多层协议提供了一种标准化的方式，使得不同厂商和组织开发的网络设备和应用程序能够互相配合和交互操作。 模块化和可扩展性：多层协议的存在使得网络能够逐步演化和升级。每个层或模块可以独立开发、测试和更新，而不会影响系统的其他部分。 问题：包头繁琐浪费、划分严格实际上高层可能需要一些低层次信息 层次功能 物理层：负责将比特流转换为物理信号，并在网络中进行传输。 链路层：将数据划分为帧并进行传输。处理物理地址（如MAC地址）的寻址和访问控制。（相邻节点传输） 网络层：负责将数据报从源主机传输到目标主机，实现数据的路由和转发。处理逻辑地址（如IP地址）的寻址和路由选择 传输层：提供端到端的数据传输服务。可靠传输、拥塞控制、流量控制等。报文段 应用层：提供各种应用程序使用的协议和服务。处理数据，与用户交互 漏斗形协议结构： 简化的协议栈：由于网络层只使用IP协议，整个协议栈变得更简洁。这降低了系统的复杂性，减少了实现和维护的工作量。 灵活性和可扩展性：通过将网络层与其他传输层协议（如TCP和UDP）分离，互联网实现了灵活性和可扩展性。新的传输层协议可以轻松地添加到现有的网络层上，而不需要对网络层进行修改。 跨平台兼容性：IP协议是一种通用的网络层协议，它可以在不同的操作系统和设备之间进行互联。这种跨平台兼容性使得不同厂商的设备能够在互联网上进行通信，促进了网络的互操作性。 路由灵活性：由于网络层只负责路由功能，它可以灵活地根据网络状况和路由策略选择最佳的路径。这使得互联网能够适应不断变化的网络拓扑和流量需求。 网络自治性：沙漏型协议体系结构支持网络自治性，即不同的网络自治系统（AS）可以根据自己的需求和政策来管理和控制自己的网络。每个自治系统可以独立地决定如何路由和传输数据，同时保持与其他自治系统的互联。 交换模式 电路交换 资源预留，通话期间独占资源，有保障 针对每个连接进行控制（如admisson control） 问题：线路复杂、资源浪费、建立连接增加时延 分组交换 按需传输，资源充分利用，每个数据包独立处理、传输 针对每个数据包进行控制，每个数据包的传输路径可能不同 问题：存在拥塞、丢包、顺序问题 虚电路 结合两种方法，建立逻辑连接（而不是物理连接），以分组的形式传输数据 建立时选择路径，数据包按照相同的路径进行传播 提供质量保证和资源预留，按序到达，又充分利用资源 在包上添加特殊标记告知路由器保留资源，建立vc 路由器会对具有特殊标识的包特殊转发 性能指标 时延 处理 排队 平均排队数目L=平均到达速率A*平均等待时间W 传输：进入链路的时间 包大小/链路宽度（链路宽度也就是传输速率由整个链路中最慢的部分决定） 传播：在线路上传输需要的时间 线路长度/传输速度 丢包（乘法） 吞吐量（传输速率） 例题 链路层 知识点 可靠传输与错误检查 弥补物理层的缺陷，不一定需要 停止等待：发送frame，等待ACK；收到后发送下一条 滑动窗口： ack附带下一个要收到的包的编号 错误处理：gobackn（从错误包开始的所有包都需要被重新传输）；选择重传（重新传输错误的包） 在数据D后添加其校验码EDC用于进行检验 奇偶校验 一维：1位记录有奇数个还是偶数个 二维：n+m-1位 可以纠正单比特错误 &&CRC 只检验，不纠错 加法减法都不借位，相当于进行异或操作(在计算除法的过程中) 称r+1比特模式/生成多项式（能检测小于r+1比特的突发差错） 取余数的后r位作为CRC校验码R(D为元数据，G位模式串，r隐式给出)（G的长度为r+1位） 因特网检验和 将数据的字节作为16比特的整数对待并求和，这个和的反码形成了携带在报文段首部的因特网检验和 ==注意==首项溢出时进位到最后一位 &&网络设备 网桥（类似于二层交换机） 连接多个局域网（lans），接收来自一个端口的数据帧，存储下（用于学习及决定转发）然后进行转发，不会对数据进行任何修改 具有学习功能，会构建转发表，根据目的MAC地址转发数据帧 具有透明性 无需配置：以太网设备（包括端）插入以太网中时，它可以立即开始使用，无需用户或网络操作人员进行额外的配置。 集线器（物理层） 当一个线路发送信息时，hub向所有其他线路进行简单重复消息 连接的所有设备处于同一个冲突域，速度就是单条线路的最大速率 star连接，但本质是bus 网卡（二层） 二层交换机 和网桥类似，基于mac转发表进行工作 具有网桥的功能，但是接口很多，每个接口连接一个端设备（星型结构），因此是无冲突的 处于兼容性的考虑，也是用了CSMA/CD 具有自学习能力（与桥类似） 传输速率很快（多条不同线路之间可以同时通信） 三层交换机 网桥、二层交换机等二层网络设备一般没有ip 三层交换机本质上与路由器的功能没有区别，体现在性能及使用场景 三层交换机具有路由功能（链路层mac+网络层ip） 三层交换机实现对网络流量的隔离和控制，分隔子网，避免了单一广播域中的问题。 引入原因：日益增长的站点数量和复杂性的要求 广播负载过重 由二层交换机连接的一组站点和局域网构成了一个单一的物理网络，共享一个MAC广播地址。广播帧会被发送到所有连接到二层交换机的局域网上的所有站点 缺乏多路径支持 两个节点之间只有一条线路（因为是生成树），限制速度和可靠度 路由机制 转发表与学习机制 &&环路与生成树算法stp 避免出现环，防止广播风暴 选择MAC作为标识符，标识符最小的节点作为根节点 全部初始化为（根x,距离0,本节点x） 向周围的节点发送信息（第一回合或者 收到消息导致最短距离发生了变化(Y, d+1, X））如果信息中的根节点更小或者距离更短则更新数据（多个时选择编号较小的）同时舍去未被选择的边 根节点宕机判断：让根节点周期性发送消息，从而让其他节点确定根节点是否正常工作 生成树可以由网桥的阻塞机制来实现 泛洪（在生成树上） 向所有其他端口发送消息 是学习了解网络结构的过程（根据收到的信息建立端口到mac的映射） 因此泛洪不是对资源的浪费 转发： 如果数据库中记录目的地的端口，则进行转发 如果找不到则进行泛洪 如果端口和发送端口相同，则不转发，drop数据 802.3以太网 bus需要进行MAC控制（如CSMA）；star模式为点对点传输，不存在冲突 非连接、不可靠 帧格式 可变负载长度：最短46字节，最长1500字节 地址（MAC）：6字节 分割帧： 使用哨兵：01111110表示开始，01111111表示结束 需要防止其它部分出现哨兵，通过在发送端如果发现出现连续5个1就插0，接收时自动删除0 arp 沟通ip和mac 发送者先在本地数据库查找，找不到的话则发送查找广播，，接收者收到并确认后进行回复，发送者收到mac信息，存储信息建立映射，附加时间戳存储在转发表 dhcp 过程：广播寻找DHCP服务器discover；服务器广播地址offer；向服务器发送请求request(refresh)；服务器分配ip资源ack DHCP相当于向用户出租资源，当用户不再使用或到达时间限制后服务器会收回资源release Soft state：DHCP使用\"Soft state\"机制来管理IP地址的分配情况。\"Soft state\"表示DHCP服务器和客户端之间的交互是一种临时状态，并且需要周期性地进行维护和更新，当出现故障时保证资源释放等操作正常进行 理念：广播、缓存、软状态 802.11无线局域网 结构 Station：接到网络的终端设备或主机（端系统） AP：用于提供无线网络连接，在有线网络和无线网络之间进行转化 BSS：无线局域网中的基本服务集，由一个AP和与之关联的一组无线设备组成，它提供了在特定区域内的无线通信。 ESS：扩展服务集，由多个BSS组成的无线网络集合。在一个ESS中，多个AP通过有线网络连接起来，形成一个统一的无线网络。用户可以在不同的BSS之间自由移动，而无需重新认证或断开连接。 DS：无线局域网中的分布系统，用于连接不同的BSS和提供跨越多个BSS的无线漫游构成ESS。 评估 SNR信噪比：信号能量/噪声能量 BER：比特出错率 增大功率提升SNR 终端移动时，信号强度/干扰都会发生变化，需要对通讯进行动态调整，维持SNR和BER在可用的范围内（如当SNR减少时可以通过降低速率来减少BER） 特点： 无线信号在传播过程中会随着穿过物质而衰减 多路径传播：无线电信号反射离物体地面，到达广告目的地 时间略有不同，会产生自干扰问题 半双工，不同同时发送和接收（因为自干扰问题难以解决） 通常具有无线性以及移动性 &&隐藏终端问题： 由于多设备连接造成 这意味着AC相互不知道对方的存在，因而可能同时向B发出信息，从而导致发生冲突干扰 解决办法 发送者先广播RTS告知周边设备他要发送 接收者再广播CTS告知他要发送 发送者发送信息 接收者广播ACK确认收到，并告知传输完成 搜索与连接 消极方式 客户端在每个信道上监听AP定期发送的信标，而不主动发送任何请求。（每个AP会周期性的发送信标帧，包含AP的SSID和MAC地址） 比较耗时 积极方式 客户端在每个信道上发送探测请求帧，并等待AP回复探测响应帧应答探测请求帧，主机在能够响应的AP中选择进行关联，再发出关联求帧等待关联响应帧（一共需要进行两次请求/响应握手）。 比较快速 频段 802.11b: 2.4GHz-2.485GHz划分为不同信道 这个85MHz的频段定义了11个部分重叠的信道（1 6 11是唯一的三个非重叠信道的集合） 帧格式 address1：下一跳（ap） address2：发送者 address3：ap的上游路由器 为什么需要三个地址： AP是链路层设备，不知道ip 在网络层来看，端设备不知到AP的存在 如果没有地址3，AP不知道因该把来自无线局域网的数据发给谁 也就是说AP不能根据ip知道下一跳的位置，需要手动设定 MAC媒体接入控制理念： 控制多设备接入的网络，组织多个设备同时传输数据，决定让哪一个设备开始数据传输，从而避免因同时发送造成冲突 理想：所有节点平分、充分利用带宽、分布式 频道划分 TDMA时间划分 FDMA频率划分 &&CDMA(扩频多址数字式通信技术） 每个节点使用不同模式字段code 将01信号转化为-1/1进行发送，发送时使用code乘以数据，并进行叠加 解码时再将数据与code相乘并除以code的长度 轮流发送 令牌环802.5 当令牌到达一个节点时，该节点检查是否有数据需要发送。如果节点有数据要发送，它就将数据封装在一个帧中，并将帧发送到网络上。 数据在环路中传输，传输完成后释放令牌到环路中，使得后面的节点可以根据需求捕获令牌发送数据 使用中心节点控制 问题：等待时间长、单点崩溃 随机接入 ALOHA：当节点有消息要发送时就发出，如果发送失败就有p的概率重新发送，1-p的概率等待一会再重新发送，接收端收到后回复ACK ALOHA slotted：同步时间和固定帧大小，数据要么传输成功、要么完全冲突损坏。如果冲突了，在之后每个区间重新发送的概率都是p &&CSMA/CD 增加对线路的监听，如果线路空闲则发送帧，如果信道繁忙则等待一段时间之后再进行传输 由于传输延迟的存在（进入线路的过程中可能会发生冲突），仍然会发生冲突 分类 nonpersistencent CSMA：如果繁忙则等待随机长度时间 1-persistent CSMA：空闲后立即发送（多个节点时易冲突） p-Persistent CSMA：如果空闲则有p概率立即发送，1-p概率等待一单元时间再发送（最优为p=1/N） 冲突检测 通过信号强度来判断是否发生了冲突（冲突的信号要强得多） 冲突一旦被察觉，并发送jam信号（加强冲突，便于其他设备检测） 当发送者收到别人发送而来的信号时会发现冲突 帧的最小长度 避免察觉到发生冲突时已经完成该数据的传输 $$Size/B>=2(L/v)$$即传输时延大于等于2倍的传播时延 最大长度是由协议决定的，较大的帧长度会占用更多的带宽和资源，增加网络传输的延迟。如果允许无限制地增加帧长度，可能会导致网络拥堵和传输效率下降。 二进制指数退避（冲突后的等待） 对于前10次发生冲突后的等待时间的选择范围每次是上一次的二倍 第n次碰撞后随机从（0 1 2...2^n^-1）中随机选一个值作为k（等待时间） k=1表示512比特时间 换算：秒=比特时间除以传输速率 之后的6次时间保持不变 16次冲突（失败后）放弃发送信息 点协调PCF（无线局域网） 帧间距控制优先级（抢先发送） SIFS内容（控制信息）：ACK、CTS、回应轮询 PIFS（比普通的DIFS有更高的优先级）：轮询、AP指令 DIFS：普通异步流量 过程 AP用PIFS轮询设备是否有高优先级的数据要发送，通知其它站点开始一个超级帧周期。 被询问的站点可以使用SIFS（短帧间隔）来回应。如果在预期的反转时间内没有收到回应，协调器就会发出另一个询问信号。当轮询列表为空或超级帧结束时，AP发送一个CF-END帧来终止PCF模式，并恢复DCF模式。） 此阶段由ap进行控制，不会发生冲突 超级帧 在超帧时间的前一部分，由点协调器轮询(PCF)，在超帧时间的后一部分，允许异步通信量争用接入（DCF）。 分布式协调DCF： 使用CSMA/CA（避免碰撞）机制，即在发送数据之前，站感知媒介是否空闲，避免与其他站点的传输发生碰撞。 取决于不同的优先级方案，在发送前会等待帧间隔（IFS） &&CSMA/CA（无线局域网） 由于无线信号的衰减和干扰，无线局域网中很难进行碰撞检测，因此DCF不使用碰撞检测机制。(使用ACK来确认是否成功发送信息) 发送站点在发送数据时很难接收到其他站点的信号 不能检测到所有可能发生的碰撞，例如隐藏终端问题 如果某站点最初监听到信道空闲，它将在DIFS的短时间段后发送该帧 否则，该站点选取一个随机回退值，并且在侦听信道空闲时递减值。 当侦听到信道忙时，计数值保持不变 当计数值减为 0 时并且空闲，该站点发送整个数据帧并等待确认 如果收到确认，发送站点知道它的帧已被 目的站正确接收了。 如果该站点要发送另一帧，它 将从第二步开始 CSMA/CA 协议。 如果未收到确认，发送站点将重新进入第二步中的回退阶段，并从一个更大的范围内选取随机值。 CSMA/CD与CSMA/CA的比较 CSMA/CA增加更多的随机等待，避免高代价的碰撞 CSMA/CA不使用碰撞检测机制，使用ACK 在 CSMAI CD 协议中碰撞并非是一个严重的问题，因为两个站点检测到碰撞后都会放弃它们的发送， 从而避免了由于碰撞而造成的该帧剩余部分的无用发送。 而 802. 11 并不检测碰撞和放弃发送，遭受碰撞的帧仍将被完全传输。 &&利用率分析 公式 最大媒体利用率$$U=帧传输用时/帧总耗时$$ $$a=传播时间/传输时间$$ 用$$1$$代表传输时间 注意分为帧较小和帧较大两种情况讨论 点到点：$$U=1/(1+a)$$ &&令牌环：假设token发出后会被下一个紧挨着的节点捕获 $$a/N$$是将令牌传播到下一个节点的时间 有两种情况是因为在发送令牌前数据要已经返回并且已经传输完成 alloha slotted 一个节点成功概率，存在节点成功的概率为 最大值为即 alloha csma/cd（p） 假设一次冲突浪费$$2a$$时间 同理可得$$A$$表示存在节点完成传输 那么失败次数的期望为 例题 网络层 知识点 服务： 路由选择：决定数据包走怎样的路从出发点到目的地，使用forwarding表，比较耗时（几秒） 转发：数据从路由器的一个口进入，从哪个口出去 尽力而为 路由器 性能评估：交换容量=N端口数目*R每个口的速率 入端口 物理层->链路层->网络层 更新ip包头、寻找通往目的地址ip的出端口 &&快速查表寻址：地址聚合，最长前缀匹配（压缩地址，合并相同方向的地址） 为了节约空间、提高速率，用范围划分决定路由方向 交换结构 memory模式：把input的数据保存到memory再传输到output bus总线模式：不同端口竞争bus的使用 Switching via a Mesh：使用算法决定通断，进行资源调度 纵横式网络能够并行转发多个分组，除非来自两个不同输入端口的两个分组其目的地为相同的输出端口 出端口 决定已怎样的顺序传输数据包，数据包分类与调度，何时丢包 分组调度 fifo Scheduler优先级轮询 排队 若N个输入、输出端口的速率都是R~lilne~，如果R~switch~比它快N倍，则只会发生轻微的排队 输入排队，如果到达速率大于转发速率。先将数据缓存起来 输出排队，到达分组必须排队(等待)经输出链路传输，如果输出端口相同，会在输出端口处出现排队 &&ip协议 地址类型：单播地址、广播地址、多播地址、任意播地址（有多个实体使用该地址，即负载均衡） 包头 版本version 头部长度IHL：明头部由多少个32位字组成（不含可选长度时为20字节） 区分服务TOS：优先级、可靠性、延迟 ttl：防止出了问题的报文一直在网络中浪费资源 全长total length：ip包的总长度 标识符 identification：唯一标识一个包的所有分片（一个包的所有分片具有相同的id） 标志flags：控制和识别分片的标志位如（禁止分片、更多分片） 分片偏移 fragment offset：记录分片在数据包中的位置（以8字节为单位） 协议protocol：传输层协议类型 头部校验和Header checksum： 它是由所有16位字（把头部切分为长度为16的片段）中的补码和计算得出的。在计算过程中，每个路由器都会重新验证并重新计算校验和，并将其设置为0。这样做是为了防止在计算过程中发生溢出。（每次都需要重新计算是因为头部会发生变化） 可选片段options：最多40字节（若不是32整数bits倍，用padding进行补齐） 数据包分解与合并 MTU：设施支持的最大传输单元 分片：在host和router进行 合并：只在目的地进行（路由器上重新组装分片是不可行的，因为分片可能会采用不同的路由） 单元标识符确定属于的数据包 偏移量确定分片在原包中的位置 计算在源数据包data中的偏移时不包含包头的长度 标志moreflag，确定是不是最后一个分片 当一组数据包中第一个到达目的地时开始计时，如果到达时间限制后仍没有全部到达，则丢弃全部数据。 ipv6 长度固定，为40字节 Traffic Class (8 bits)：QoS（为了区分不同的数据流而设置的一种标识。） Flow Label (20 bits)：流标签（标记一组流量，共享相同类型的服务） &&ipv4与ipv6的异同 路由器不再负责分片，如果一个IPv6数据包太大，无法通过下一跳，则会发送ICMPv6告知 ipv6不再有单独的broadcast地址，而是使用包含所有节点的组进行多拨来实现。（减少广播风暴、唤醒不必要的节点） 不使用ARP，使用Neighbor Discovery 取消首部校验和 128比特地址，解决了IPv4地址枯竭的问题。 更好的区分服务QoS的支持 更容易扩展选项 更加安全： 内置的、强大的IP层 加密和认证 更有效、更强大的移动性机制 缺点： 迁移成本高 网络基础设施不完善 兼容性问题 融合方式 双栈 - 一些具有双栈（IPv6、IPv4）的路由器 可以在不同格式之间进行转换 隧道--在IPv4数据报中以有效载荷形式传输IPv6 &&子网划分 地址划分 子网掩码指示哪些位是子网号，哪些是主机号 网络地址=子网掩码&ip地址，网络地址相同说明处于同一个子网 主机号=~子网掩码&ip地址 优点 每个局域网分配一个子网号，具有更大的灵活性 本地路由器在子网化网络内进行路由 子网对整个互联网来说就像一个单一的网络 使整个互联网与网络号的增长和路由复杂性隔离开来 传统类型划分（网络资源划分思想80） A 子网掩码：255.0.0.0 1.x.x.x~126.x.x.x（不含0和127） 每个网段支持2^24^-2个主机（全0是网络号，全1是广播号）(这两个地址不一定必须是全0和全1，也可以是别的地址，但对于所有网段必须预留出来两个位置) B 子网掩码：255.255.0.0 网段从128.0.x.x到191.255.x.x（八位一组）2^14^个 每个网段2^16^-2个主机 C 子网掩码：255.255.255.0 网段192.0.0.x到223.255.255.x共2^21^个网段 每个网段最多2^8^-2 D多播使用 E保留地址 CIDR 更有效地利用IP地址空间和改善路由表的管理，并不能增加 可以更方便的分层嵌套 从原来的主机号里面借了几位拿去做子网号了 x.x.x.x/n(n表示网络ID的位数)（即自由划分网络号和主机号的位数分配） 二级地址->三级地址 NAT 给内部网络和外部网络分配不同的IP集（不同内部网络可以使用相同的ip），在出网关时内部地址会被替换为外部地址 来解决地址不够使用的问题；安全（隐藏内部ip地址）；便于切换isp（只需要重新配置网关） 分类 静态NAT：一个内部ip绑定一个对应的外部地址，用于网络服务器 动态NAT：动态分配外部ip给内部设备（有一个ip池），谁用分配给谁 单地址模式NAPT：只有一个外部ip，所有内部ip对外通讯时都会被进行替换。路由器维护一个转发表，将外部端口与内部ip绑定，当外部ip向路由器发送信息时，会根据使用的端口向特定的内部设备转发消息 移动ip协议 解决设备从一个网络到另一个网络时TCP断开连接的问题 具有动态IP的特点 发现 路由器发送ICMP告知是否有这项服务 移动设备向路由请求服务 注册 节点向外部网络请求服务 外部网络向家庭网络发送请求 家庭网络进行答复 外部网络把结果返回给节点 隧道 注册之后就建立起了隧道 家庭代理将移动节点的IP地址绑定到家庭代理的MAC地址上 家庭代理接收到发送到移动节点的数据包，并通过IP隧道将数据包转发到外部代理 而移动节点直接回复信息 控制信息 ICMP、ARP、DHCP等信息的头部都是接在IP头部后面 其类型记录在IP包头的Protocol字段 ICMP 传递控制、错误消息、ping等 当buffer已经满了时丢弃掉新进入的数据，通过ICMP告知发送者 protocol=1 &&ping/traceroute的实现 重复三次计算RTT Ping: 发送端发送一个ICMP Echo Request（Ping）消息到目标主机。 目标主机接收到ICMP Echo Request消息后，会生成一个ICMP Echo Reply（Pong）消息，并将其发送回发送端。 Traceroute: 发送TTL依次递增的UDP数据包（到不同路由器时TTL为0，路由器会返回信息），这样可以知道到每个路由器的时间，以及路由器的地址 MTU计算： 发送具有一定大小的数据包，并禁止尽心分片，这样通过对包长度进行二分搜索来确定能通过最大的包大小 不能通过时路由器会返回信息 &&路由算法 目标：效率、鲁棒性、稳定性 评价因素：最少跳、最少路径代价、最小延迟（排队长度） 决策时间：普通包（路由器），vc（建立线路时） 决策地点：集中式、分布式 路由表更新：动态（周期更新、拓扑变化，容易出现路由震荡、循环选择）、静态（手动更新） 分类 集中式：当网络发生重大改变时中央重新计算并下发 分布式 泛洪：收到数据包后发送到除了发送端口以外的全部端口，最终会有一系列的（相同）数据包到达目的地 随机： 从除了发送端口以外的其他端口随机发送 适用于连通性很强的网络（邻居节点很多） 自适应路由：需要网络信息，致力于拥塞控制，网络发生变化时路由选择也会发生变化 &&算法示例 Dijkstra’s Bellman-Ford 类型 Link State集中式算法 Distance Vector分布式算法 特点 每个节点都需要知道整个网络拓扑来构建转发表 每个节点只需要维护到已知节点的距离向量，和相邻节点传递 过程 接待你之间相互发送向量表，根据其它节点上一阶段的表，更新自己本阶段的表（条目），别人的直接复制过来，当所有表不再发生变化时终止算法 问题 震荡：当路由算法选择了某个路径后，该路径的负载会增加，导致该路径的成本增加。当其他可用路径的成本更低时，路由算法将会选择其他路径。 循环选择(无穷计数)：当一个节点检测到本地链路成本的变化后，它会更新自己的距离向量，重新计算到其他节点的距离，并将更新的信息通知给它的邻居节点。 改进 让一些流量留在负载较重的链路上，以平衡流量；非同步运行路由器，增加随机性； 毒性逆转：如果一个节点要通过它的邻居节点(如 z-w-y-x中y会告诉w无穷大，但不会告诉非直接相连的z)来到达某个目的地，那么该节点会将到达该目的地的距离设置为无穷大（来针对这个邻居节点防止被选择），但是当环上有3个以上节点时还是会出现无穷计数 节点故障的影响 错误范围受到限制 错误可能会通过网络传播，到达整个网络 发展 第一阶段：BF（DV），输出队列长度衡量代价，收敛太慢 第二阶段：DK（LS），延迟衡量代价，将链路信息传播到整个网络时效率低下的尤其是当网络的规模较大的时候 第三阶段：OSPF，采用更全面的链路信息。通过构建拓扑图和计算最短路径来选择路由。它考虑了延迟、带宽和拥塞等因素，能够更准确地选择最佳路径。 延迟=重新传输的时间-数据包到达的时间+传输时间+传播时间 代价计算 ρ = 2(Ts − T)/(Ts − 2T) T是当前测量的延迟 Ts是平均数据包长度/链路的传输速率 平滑化（leveling） Un = α×ρn+(1–α)×Un–1 α – constant, now set 0.5 路由协议 目的：解决规模问题、自治倾向 层级管理： 根据自治域AS进行划分，同一个AS内的路由器使用相同的内部路由策略 网关路由：负责路由到AS外目的地的路由器。与其他网关路由器的自治系统间路由协议，并与AS内的路由器运行自治系统内路由协议 IGP（内部路由算法） 专注于性能 RIP 使用dv（最多15跳） 每隔30秒，路由器会向相邻的节点发送一条RIP更新消息（UDP），其中包含了距离向量信息。 如果在180秒内未能接收到更新消息，则说明与相邻节点的连接已经断开。 OSPF 代替了RIP，使用Link-State 每个节点都存储了一个有向图，用于描述该节点的相邻节点和它们之间的连接方式。每个路由器都会维护与相邻路由器之间的链路状态列表，并10s向整个自治系统广播（泛洪）状态信息，直接使用ip协议进行传输 优点 使用身份验证来防止恶意入侵 负载均衡 多播支持 TOS区分服务的支持 分层结构 每个节点都使用DK算法确定以自己为根节点的最小生成树（因此在传输包时只用上了每个生成树的下一跳信息） 区域划分 将AS内部进一步划分， 每个区域由一个32位的区域ID进行标识，该区域内的路由器只知道该区域内的完整拓扑信息，从而限制了链路状态信息向其他区域的洪泛。 区域边界路由器负责与其他区域传输 每个区域都必须与骨干区域（0.0.0.0）相连以便在区域之间传播路由信息。 分类 内部路由IR 边界路由ABR：连接多个区域（如连接到骨干网） 骨干路由器BBR：运行在骨干网、骨干网与其他区域网之间的路由器 ASB：发送到其他AS 广播 路由器链路广告： EGP（外部、网关路由算法） 专注于策略 DV和LS都不能胜任： AS通常希望知道链路经过的线路 使用 Path-Vector 路径矢量路由协议的关键思想是广告整个路径，根据路径来转发数据包 每个网关路由器向邻居广播到达目的地的完整路径。这样，网关路由器可以执行策略路由，避免经过特定的自治系统，同时考虑更多的其他参数。 期望：自主选择路由（传输过程）、自主性、隐私性(保密自身的信息，如拓扑结构) BGP AS中的边界路由使用BGP协议 AS间关系：商家与顾客（Pr-Cu）/合作（Peer-Peer） 合作的前提：前提：peer双方都能从中受益 由于AS的内部是隐藏的，因此网络拓扑图中只显示自治域间的路由信息。 AS决定传输的路径，以及对外广播公布的内容 受到DV的启发，但有许多不同 选择最好而不是最短的路径，综合考虑 知道具体的路径，可以更加灵活的选择路径，并避免回路 即使物理上有链接，但可能不进行广告，拒绝某种传输 可以根据前缀转发，一次向多个路由器进行转发 BGP的组成 eBGP：处于不同自治系统（AS）之间的边界路由器之间的BGP会话 iBGP：处于同一个自治系统中的边界路由器和其他路由器之间的BGP会话，目的是在AS内部分发外部学习到的路由信息 iBGP协议确保自治域内部所有路由器之间的路由信息同步，并且避免出现路由环路等问题。 Tip：IGP目的是为自治域内部的所有路由器提供内部可达性 总结 自治域内的边界路由器会使用eBGP协议来学习到外部AS中的路由信息。然后，AS内部路由器之间使用iBGP协议来分发和同步学习到的外部路由信息，以确保自治域内的所有路由器都具有完整的路由信息。 最后，自治域内的所有路由器都使用IGP协议（如OSPF或RIP）来确定到达目的地的最短路径。这个过程会一步步地进行，直到数据包到达自治域的边界路由器，然后通过eBGP协议将数据包发送到目的地的外部AS中。 BGP中的属性（用于进行路径的决策） 本地属性是仅在本地AS中使用的属性，不包括在路由公告中。全局属性则会随着eBGP路由公告一起传播。用于帮助路由器进行路径的选择 ASPATH：全局属性，反向顺序列出经过的AS（可以用于防止环路、黑名单） LOCAL PREF：本地属性，指定想要的路由路径（偏好） MED：存在多个出口的情况下选择到达目的地的最优路径（转发的AS所宣布的），表示从一个AS到另一个AS的内部路径的距离 IGP cost：通过在自治系统内使用内部网关协议（IGP）来计算的，每个路由器根据内部域协议中的路径成本选择最近的出口点。 *多播 发一份（一个操作）到达不同目的地，效率高 建立一个生成树连接发送源和接收组成员 当一个主机加入一个组播组时，它会通知本地路由器，告诉路由器它要接收该组的数据包。路由器会记录哪些主机已经加入了哪些组播组，并在收到组播数据包时，将数据包转发给那些已经加入了该组的主机。 ipv4 D类地址 组播MAC地址：组播mac地址的高24bit为0x01005e，mac 地址 的低23bit为组播ip地址的低23bit。 IGMP 主机可以通知多播路由器告知要加入某个组，多播路由器相互交互，构建多播树 路由器周期性的询问主机都是否还要在某个组里（不回答就是退出） 每个子网中只需要选出一个路由器来作为询问者 回复时，每个节点给与每个组一个随机的发送时延（0-10s） 第一个计时结束的节点代表整个组进行发送，其他节点发现有人回复了就不再回复 发送的TTL为了表示只在该子网内进行传输 两个特殊地址： 224.0.0.1: all multicast groups on subnet 224.0.0.2: all routers on subnet 版本 v1：每次都广播询问所有组的订阅情况，主机只发送要加入的组，通过不回复来表示离开某个组 v2：可以询问单个组的使用情况，允许主动发送消息主动离开组 问题：垃圾邮件、发送源的位置是未知的 v3：允许接收主机设定一个源列表（只接受来自列表中的源的信息），其他的会在路由器丢弃 多播算法——多播树的构建 发送源构建一个树 Shortest Path Trees 使用DK算法，OSPF &&Reverse path forwarding RIP，要求途中的路由器知道到达发送源的最短路径 基本思想是：当一个路由器收到一个多播数据包时，它将检查其路由表中是否存在最佳路径来到达数据包的源地址（即数据包从最短路径而来），如果是则泛洪，否则丢弃 如果路由器不含加入多播组的节点，路由器可以向上游发送“prune”消息告知不要再继续转发了 不适用于链路代价不对称、动态变化的情况 每个接收节点选择到发送源的最短路径，构成生成树 Center-based trees 将网络中的一个路由器标识为中心节点其他路由器可以通过向中心节点发送单播加入消息来加入该树形结构。 *多播协议 DVMRP 基于RIP的多播路由协议，使用dv 该协议是软状态的，DVMRP路由器会定期（1分钟）\"忘记\"剪枝的分支，多播数据会再次通过未剪枝的分支传输。下游路由器可以重新剪枝，否则将继续接收数据。 在规模化网络中不适用，因为所有路由器都需要全局了解所有多播组和其源的信息。 MOSPF 基于ospf 可以为每个多播数据报计算一棵相同的最短路径树 PIM 可以与任何单播路由协议一起使用 在稀疏模式下，PIM 协议使用中心点方法建立组播树，这个中心点可以是任意一个路由器，其他路由器通过向中心点发送加入消息来加入组播。组成员比较分散，带宽有限。 在密集模式下，PIM 协议使用源点树和反向路径转发建立组播树，与 DVMRP 协议类似。组成员比较密集，带宽相对较充足。 应用层多播 由于硬件的限制，ip多播并没有得到广泛的应用 应用层组播通过在应用层复制和缓存数据包而不是在路由器上复制数据包来避免IP组播的部署问题。应用层组播无须对路由器作任何修改,因此在 Internet 上非常容易部署 不解决多播的效率问题（相对ip多播较低），只实现多播的功能 通过分段单播连接实现的。终端主机而不是路由器负责复制和转发组播数据包 优缺点： 优点： 不需要底层网络支持IP多播功能，因此可以在任何网络环境中使用。 可以更容易地控制多播组成员，以便更好地保护网络安全。 可以更灵活地处理不同的应用需求，如实时视频和音频流等。 缺点： 由于没有底层支持，因此需要更多的计算和网络带宽资源。 需要专门的服务器来协调多播组成员，这可能会导致单点故障和瓶颈问题。 应用层多播不如IP多播标准化和普及，因此不如IP多播适用于大规模网络部署。 例题 毒性逆转 传输层 知识点 运行在端系统上，分为发送端和接收端 使用原因： 对数据进行合并、分发给不同应用程序，进程之间进行通信，为应用层提供端到端的服务 网络层是尽力而为的服务，缺少保障 套接字：应用程序进程与操作系统中的传输层之间交换网络消息的接口。 传输层地址 UDP套接字 TCP套接字 mux与demux 传输层数据包格式，包含源端口和目的端口 对于UDP，对于来自不同ip/端口的数据，如果有相同的目标ip/端口则会被放入目标的同一个socket中。（仅依据目标信息进行合并） 对于TCP，要求四元组完全相同才会放入一个套接字（源IP地址，源端口号，目标IP地址和目标端口号。） 可靠传输设计理念 数据包损坏处理 校验和、回复ACK 由于ACK也可能出错，因此对于ACK还要附带序号 数据包丢失 使用计时判断超时 停止等待协议 发送确认收到的循环进行 效率极低，不能充分利用资源（空闲时间长） &&流水线协议 一次发送多个数据包（滑动窗口） 带宽MIN(n*DATA/RTT, Link Bandwidth) 确认方式 Cumulative ACKs：返回下一个要收到的包的序列 Selective ACKs：对收到的每一个包进行答复 丢失处理 GBN 配合Cumulative ACKs，提前到达的数据包都会被丢弃 发送端只需要为一组数据包中的第一个设置定时器，如果这个包没有成功发送，那就重新发送所有的数据包 SR 对每个数据包都设置定时器 当错误率很高时gbn甚至不能完成传输 sr常用于无线网络 UDP 尽力而为、无连接 为了加强校验能力，除了头部外还有一个伪首部参与校验码checksum的计算 对报文段中所有16比特字的和进行加和 将溢出位加在末尾 最后对结果取反码得到checksum &&TCP 可靠、有序、字节流传输、选择重传、累计确认 32比特的序号字段和32比特的确认号字段。这些字段被TCP发送方和接收方用来实现可靠数据传输服务 16比特的接收窗口字段，该字段用于流量控制。该字段用于指示接收方愿意接受的字节数量。 6比特的标志字段，ACK比特用于指示确认字段中的值是有效的，即 该报文段包括一个对已被成功接收报文段的确认。RST、SYN和FIN比特用于连 接建立和拆除。 分片 IP最大MTU（1500字节） TCP最大MSS（1460）（总长度减去ip和tcp头部） 假设一个数据包有B个字节，如果X之前的数据都收到了，那么接收者会发送X+B，即ACK sequence = 收到的数据包的sequence+length(data) 受到重复（3）ACK、或者计时器超时说明发生了丢包，要进行重传（从滑动窗口中第一个开始重传） &&RTT估算 回归法 SampleRTT：样本RTT，是指当前分组往返的时间；（不能使用从重传获取的SampleRTT） EstimatedRTT：估计的RTT，是指对SampleRTT进行平均计算得到的RTT值 Jacobson/Karels algorithm SRTT（EstimatedRTT）：平滑的往返时延，通常是通过对多次测量的SampleRTT进行加权平均得出的估计值。SRTT是用于计算RTO和DevRTT的重要参数。 SERR (Smoothed Error)：平滑误差，是估计的RTT和实际测量值之间的差异。SERR用于计算SDEV，以便更好地估计RTT的变异性。（SamplaeRTT-EstimatedRTT）即Deviation SDEV (Smoothed Deviation)：平滑的偏差，是样本RTT与SRTT之间的差异的指数平均值。SDEV用于计算RTO，以便更好地调整重传超时时间，以适应网络中的变异性。即DevRTT 计算RTO：RTO是估计RTT加上4倍平均偏差的值，旨在提供足够的时间来等待确认信息的到达。 &&连接握手 连接建立（3次） 为了防止过时的数据包造成的干扰，对发送包序列号SN起点ISN进行随机初始化 SN：序列号，用于标识TCP协议中每个数据包的唯一序列号。 AN：确认号，用于标识收到的数据包的序列号。当接收方收到TCP数据包后，会向发送方发送一个ACK包，其中包含确认号，表明接收方已经成功接收了前面发送方发送的数据包。 双方会分别选择一个序号作为自己包序列序号的起点 为SYN也增加序列号和校验，避免干扰 拒绝错误的包 如果syn包发送失败，那么不会收到ack回复，并且发送者不知道接收者距离有多远，因此设置一个固定的超时时长（一般3s） 连接关闭（3/4次） 单边关闭 time_wait：回复ACK确认关闭后实际并不会立刻进行关闭，因为对方可能收不到ACK，这种情况就需要进行重发 同时（双边）关闭 强制关闭 发送rst后对方不会进行回复，但如果对方继续发送data(表示没收到rst)则会重新发送rst 传输控制 窗口的右边缘则是左边缘加上一个常数，这个常数只受传输层缓存大小的限制。 对于接收方数据接收到并取走才滑动（即离开缓冲区被应用程序获取） 通过控制发送窗口的大小来控制发送速率（正在传输的数据量一定不会大于窗口的容量） ~Window/RTT（使用MSS表示速率，即以MSS为单位而不是字节） 流量控制 防止发送速度大于接收端的硬件处理性能 接收端回复ack的同时附件参数RWND，告诉发送方自己有多少空间可以进行存储 ACK正常回复（但ACK并不代表处理完成了），将确认和控制信号RWND分开 如果ACK/CREDIT消息丢失了，那么对协议的影响很小，因为未来的ACK消息会重新同步协议。 死锁问题： 接收方B首先向发送方A发送一个带有AN=i、W=0的数据段，表示关闭接收窗口。接着，B向A发送另一个数据段，其中AN=i，W=j，表示重新打开窗口，但这个数据段可能会丢失。此时，A认为窗口已经关闭，而B认为窗口已经打开，从而导致了死锁。 采用窗口定时器的方法，当窗口定时器到期时，如果没有收到任何数据，则发送方A可以发送一些数据，例如重传之前的数据段。这样，即使接收方B发送的第二个数据段丢失了，发送方A仍然可以通过定时器来重新激活数据传输，从而避免了死锁。 拥塞控制 让传输路径上的路由器发送速率大于接收速率，防止在传输过程中超出路由器缓存造成丢包（当繁忙时会产生大量丢包与重传，即做大量无用功，进一步加重拥塞） 增减窗口限制CWND Sender-side window = min {CWND, RWND} TCP Reno流程 慢启动（指数增长） 初始时CWND=1，发送速率为MSS（数据包最大大小）/RTT（通过每收到一个ACK就把CWND+1），相当于每RTT翻一倍 ssthresh最初会被初始化为一个很大的值 拥塞避免（加性增加和乘性减少） CWND > ssthresh达到阈值进入拥塞避免，CWND每RTT增加一个MSS 丢包拥塞 3个重复ACK：ssthresh = CWND/2 CWND= ssthresh（收到3个重复ACK）之后拥塞避免（快速恢复）(Tachoe不区分重复和超时，全部置为1) 超时：ssthresh = CWND/2, CWND = 1之后重新慢启动 tip： 当出现ack冗余或者数据包丢失后，拥塞窗口长度会在下一轮回发生变化 如果在一轮回达到了sshresh，那么本轮回的长度就是sshresh，因为到达后会终止本回合开启下一回合！ 选择AIMD的原因 效率&公平：找到带宽上限、动态公平分配 A加性、D乘性 红线代表效率、绿线代表功能 AIAD 不公平 MIMD 不公平 AIMD 完美 快速恢复改进-TCP newReno（默认使用） 对重复ACK的情况进行改进：原先在等待重传包到达时窗口大小增长过于缓慢，造成窗口的阻塞 ssthresh = CWND/2 CWND= ssthresh+3由于收到三个重复的ACK，可以认为这三个包都被正常收到了，因此对CWND正常进行增加 在收到重传包的ACK之前收到一个ACK就CWND+1（保持乘性增） 收到之后退出快速回复，令CWND = ssthresh，进入拥塞避免 对比 Reno New Reno 可以更快的推动窗口滑动 xmit表示发包 &&拥塞控制分析 忽略慢启动指数增加阶段，因为这一阶段是很短的 速率在 W/(2xRTT) W/RTT 之间变化（拥塞抑制阶段，每次加一个MSS），故平均值为0.75W/RTT 用丢包率p来表示W（窗口大小） *TCP潜在问题 当RTT不一致时TCP不是公平的 目标速率较高时，要求几乎为0的丢包率 解决：当越过上界时加快传输增加速度（乘性增加）、建立多条连接 速率震荡（应用程序更喜欢稳定的传输） 避免震荡，直接计算出rate，发送数据 目的：速率与传统方式相同，但比较平稳，固定速率发送 移动网络丢包 TCP在某些情况下可能会将数据包的丢失误认为是网络拥塞的结果而触发拥塞控制算法中的拥塞避免机制，导致流量的速率被削减。 短数据问题 如果数据流比较短，可能无法充分加速，没有离开慢启动就结束了 长数据支配短数据，tcp总是想将缓存占满，因此数据包到达路由器后可能会经历漫长的延时等待（即使包很小） 欺骗问题 由于TCP是端算法，如果在操作系统修改CWDN的长度，会造成公平性的问题 路由器拥塞控制思想 由路由器告知终端发生了拥塞、通知终端发送速率、并保证传输公平性 抑制分组：路由器发送ICMP告诉源发生了丢包（对路由器性能要求太大） 反压：逐层进行抑制分组，一层通知相邻的一层 精确拥塞通知ECN 警告位：在数据包的包头做一位标记，如果接收端发现head中有信号，则在返回的ACK中添加标志位（ECN）提醒发送端，由此接收端不丢包也可以知道拥塞状态 提前指示拥塞：ECN可以作为早期拥塞指示器，提供关于网络拥塞的信息。这可以帮助发送方避免等待传输超时来检测拥塞，从而减少传输的延迟。 易于增量部署 随机早期丢包：防止TCP出现同步速率波动 RED策略：路由器缓冲区越满，丢包率越高 &&MAX-MIN 流平分带宽保证公平性，同时充分利用带宽兼顾效率 尽可能平分带宽，但如果有流比较小率先完成传输，则会被从平分名单去除，剩下的流进行平分 实现方式：公平队列 使用算法进行模拟：首先计算理想评分条件下每个数据包完成发送的时间，按照理论完成的先后依次进行发送（并不是时间上的完全符合，而是满足偏序关系） 为了减少计算，可以扩大流的范围（如一定特征的TCP归属为一个流） 优点：避免欺骗、避免RTT公平性问题 问题：复杂、不能拥塞避免、貌似公平实际做无用功浪费带宽 &&（路由器）质量控制Qos 不同类型数据流对服务的要求不同，因此需要差异化服务（对丢包率、传输速度、延迟的要求） ISA 把一组数据包定义为一个流，具有相同的QoS参数 功能： 路由算法：全方位考虑更多因素 排队：多队列，对流分类 丢包：指定丢弃的包而不是新到来的 资源预留：为特定QoS的流预留资源（RSVP） Admission control：确定是否有足够的资源来满足请求的服务质量 Traffic control database：流量控制数据库用于存储与流量控制相关的参数 Management agent：管理代理通过修改流量控制数据库的内容来指导接纳控制模块设置策略。 RSVP 应用程序或网络服务发送RSVP请求，指定其对服务质量的需求，如带宽、延迟、丢包率等。 RSVP消息沿着网络路径传播，与途径上的每个路由器交换信息，以协商资源预留。 路由器根据收到的RSVP消息，检查是否有足够的可用资源来满足请求，并向上游和下游节点发送相应的确认消息。 如果路径上的所有路由器都能满足请求，并且资源预留成功，数据传输就可以开始。 缺点 设备要求高，复杂，成本高 不具有很好的弹性 不能很好的同时服务很多的流 DS 不区分流，而是将数据包的传输分为几类面对每一类的数据进行相同处理（减少类型，降低复杂度） 通常在ISP内独立执行（DS Domain），由内部路由和边缘路由组成 在域内一致解释DS代码：确保在特定网络域内对DS（差异化服务）代码点的一致解释。 内部路由 内部路由器：内部路由器根据边缘路由器的标记对数据包进行分类、缓冲和调度。它根据数据包的标记给予优先处理，更重视符合要求的数据包。 边缘路由 对每个流进行流量管理：边缘路由器可以对每个数据流进行个别的流量管理。它可以标记和监管数据包，将其划分为符合要求的流量和不符合要求的流量，标识分组。 流量调度算法（边缘路由分类） 控制指标： 平均速率：指的是数据以恒定速率离开漏桶的速率。它表示单位时间内允许发送的平均数据量。（较长时间的平均值） 峰值速率：表示漏桶允许的最大发送速率。峰值速率通常高于平均速率，并且可以在短时间内发送更多的数据。 突发长度：指的是漏桶能够容纳的最大突发数据长度。突发长度与峰值速率相关，它定义了在突发情况下漏桶可以容纳的最大数据量。 漏桶 以恒定速率将数据放入网路，用缓冲区进行稳定 &&令牌桶 在边缘有一个”桶“里面装在用于提供特殊服务的token，装入速率r表示允许的最大(平均)速率，大小b表示可以爆发传输的最大数据量，没有token的意味着普通服务（低优先级） t时间内最多$$rt+b$$ WFQ加权公平队列 当$$bi$$个分组被一次性加入到WFQ等待区域时具有最大时延$$d{max}=\\frac{b_i}{R*\\frac{w_i}{\\sum w_j}}$$ 例题 网络安全 知识点 网络攻击 分类： 主动攻击：伪装、修改、阻断 容易发现但难以阻止 被动攻击：窃听 很难被发现 期望： 可用性：针对阻断（通讯不能被阻断） 机密性：针对窃听（不能被听懂（可以听）） 完整性：针对篡改（不能在无法察觉的前提下修改） 授权性：针对伪装（保证双方的身份正确） 手段：加密、校验、身份认证 不能对传输过程物理安全以及加密的算法做任何假设 攻击方式 只拥有密文： 穷举法：尝试使用所有可能的密钥对密文进行解密。 密码分析：利用加密算法的性质以及对明文和密文的一般特征的了解，试图推断出原始信息或加密密钥。 已知明文攻击： 拥有明文和相应的密文。能够分析二者之间的关系，有可能推断出加密密钥或解密其他密文。 已选择明文攻击： 可以选择特定的明文消息并获取相应的密文。能够分析加密过程，可能发现漏洞或推导出加密密钥。 为了更为通用的加密算法，可以将传输内容全部用数字来表示 如把字母序号转化为二进制再转化为数字dog=>00100 01111 00111=>4583 对称加密 关键：如何实现安全的密钥传递 传统加密 &&凯撒密码 单表密码（随意对应的加强凯撒密码） 维吉尼亚密码 篱笆密码 按列书写，按行读取 key是行数 行列密码 按行书写，打乱列后按列读取 *块加密 计算机可以实现暴力破解 数据加密标准：DES是一种对称密钥块密码，使用56位密钥对64位的明文块进行加密。然而，由于DES的密钥长度较短，已经被认为不够安全，因此在一些应用中已经不再广泛使用。 三重数据加密标准：TDES是对DES的改进和增强版本。它通过对数据应用DES算法三次来提高安全性。TDES可以使用不同的密钥长度（如168位）和操作模式，以提供更高的保护级别。（存在效率低的问题） 高级加密标准：AES是一种广泛采用的对称密钥块密码，被视为DES的替代方案。AES使用可变长度的密钥（如128位、192位或256位），以及不同的加密模式和操作方法，具有较高的安全性和效率。 公钥系统 &&非对称加密RSA 过程 选择两个很大的素数p、q（500-1024bits） 取$$ N = p × q$$ $$Φ = (p–1)×(q–1)$$（欧拉函数，计算小于N并与N互素 的整数个数） 选择一个e $$GCD(e, Φ) = 1$$ 找到e的模反元素（$$(d×e) mod Φ = 1$$）（因为幂存在周期Φ） Public Key: (e, N), and Private Key: (d, N) 发送： 使用e作为指数，N作为模数 $$C = M^e(mod N)$$ 发送$$C$$ 接收： $$M=C^d(modN)$$ 要求 素数 p 和 q 应该具有大致相同的长度，并且应该是应该是不相关的。 公钥指数 e 可以选择较小的值。公钥指数通常是一个较小的常数值，用于加密过程，因为它不会对加密过程增加太大的负担。 私钥指数 d 必须选择一个较大的值。私钥指数用于解密过程，需要足够大的值以确保解密的安全性。 RSA加密和解密过程中需要进行大数的指数运算，这需要较长的计算时间和资源。比DES等块加密慢得多，因此可以先使用RSA传递对称密钥建立连接，再之后的通话中使用对称密钥KS进行加密 身份认证 可以反向使用RSA（私钥加密，公钥解密） 随机化R防止重放攻击 ap4.0 使用随机数避免重放攻击，但要求有知道的共享对称密钥 ap5.0 但是由于Bob可能不知道Alice的公钥，在这个过程中可能被欺骗 攻击者伪装alice与bob通信，并让bob误以为自己与alice通信（同时伪装与alice和bob进行通信） MAC校验 确认信息的来源正确，并且没有被篡改 消息认证码（MAC）是一个固定长度的代码，它会附加在要传输的消息末尾。它用于验证消息的完整性和真实性。 MAC不应该可逆，不需要解密 可以处理任何长度的消息而自身的长度固定 单项性：已知MAC为X的情况下，很难找到一个数据Y满足MAC(Y)=X。（即过程几乎不可逆） 弱碰撞抗性：给定一个消息X1，很难找到另一个消息X2，使得MAC(X1) = MAC(X2)。 强碰撞抗性：很难找到任意两个不同的消息X1和X2，使得MAC(X1) = MAC(X2)。 加密进行身份认证 CBC：$$Ci = E_K(M_i+C{i–1})i = 1, 2, . . ., L$$ 哈希身份认证 MD5、SHA-1 数字签名 对称密钥法：根据消息和一个密钥生成MAC，添加密钥是为了防止消息被篡改（整个替换） 公私密钥法 对MAC进行加密/解密 密钥分发 Diffie-Hellman交换 通过公开的通信渠道协商出一个共享的秘密密钥，而不需要在传输过程中直接共享密钥。 过程 选择一个知名的大质数P，以及P的一个原根g（增加破解的复杂度） A从$$$Z_P^*$$$选择一个数$$x$$，把$$X=g^x(modP)$$发送给B B从$$$Z_P^*$$$选择一个数$$y$$，把$$Y = g^y(modP)$$发送给A A得到密钥$$Y^xmodP$$ 即($$g^{xy}modP$$) B得到密钥$$X^ymodP$$ 权威机构CA 会话密钥是一种在逻辑连接期间使用的密钥。它会在会话结束时销毁，并且不是永久性的密钥。 永久密钥主要作用是用于密钥分发。 CA负责确定发送方和接收方的身份有效性，并为该连接提供一个会话密钥。 安全服务模块在整个通信链路中扮演重要角色。SSM负责执行端到端的加密操作，并获取用于主机的密钥。 公钥证书 由权威机构签名认证的公钥，保证是属于指定用户的真实密钥 整数包含：唯一序列号、所有者、颁发者等信息，并且CA会在末尾添加MAC并使用私钥进行加密（数字签名） &&电子邮件系统设计PGP 提供保密性 使用非对称密钥传递对称密钥，并使用对称密钥对信息进行加密 提供消息完整性及身份验证 对MAC进行加密 提供消息完整性和保密性 嵌套使用 SSL传输层网络安全 传输层加密可以确保数据在传输过程中的保密性，保护应用数据安全传输，保护一个互动数据流（连接），但在网络中的其他节点上可能仍然可以观察到传输的元数据 在TCP与应用层之间添加SSL，使用SSL发送数据而不是tcp 理念 握手认证，双方通过公私密钥互相认证，得到一个统一的对称主密钥MS 使用共享主密钥生成一系列密钥，对分块数据进行加密 对数据进行分块（记录） 将数据流分解为一系列块。每个块都携带自己的MAC，使得接收方可以在每个记录到达时立即进行处理，而不需要等待整个数据流的接收完成。 并且为了防止攻击，添加序列号（防止重排，MAC = MAC(Mx, sequence || data)），添加一次性数字（防止重放攻击） 安全关闭连接（防止伪造关闭信息） 使用记录类型，并为连接关闭操作定义一个特殊的记录类型。即使用加密和MAC保护信息 *真实SSL 记录（块）协议（基础协议）：它负责将数据分割成记录，并对每个记录进行加密、完整性校验和解密等操作。 高层协议：握手过程、证书交换、密钥协商和身份验证等 记录（数据单元PDU） 握手协议 服务器和客户端之间需要通过握手协议建立会话session，可以为多个TCP通信建立保护 大致过程 建立安全能力：通过握手协议，客户端和服务器之间建立了SSL连接，并确定了双方的安全能力。包括使用的加密算法、MAC算法和密钥长度等参数。 服务器鉴别与密钥交换：服务器在握手过程中对自身进行身份验证。它向客户端提供适用于共享密钥分发的公钥，以确保通信的安全性。 客户端验证服务器并开始密钥交换：客户端对服务器进行验证，并开始进行密钥交换。这确保了客户端与合法的服务器进行通信，并建立了共享密钥。 交换确认：在握手过程中，各个阶段都会进行确认，确保握手的每个步骤都得到了正确执行。 根据协商更改密码规范：一旦握手协议的各个阶段完成，通信双方根据协商的结果改变密码规范。这意味着双方根据握手协议中达成的协议更改加密算法、MAC算法和密钥等参数开始正式进行传输。 VPN（ipsec） 网络层加密提供了更高级别的安全性，保护整个通信链路中的数据和通信元数据。 应用：分支机构通过互联网连接：IPsec可以用于建立安全的分支机构与总部之间的通信连接，以保护数据的机密性和完整性；安全远程访问；服务器之间的流量加密；电子商务 VPNs：虚拟私有网络 不需要专用设备及链路，成本低，并且可以实现私人网络的搭建 VPN会在数据进入公共互联网之前进行加密，确保数据的安全性。 VPN在逻辑上与其他流量隔离，实现了逻辑上的分离。 传输模式 终端设备实现IPsec协议。 仅对IP数据包的有效负载进行加密，而IP头部保持原样。 传输模式通常用于直接连接的通信 隧道模式 常用于防火墙之间的通信，并用于构建虚拟私人网络 Psec会加密整个IP数据包，包括IP头部和有效负载。IP数据包的头部中的IP地址是IPSec网关的地址，而不是实际的源和目的地址。 安全关联 在发送数据之前，发送方和接收方之间会建立一个称为\"安全关联\"的SA，用于定义双方之间的单向关系。用于描述安全通信的参数和策略。（双向通信需要两个SA） IP是无连接的，而IPsec是面向连接的，因此需要建立和维护SA来确保安全通信。 本地有SA表，使用安全参数索引SPI标识和区分不同安全关联SA 认证协议AH：AH协议通过在IP数据包中添加认证头部来实现数据的完整性验证和源身份验证。 封装协议ESP：ESP协议负责对有效载荷进行加密，并添加校验码以验证数据的完整性。 分为头部和尾部，夹住数据 头部提供了协议参数和选项的定义 尾部则提供了完整性保护和数据验证的能力。 密钥交换协议IKE：IKE协议用于在两个对等体之间协商安全功能和密钥。使用Diffie-Hellman密钥交换算法，允许节点在不直接交换密钥的情况下生成共享密钥。 帧结构 ESP Header：用于封装加密和认证的数据。它包含ESP的各种参数和选项，如加密算法、认证算法、SPI等。 ESP Trailer：ESP尾部，包含填充字段和填充长度等。 Next Header：下一个头部字段，指示在ESP封装后的数据中紧随ESP头部之后的下一个头部类型。 ESP auth校验码 使用共享的密钥创建的消息认证码（MAC），用于验证数据的完整性和防止数据被篡改。 WIFI WEP有线等效隐私(802.11) 使用共享密钥，由一个40位的主密钥和一个24位的初始化向量（IV）组成 主密钥需要手动进行设置 认证 移动设备向接入点发送认证请求。 接入点回复一个128位的随机数（用于防止重播攻击（录制））。 移动设备使用共享的主密钥（KS）对随机数进行加密。 接入点解密随机数并对移动设备进行认证。 加密 使用主密钥和初始化向量，生成一串密钥流。（种子） 加密器确保相同的64位密钥生成相同的密钥流。 密钥流与明文和校验和进行异或操作，生成密文。 安全漏洞 如果IV是随机分配的，预期在5000个数据帧中会出现一次重复使用的情况。如果IV是顺序分配的，那么在每次启动时都会重新使用IV。 并且IV明文传输，因此IV的重复是会被察觉的 如果攻击者（Trudy）引导Alice加密一个已知的明文P1，一旦IV重新出现，攻击者就能够知道对应的加密后的密文P2。 对相同的密钥C进行两次加密会使得加密失效 802.11i 通过使用独立的身份验证服务器，可以实现更强大的加密方式，并且提供更安全的密钥管理。身份验证服务器可以负责生成和分发密钥，确保只有授权的设备能够访问网络。 类似AC，服务器为AP和设备分配共享对称密钥 防火墙 理念： 将组织的内部网络与更大的互联网隔离开来。 允许某些数据包通过，阻止其他数据包。 确保内部网络和系统免受外部的黑客和恶意软件的攻击 应用： 防止拒绝服务攻击：通过阻止攻击者建立伪造的TCP连接或尝试ping攻击来防止SYN洪泛等类型的拒绝服务攻击。 仅允许授权的访问进入内部网络，防止对内部数据的非法访问/修改 &&无状态数据包过滤 基于数据包的源地址、目标地址、端口等信息进行过滤 例子 丢弃发出的80端口号包：禁用web服务 阻止ACK位为0的入站TCP段（发起方发送SYN段，其中的ACK字段为0特殊标识！）防止建立TCP连接 丢失表示TTL超时的ICMP，防止被路由追踪 丢失目的以太网地址是广播地址的包，防止被用于Dos ACL控制表 操作，来源、目的ip，协议，端口，特殊标识 有状态数据包过滤（使用状态跟踪） 有状态跟踪功能，可以检测和控制数据包的状态和连接。 跟踪每个TCP连接的状态 在访问控制列表（ACL）中增加了一个指示，在允许数据包通过之前需要检查连接状态表。 应用程序网关：也称为代理服务器，它在应用层对网络流量进行过滤和代理，提供更高级的安全性和控制。 例题 应用层 知识点 | | 应用 | 特点 | 优点 | 缺点 | | ---- | ------------- | --------------------------- | -------------------------- | ---------- | | CS | Voice-over-IP | 集中化控制；客户端-服务器； | 高可靠性安全性高； | 单点故障 | | P2P | BitTorrent | 分布式控制；对等节点 | 去中心化，无依赖；自扩展性 | 不保证可用 | &&DNS 从域名到ip的映射 分布式、自治性管理：可以更改自己的信息，不需要跟踪（记录）全世界的所有信息 域名层次结构 从根节点向下划分域名，使用树形结构 从右向左*.nju.edu.cn DNS数据库被分割成多个部分，并分布在不同的服务器上。每个服务器只存储与其具有管理权限的域相关的资源记录。 域名服务器 根域名服务器：保存了顶级域名的信息，如.com、.org、.net、.edu等。当本地名称服务器无法解析某个名称时，它会向根域名服务器发送请求，并且可以提供对其他DNS服务器的查询引导。 顶级域名服务器（TLD）：这些服务器负责管理顶级域名 授权DNS服务器：这些服务器属于组织或机构，提供对特定的域名到IP地址的授权映射。授权DNS服务器负责存储其具有管理权限的域中所有DNS名称的资源记录。 本地名称服务器：不严格属于DNS层次结构，每个住宅ISP、公司、大学都维护着自己的本地名称服务器。当主机发起DNS查询时，查询被发送到本地名称服务器，它负责处理查询并尝试解析域名（本地缓存查找）。如果本地名称服务器无法解析域名，它会向更高级的DNS服务器发送查询请求。 查询过程 FTP 客户端/服务器模型，相互传递文件 建立两条信道：数据/控制 过程 进行客户端身份认证 客户端收到文件列表，查看 客户端选择文件进行处理，服务端收到指令后开始执行（传输） 电子邮件 sc模型 用户代理+邮件服务器 Alice的用户代理通过SMTP协议将邮件发送到她的邮件服务器，并将邮件放置在消息队列中。 SMTP客户端在客户端与Bob的邮件服务器之间建立TCP连接。 SMTP客户端通过TCP连接发送Alice的邮件。 Bob的邮件服务器将邮件放置在Bob的邮箱中。 Bob使用他的用户代理（UA），例如通过POP3协议，来读取邮件。 SMTP：用于传递简单文本消息的协议。 TCP MIME：用于传递各种类型的数据，例如声音、图像、视频剪辑等，扩展了SMTP协议的功能。 MIME将邮件内容和附件中的所有数据都编码为7位ASCII字符集，以确保兼容性和可靠的传输。 POP：用于从服务器中检索邮件的协议，包括授权和下载邮件。 用于用户代理（邮件客户端）与邮件服务器之间的授权验证和邮件下载过程。 IMAP：用于在服务器上操作存储的邮件的协议。 WWW 由许多互连的文档（称为“页面”）组成的分布式数据库。 cs url 每个页面都有一个唯一的地址，称为统一资源定位符（URL），可以通过浏览器访问 格式://:/? 协议；主机（域名/ip）；端口；路径；查询字符串（url参数） 缓存 引用局部性指的是在一段时间内，访问的数据往往具有较高的相关性，即相邻的数据项更有可能被多次访问。 在本地浏览器保存网页，请求时提供上一次的请求时间，询问是否发生了变化 HTTP 无状态性 每个客户端请求和服务器的响应都被独立地处理，服务器不需要保留先前请求的状态 优点：故障处理更加容易；服务器能够处理更高速率的请求；请求的顺序对服务器来说不重要 缺点：某些应用程序需要保持持久状态 过程 先建立TCP连接然后发送请求 cookie 状态存储在客户端 身份认证 问题：cookie可能会泄露信息，发送给网页服务器 &&效率 网页上有很多object，图片等各种信息，早期http一次一个，效率很低 办法：同时发送多个请求；一个TCP传输更多信息 小文件延时（传输时间忽略）Tip一个RTT是一个来回 逐个获取 2nRTT 并发获取（m 个并发连接）2[n/m]RTT 持久连接（一个TCP一次获取一个）(n+1) RTT 流水线传输（一个连接，一次全部获取） 2RTT 流水线传输与持久连接：首次 2RTT，之后 RTT 大文件延时（忽略RTT） 逐个获取nF/B 并发获取[n/m]F/B（前提是多个TCP时总带宽增加） 流水线传输和/或持久连接nF/B CDN 转发代理 客户端发送请求时，请求首先发送到转发代理，然后由代理服务器转发请求到目标服务器。 转发代理还可以缓存响应以提高性能，减少对目标服务器的请求 代表客户端发送请求。 反向代理 使用反向代理进行缓存可以将文档缓存在靠近服务器的位置。代表目标服务器处理请求，并将响应返回给客户端。 DNS转接到CDN的地址（重定向） 一个域名会映射到多个ip （路由）转接到最近的、负载最小的服务器 CDN通过创建一个“地图”，标示出与末端ISP和CDN服务器之间的距离。当查询到达权威DNS服务器时，服务器确定查询起源的ISP，并使用“地图”来确定最佳的CDN服务器。CDN服务器创建一个应用层覆盖网络。 "}}